

============================== 2023-03-03 09:38:02.432199 | 69b8f2bc-a35a-464f-87d1-935ab6f86e0f ==============================
[0m09:38:02.432207 [info ] [MainThread]: Running with dbt=1.3.3
[0m09:38:02.432432 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/lewischarlesbaker/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m09:38:02.432506 [debug] [MainThread]: Tracking: tracking
[0m09:38:02.444322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034c6190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034c62b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034c62e0>]}
[0m09:38:02.445691 [debug] [MainThread]: Set downloads directory='/var/folders/kq/1tj4_9sj5pz5mh4crbk9f7dw0000gn/T/dbt-downloads-11oahb3o'
[0m09:38:02.446113 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m09:38:02.519875 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m09:38:02.520158 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/fivetran_utils.json
[0m09:38:02.559893 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/fivetran_utils.json 200
[0m09:38:02.592883 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/tnightengale/dbt_meta_testing.json
[0m09:38:02.636104 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/tnightengale/dbt_meta_testing.json 200
[0m09:38:02.638672 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m09:38:02.679437 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m09:38:02.697453 [debug] [MainThread]: Executing "git clone --depth 1 git@github.com:rittmananalytics/wire_jira.git 2866b3ab007d7c145b466af137a6d251"
[0m09:38:04.491242 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:04.491750 [debug] [MainThread]: STDERR: "b"Cloning into '2866b3ab007d7c145b466af137a6d251'...\n""
[0m09:38:04.492188 [debug] [MainThread]: Pulling new dependency 2866b3ab007d7c145b466af137a6d251.
[0m09:38:04.492305 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:04.506541 [debug] [MainThread]: STDOUT: "b'31b38c2b4da1a44848263cc53572dcaf64567016\n'"
[0m09:38:04.507034 [debug] [MainThread]: STDERR: "b''"
[0m09:38:04.507215 [debug] [MainThread]:   Checking out revision HEAD.
[0m09:38:04.507343 [debug] [MainThread]: Executing "git remote set-branches origin HEAD"
[0m09:38:04.522883 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:04.523322 [debug] [MainThread]: STDERR: "b''"
[0m09:38:04.523479 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags HEAD"
[0m09:38:06.117804 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:06.118171 [debug] [MainThread]: STDERR: "b'From github.com:rittmananalytics/wire_jira\n * branch            HEAD       -> FETCH_HEAD\n'"
[0m09:38:06.118286 [debug] [MainThread]: Executing "git tag --list"
[0m09:38:06.130157 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:06.130568 [debug] [MainThread]: STDERR: "b''"
[0m09:38:06.130688 [debug] [MainThread]: Executing "git reset --hard origin/HEAD"
[0m09:38:06.147983 [debug] [MainThread]: STDOUT: "b'HEAD is now at 31b38c2 Merge pull request #2 from rittmananalytics/wire_jira_dev/0.1.2\n'"
[0m09:38:06.148314 [debug] [MainThread]: STDERR: "b''"
[0m09:38:06.148476 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:06.160379 [debug] [MainThread]: STDOUT: "b'31b38c2b4da1a44848263cc53572dcaf64567016\n'"
[0m09:38:06.160761 [debug] [MainThread]: STDERR: "b''"
[0m09:38:06.160903 [debug] [MainThread]:   Checked out at 31b38c2.
[0m09:38:06.161037 [warn ] [MainThread]: [33mWARNING: The git package "git@github.com:rittmananalytics/wire_jira.git" 
	is not pinned, using HEAD (default branch).
	This can introduce breaking changes into your project without warning!

See https://docs.getdbt.com/docs/package-management#section-specifying-package-versions[0m
[0m09:38:06.169194 [debug] [MainThread]: Executing "git clone --depth 1 git@github.com:rittmananalytics/wire_harvest.git dd7d8beded6f5f5357bdaba65e154e7c"
[0m09:38:07.823391 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:07.823937 [debug] [MainThread]: STDERR: "b"Cloning into 'dd7d8beded6f5f5357bdaba65e154e7c'...\n""
[0m09:38:07.824158 [debug] [MainThread]: Pulling new dependency dd7d8beded6f5f5357bdaba65e154e7c.
[0m09:38:07.824282 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:07.840924 [debug] [MainThread]: STDOUT: "b'73070bef9c4c24749a624255705f462c4e3ea60b\n'"
[0m09:38:07.841482 [debug] [MainThread]: STDERR: "b''"
[0m09:38:07.841686 [debug] [MainThread]:   Checking out revision harvest_dev/0.1.1.
[0m09:38:07.841829 [debug] [MainThread]: Executing "git remote set-branches origin harvest_dev/0.1.1"
[0m09:38:07.859519 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:07.859950 [debug] [MainThread]: STDERR: "b''"
[0m09:38:07.860066 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags harvest_dev/0.1.1"
[0m09:38:09.574783 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:09.575251 [debug] [MainThread]: STDERR: "b'From github.com:rittmananalytics/wire_harvest\n * branch            harvest_dev/0.1.1 -> FETCH_HEAD\n * [new branch]      harvest_dev/0.1.1 -> origin/harvest_dev/0.1.1\n'"
[0m09:38:09.575404 [debug] [MainThread]: Executing "git tag --list"
[0m09:38:09.590119 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:09.590695 [debug] [MainThread]: STDERR: "b''"
[0m09:38:09.590832 [debug] [MainThread]: Executing "git reset --hard origin/harvest_dev/0.1.1"
[0m09:38:09.612997 [debug] [MainThread]: STDOUT: "b'HEAD is now at bf812d8 harvest invoices xa fix\n'"
[0m09:38:09.613327 [debug] [MainThread]: STDERR: "b''"
[0m09:38:09.613450 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:09.624527 [debug] [MainThread]: STDOUT: "b'bf812d8c425816b8417474e5ff0e9f7f53dab7f6\n'"
[0m09:38:09.624944 [debug] [MainThread]: STDERR: "b''"
[0m09:38:09.625088 [debug] [MainThread]:   Checked out at bf812d8.
[0m09:38:09.644785 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/audit_helper.json
[0m09:38:09.684487 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/audit_helper.json 200
[0m09:38:09.688215 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/jira.json
[0m09:38:09.728365 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/jira.json 200
[0m09:38:09.751243 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/jira_source.json
[0m09:38:09.790265 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/jira_source.json 200
[0m09:38:09.802383 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/spark_utils.json
[0m09:38:09.845478 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/spark_utils.json 200
[0m09:38:09.898643 [debug] [MainThread]: Executing "git clone --depth 1 git@github.com:rittmananalytics/wire_jira.git 2866b3ab007d7c145b466af137a6d251"
[0m09:38:09.909611 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:09.909900 [debug] [MainThread]: STDERR: "b"fatal: destination path '2866b3ab007d7c145b466af137a6d251' already exists and is not an empty directory.\n""
[0m09:38:09.909983 [debug] [MainThread]: command return code=128
[0m09:38:09.910625 [debug] [MainThread]: Updating existing dependency 2866b3ab007d7c145b466af137a6d251.
[0m09:38:09.910703 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:09.920527 [debug] [MainThread]: STDOUT: "b'31b38c2b4da1a44848263cc53572dcaf64567016\n'"
[0m09:38:09.920849 [debug] [MainThread]: STDERR: "b''"
[0m09:38:09.920966 [debug] [MainThread]:   Checking out revision HEAD.
[0m09:38:09.921046 [debug] [MainThread]: Executing "git remote set-branches origin HEAD"
[0m09:38:09.931188 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:09.931485 [debug] [MainThread]: STDERR: "b''"
[0m09:38:09.931556 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags HEAD"
[0m09:38:11.630108 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:11.630723 [debug] [MainThread]: STDERR: "b'From github.com:rittmananalytics/wire_jira\n * branch            HEAD       -> FETCH_HEAD\n'"
[0m09:38:11.630922 [debug] [MainThread]: Executing "git tag --list"
[0m09:38:11.648808 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:11.649358 [debug] [MainThread]: STDERR: "b''"
[0m09:38:11.649537 [debug] [MainThread]: Executing "git reset --hard origin/HEAD"
[0m09:38:11.671413 [debug] [MainThread]: STDOUT: "b'HEAD is now at 31b38c2 Merge pull request #2 from rittmananalytics/wire_jira_dev/0.1.2\n'"
[0m09:38:11.671956 [debug] [MainThread]: STDERR: "b''"
[0m09:38:11.672125 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:11.686316 [debug] [MainThread]: STDOUT: "b'31b38c2b4da1a44848263cc53572dcaf64567016\n'"
[0m09:38:11.686730 [debug] [MainThread]: STDERR: "b''"
[0m09:38:11.686892 [debug] [MainThread]: Already at 31b38c2, nothing to do.
[0m09:38:11.687043 [warn ] [MainThread]: [33mWARNING: The git package "git@github.com:rittmananalytics/wire_jira.git" 
	is not pinned, using HEAD (default branch).
	This can introduce breaking changes into your project without warning!

See https://docs.getdbt.com/docs/package-management#section-specifying-package-versions[0m
[0m09:38:11.694753 [debug] [MainThread]: Executing "git clone --depth 1 git@github.com:rittmananalytics/wire_harvest.git dd7d8beded6f5f5357bdaba65e154e7c"
[0m09:38:11.706942 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:11.707359 [debug] [MainThread]: STDERR: "b"fatal: destination path 'dd7d8beded6f5f5357bdaba65e154e7c' already exists and is not an empty directory.\n""
[0m09:38:11.707443 [debug] [MainThread]: command return code=128
[0m09:38:11.707939 [debug] [MainThread]: Updating existing dependency dd7d8beded6f5f5357bdaba65e154e7c.
[0m09:38:11.708017 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:11.718573 [debug] [MainThread]: STDOUT: "b'bf812d8c425816b8417474e5ff0e9f7f53dab7f6\n'"
[0m09:38:11.718890 [debug] [MainThread]: STDERR: "b''"
[0m09:38:11.719001 [debug] [MainThread]:   Checking out revision harvest_dev/0.1.1.
[0m09:38:11.719091 [debug] [MainThread]: Executing "git remote set-branches origin harvest_dev/0.1.1"
[0m09:38:11.729838 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:11.730159 [debug] [MainThread]: STDERR: "b''"
[0m09:38:11.730232 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags harvest_dev/0.1.1"
[0m09:38:13.347305 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:13.347925 [debug] [MainThread]: STDERR: "b'From github.com:rittmananalytics/wire_harvest\n * branch            harvest_dev/0.1.1 -> FETCH_HEAD\n'"
[0m09:38:13.348140 [debug] [MainThread]: Executing "git tag --list"
[0m09:38:13.365702 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:13.366280 [debug] [MainThread]: STDERR: "b''"
[0m09:38:13.366436 [debug] [MainThread]: Executing "git reset --hard origin/harvest_dev/0.1.1"
[0m09:38:13.395551 [debug] [MainThread]: STDOUT: "b'HEAD is now at bf812d8 harvest invoices xa fix\n'"
[0m09:38:13.395974 [debug] [MainThread]: STDERR: "b''"
[0m09:38:13.396118 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:13.408672 [debug] [MainThread]: STDOUT: "b'bf812d8c425816b8417474e5ff0e9f7f53dab7f6\n'"
[0m09:38:13.409029 [debug] [MainThread]: STDERR: "b''"
[0m09:38:13.409164 [debug] [MainThread]: Already at bf812d8, nothing to do.
[0m09:38:13.416835 [info ] [MainThread]: Installing fivetran/fivetran_utils
[0m09:38:13.785370 [info ] [MainThread]:   Installed from version 0.4.1
[0m09:38:13.785763 [info ] [MainThread]:   Updated version available: 0.4.2
[0m09:38:13.786219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '69b8f2bc-a35a-464f-87d1-935ab6f86e0f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034aa280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10352fb80>]}
[0m09:38:13.786592 [info ] [MainThread]: Installing tnightengale/dbt_meta_testing
[0m09:38:14.006973 [info ] [MainThread]:   Installed from version 0.3.6
[0m09:38:14.007286 [info ] [MainThread]:   Up to date!
[0m09:38:14.007553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '69b8f2bc-a35a-464f-87d1-935ab6f86e0f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10354be50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10354b880>]}
[0m09:38:14.007763 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m09:38:14.268663 [info ] [MainThread]:   Installed from version 1.0.0
[0m09:38:14.268960 [info ] [MainThread]:   Up to date!
[0m09:38:14.269219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '69b8f2bc-a35a-464f-87d1-935ab6f86e0f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10354ba60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034c6580>]}
[0m09:38:14.269517 [info ] [MainThread]: Installing git@github.com:rittmananalytics/wire_jira.git
[0m09:38:14.269823 [debug] [MainThread]: Executing "git clone --depth 1 git@github.com:rittmananalytics/wire_jira.git 2866b3ab007d7c145b466af137a6d251"
[0m09:38:14.284618 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:14.285002 [debug] [MainThread]: STDERR: "b"fatal: destination path '2866b3ab007d7c145b466af137a6d251' already exists and is not an empty directory.\n""
[0m09:38:14.285120 [debug] [MainThread]: command return code=128
[0m09:38:14.285733 [debug] [MainThread]: Updating existing dependency 2866b3ab007d7c145b466af137a6d251.
[0m09:38:14.285907 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:14.298831 [debug] [MainThread]: STDOUT: "b'31b38c2b4da1a44848263cc53572dcaf64567016\n'"
[0m09:38:14.299258 [debug] [MainThread]: STDERR: "b''"
[0m09:38:14.299422 [debug] [MainThread]:   Checking out revision HEAD.
[0m09:38:14.299545 [debug] [MainThread]: Executing "git remote set-branches origin HEAD"
[0m09:38:14.311715 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:14.312065 [debug] [MainThread]: STDERR: "b''"
[0m09:38:14.312144 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags HEAD"
[0m09:38:16.022590 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:16.023136 [debug] [MainThread]: STDERR: "b'From github.com:rittmananalytics/wire_jira\n * branch            HEAD       -> FETCH_HEAD\n'"
[0m09:38:16.023312 [debug] [MainThread]: Executing "git tag --list"
[0m09:38:16.038667 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:16.039081 [debug] [MainThread]: STDERR: "b''"
[0m09:38:16.039236 [debug] [MainThread]: Executing "git reset --hard origin/HEAD"
[0m09:38:16.056816 [debug] [MainThread]: STDOUT: "b'HEAD is now at 31b38c2 Merge pull request #2 from rittmananalytics/wire_jira_dev/0.1.2\n'"
[0m09:38:16.057289 [debug] [MainThread]: STDERR: "b''"
[0m09:38:16.057458 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:16.073070 [debug] [MainThread]: STDOUT: "b'31b38c2b4da1a44848263cc53572dcaf64567016\n'"
[0m09:38:16.073550 [debug] [MainThread]: STDERR: "b''"
[0m09:38:16.073716 [debug] [MainThread]: Already at 31b38c2, nothing to do.
[0m09:38:16.074030 [info ] [MainThread]:   Installed from HEAD (default revision)
[0m09:38:16.074418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '69b8f2bc-a35a-464f-87d1-935ab6f86e0f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103570730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103570700>]}
[0m09:38:16.074732 [info ] [MainThread]: Installing git@github.com:rittmananalytics/wire_harvest.git
[0m09:38:16.074942 [debug] [MainThread]: Executing "git clone --depth 1 git@github.com:rittmananalytics/wire_harvest.git dd7d8beded6f5f5357bdaba65e154e7c"
[0m09:38:16.087141 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:16.087509 [debug] [MainThread]: STDERR: "b"fatal: destination path 'dd7d8beded6f5f5357bdaba65e154e7c' already exists and is not an empty directory.\n""
[0m09:38:16.087591 [debug] [MainThread]: command return code=128
[0m09:38:16.088134 [debug] [MainThread]: Updating existing dependency dd7d8beded6f5f5357bdaba65e154e7c.
[0m09:38:16.088226 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:16.100532 [debug] [MainThread]: STDOUT: "b'bf812d8c425816b8417474e5ff0e9f7f53dab7f6\n'"
[0m09:38:16.101061 [debug] [MainThread]: STDERR: "b''"
[0m09:38:16.101196 [debug] [MainThread]:   Checking out revision harvest_dev/0.1.1.
[0m09:38:16.101310 [debug] [MainThread]: Executing "git remote set-branches origin harvest_dev/0.1.1"
[0m09:38:16.114768 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:16.115114 [debug] [MainThread]: STDERR: "b''"
[0m09:38:16.115196 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags harvest_dev/0.1.1"
[0m09:38:17.801383 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:17.809923 [debug] [MainThread]: STDERR: "b'From github.com:rittmananalytics/wire_harvest\n * branch            harvest_dev/0.1.1 -> FETCH_HEAD\n'"
[0m09:38:17.810424 [debug] [MainThread]: Executing "git tag --list"
[0m09:38:17.841948 [debug] [MainThread]: STDOUT: "b''"
[0m09:38:17.842581 [debug] [MainThread]: STDERR: "b''"
[0m09:38:17.842768 [debug] [MainThread]: Executing "git reset --hard origin/harvest_dev/0.1.1"
[0m09:38:17.857177 [debug] [MainThread]: STDOUT: "b'HEAD is now at bf812d8 harvest invoices xa fix\n'"
[0m09:38:17.857537 [debug] [MainThread]: STDERR: "b''"
[0m09:38:17.857644 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m09:38:17.869827 [debug] [MainThread]: STDOUT: "b'bf812d8c425816b8417474e5ff0e9f7f53dab7f6\n'"
[0m09:38:17.870245 [debug] [MainThread]: STDERR: "b''"
[0m09:38:17.870351 [debug] [MainThread]: Already at bf812d8, nothing to do.
[0m09:38:17.870644 [info ] [MainThread]:   Installed from revision harvest_dev/0.1.1
[0m09:38:17.871011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '69b8f2bc-a35a-464f-87d1-935ab6f86e0f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1035719d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103571130>]}
[0m09:38:17.871267 [info ] [MainThread]: Installing dbt-labs/audit_helper
[0m09:38:18.079174 [info ] [MainThread]:   Installed from version 0.7.0
[0m09:38:18.079679 [info ] [MainThread]:   Up to date!
[0m09:38:18.080086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '69b8f2bc-a35a-464f-87d1-935ab6f86e0f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103571520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103571b80>]}
[0m09:38:18.080249 [info ] [MainThread]: Installing fivetran/jira
[0m09:38:18.482939 [info ] [MainThread]:   Installed from version 0.12.2
[0m09:38:18.483211 [info ] [MainThread]:   Up to date!
[0m09:38:18.483454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '69b8f2bc-a35a-464f-87d1-935ab6f86e0f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103540820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1035400d0>]}
[0m09:38:18.483638 [info ] [MainThread]: Installing fivetran/jira_source
[0m09:38:18.888224 [info ] [MainThread]:   Installed from version 0.6.1
[0m09:38:18.888543 [info ] [MainThread]:   Up to date!
[0m09:38:18.888797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '69b8f2bc-a35a-464f-87d1-935ab6f86e0f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103540e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103540cd0>]}
[0m09:38:18.889003 [info ] [MainThread]: Installing dbt-labs/spark_utils
[0m09:38:19.093439 [info ] [MainThread]:   Installed from version 0.3.0
[0m09:38:19.093999 [info ] [MainThread]:   Up to date!
[0m09:38:19.094483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '69b8f2bc-a35a-464f-87d1-935ab6f86e0f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103540610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103540520>]}
[0m09:38:19.094946 [info ] [MainThread]: 
[0m09:38:19.095377 [info ] [MainThread]: Updates available for packages: ['fivetran/fivetran_utils']                 
Update your versions in packages.yml, then run dbt deps
[0m09:38:19.098327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034c6190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1035406d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103540cd0>]}
[0m09:38:19.098942 [debug] [MainThread]: Flushing usage events


============================== 2023-03-03 09:38:21.959502 | c56e1cb2-a929-475b-a37a-fe1fd5478edd ==============================
[0m09:38:21.959538 [info ] [MainThread]: Running with dbt=1.3.3
[0m09:38:21.960067 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/lewischarlesbaker/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'target': 'dev', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m09:38:21.960221 [debug] [MainThread]: Tracking: tracking
[0m09:38:21.980550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126a4f940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126a4fa60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126a4fa90>]}
[0m09:38:22.061242 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
[0m09:38:22.061445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126a2d430>]}
[0m09:38:22.186654 [debug] [MainThread]: Parsing macros/etc.sql
[0m09:38:22.187827 [debug] [MainThread]: Parsing macros/catalog.sql
[0m09:38:22.191857 [debug] [MainThread]: Parsing macros/adapters.sql
[0m09:38:22.204276 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m09:38:22.205684 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m09:38:22.207226 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m09:38:22.215030 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m09:38:22.216640 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m09:38:22.226491 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m09:38:22.227391 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m09:38:22.227579 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m09:38:22.227895 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m09:38:22.228435 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m09:38:22.228619 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m09:38:22.228886 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m09:38:22.229200 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m09:38:22.229710 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m09:38:22.230335 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m09:38:22.230577 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m09:38:22.230814 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m09:38:22.231071 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m09:38:22.231317 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m09:38:22.231519 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m09:38:22.232286 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m09:38:22.232542 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m09:38:22.232948 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m09:38:22.233296 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m09:38:22.234836 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m09:38:22.237236 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m09:38:22.238570 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m09:38:22.239453 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m09:38:22.248423 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m09:38:22.256490 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m09:38:22.263539 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m09:38:22.265857 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m09:38:22.266829 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m09:38:22.267747 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m09:38:22.272027 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m09:38:22.281740 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m09:38:22.282607 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m09:38:22.286121 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m09:38:22.291866 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m09:38:22.302240 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m09:38:22.305585 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m09:38:22.307430 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m09:38:22.310352 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m09:38:22.311004 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m09:38:22.312779 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m09:38:22.314027 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m09:38:22.318462 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m09:38:22.330099 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m09:38:22.330922 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m09:38:22.332150 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m09:38:22.332962 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m09:38:22.333432 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m09:38:22.333830 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m09:38:22.334164 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m09:38:22.334981 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m09:38:22.337842 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m09:38:22.342359 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m09:38:22.342763 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m09:38:22.343389 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m09:38:22.343854 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m09:38:22.344322 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m09:38:22.344930 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m09:38:22.345336 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m09:38:22.345908 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m09:38:22.346602 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m09:38:22.347822 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m09:38:22.348419 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m09:38:22.348927 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m09:38:22.349464 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m09:38:22.349957 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m09:38:22.350393 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m09:38:22.350909 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m09:38:22.351409 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m09:38:22.355083 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m09:38:22.355755 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m09:38:22.356267 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m09:38:22.357267 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m09:38:22.358652 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m09:38:22.359150 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m09:38:22.359891 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m09:38:22.360421 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m09:38:22.361481 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m09:38:22.363164 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m09:38:22.364645 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m09:38:22.372914 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m09:38:22.373955 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m09:38:22.380973 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m09:38:22.383220 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m09:38:22.387441 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m09:38:22.392812 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m09:38:22.396422 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m09:38:22.398114 [debug] [MainThread]: Parsing macros/web/get_url_host.sql
[0m09:38:22.399209 [debug] [MainThread]: Parsing macros/web/get_url_path.sql
[0m09:38:22.400638 [debug] [MainThread]: Parsing macros/web/get_url_parameter.sql
[0m09:38:22.401391 [debug] [MainThread]: Parsing macros/generic_tests/fewer_rows_than.sql
[0m09:38:22.403966 [debug] [MainThread]: Parsing macros/generic_tests/equal_rowcount.sql
[0m09:38:22.406297 [debug] [MainThread]: Parsing macros/generic_tests/relationships_where.sql
[0m09:38:22.407508 [debug] [MainThread]: Parsing macros/generic_tests/recency.sql
[0m09:38:22.409303 [debug] [MainThread]: Parsing macros/generic_tests/not_constant.sql
[0m09:38:22.410366 [debug] [MainThread]: Parsing macros/generic_tests/accepted_range.sql
[0m09:38:22.411606 [debug] [MainThread]: Parsing macros/generic_tests/not_accepted_values.sql
[0m09:38:22.412735 [debug] [MainThread]: Parsing macros/generic_tests/at_least_one.sql
[0m09:38:22.414045 [debug] [MainThread]: Parsing macros/generic_tests/unique_combination_of_columns.sql
[0m09:38:22.415568 [debug] [MainThread]: Parsing macros/generic_tests/cardinality_equality.sql
[0m09:38:22.416642 [debug] [MainThread]: Parsing macros/generic_tests/expression_is_true.sql
[0m09:38:22.417604 [debug] [MainThread]: Parsing macros/generic_tests/not_null_proportion.sql
[0m09:38:22.419335 [debug] [MainThread]: Parsing macros/generic_tests/sequential_values.sql
[0m09:38:22.421409 [debug] [MainThread]: Parsing macros/generic_tests/equality.sql
[0m09:38:22.423239 [debug] [MainThread]: Parsing macros/generic_tests/not_empty_string.sql
[0m09:38:22.424202 [debug] [MainThread]: Parsing macros/generic_tests/mutually_exclusive_ranges.sql
[0m09:38:22.429859 [debug] [MainThread]: Parsing macros/jinja_helpers/pretty_log_format.sql
[0m09:38:22.430410 [debug] [MainThread]: Parsing macros/jinja_helpers/_is_relation.sql
[0m09:38:22.430964 [debug] [MainThread]: Parsing macros/jinja_helpers/pretty_time.sql
[0m09:38:22.431561 [debug] [MainThread]: Parsing macros/jinja_helpers/log_info.sql
[0m09:38:22.432210 [debug] [MainThread]: Parsing macros/jinja_helpers/slugify.sql
[0m09:38:22.433063 [debug] [MainThread]: Parsing macros/jinja_helpers/_is_ephemeral.sql
[0m09:38:22.434279 [debug] [MainThread]: Parsing macros/sql/date_spine.sql
[0m09:38:22.436856 [debug] [MainThread]: Parsing macros/sql/nullcheck_table.sql
[0m09:38:22.437894 [debug] [MainThread]: Parsing macros/sql/get_relations_by_pattern.sql
[0m09:38:22.439812 [debug] [MainThread]: Parsing macros/sql/generate_series.sql
[0m09:38:22.442052 [debug] [MainThread]: Parsing macros/sql/get_relations_by_prefix.sql
[0m09:38:22.443864 [debug] [MainThread]: Parsing macros/sql/get_tables_by_prefix_sql.sql
[0m09:38:22.444741 [debug] [MainThread]: Parsing macros/sql/star.sql
[0m09:38:22.447832 [debug] [MainThread]: Parsing macros/sql/unpivot.sql
[0m09:38:22.451287 [debug] [MainThread]: Parsing macros/sql/safe_divide.sql
[0m09:38:22.451843 [debug] [MainThread]: Parsing macros/sql/union.sql
[0m09:38:22.459583 [debug] [MainThread]: Parsing macros/sql/groupby.sql
[0m09:38:22.460330 [debug] [MainThread]: Parsing macros/sql/deduplicate.sql
[0m09:38:22.462240 [debug] [MainThread]: Parsing macros/sql/surrogate_key.sql
[0m09:38:22.462990 [debug] [MainThread]: Parsing macros/sql/safe_add.sql
[0m09:38:22.464086 [debug] [MainThread]: Parsing macros/sql/nullcheck.sql
[0m09:38:22.464916 [debug] [MainThread]: Parsing macros/sql/get_tables_by_pattern_sql.sql
[0m09:38:22.469205 [debug] [MainThread]: Parsing macros/sql/get_column_values.sql
[0m09:38:22.472562 [debug] [MainThread]: Parsing macros/sql/pivot.sql
[0m09:38:22.474935 [debug] [MainThread]: Parsing macros/sql/get_filtered_columns_in_relation.sql
[0m09:38:22.476429 [debug] [MainThread]: Parsing macros/sql/width_bucket.sql
[0m09:38:22.479492 [debug] [MainThread]: Parsing macros/sql/get_query_results_as_dict.sql
[0m09:38:22.480677 [debug] [MainThread]: Parsing macros/sql/generate_surrogate_key.sql
[0m09:38:22.482064 [debug] [MainThread]: Parsing macros/sql/get_table_types_sql.sql
[0m09:38:22.482894 [debug] [MainThread]: Parsing macros/sql/get_single_value.sql
[0m09:38:22.484662 [debug] [MainThread]: Parsing macros/sql/haversine_distance.sql
[0m09:38:22.487816 [debug] [MainThread]: Parsing macros/compare_relations.sql
[0m09:38:22.488987 [debug] [MainThread]: Parsing macros/compare_all_columns.sql
[0m09:38:22.491808 [debug] [MainThread]: Parsing macros/compare_column_values_verbose.sql
[0m09:38:22.494203 [debug] [MainThread]: Parsing macros/compare_column_values.sql
[0m09:38:22.498947 [debug] [MainThread]: Parsing macros/compare_queries.sql
[0m09:38:22.500438 [debug] [MainThread]: Parsing macros/compare_relation_columns.sql
[0m09:38:22.503845 [debug] [MainThread]: Parsing macros/fetch_configured_models.sql
[0m09:38:22.508189 [debug] [MainThread]: Parsing macros/required_tests.sql
[0m09:38:22.510376 [debug] [MainThread]: Parsing macros/required_docs.sql
[0m09:38:22.512402 [debug] [MainThread]: Parsing macros/logger.sql
[0m09:38:22.514241 [debug] [MainThread]: Parsing macros/utils/_get_meta_tests_namespace.sql
[0m09:38:22.514686 [debug] [MainThread]: Parsing macros/utils/required_docs/validate_required_docs.sql
[0m09:38:22.515617 [debug] [MainThread]: Parsing macros/utils/required_docs/evaluate_required_docs.sql
[0m09:38:22.520262 [debug] [MainThread]: Parsing macros/utils/formatters/format_raise_error.sql
[0m09:38:22.521047 [debug] [MainThread]: Parsing macros/utils/formatters/format_error_tests.sql
[0m09:38:22.522150 [debug] [MainThread]: Parsing macros/utils/formatters/format_error_docs.sql
[0m09:38:22.523470 [debug] [MainThread]: Parsing macros/utils/required_tests/evaluate_required_tests.sql
[0m09:38:22.525522 [debug] [MainThread]: Parsing macros/utils/required_tests/validate_required_tests.sql
[0m09:38:22.528234 [debug] [MainThread]: Parsing macros/utils/required_tests/get_regex_match_count.sql
[0m09:38:22.529181 [debug] [MainThread]: Parsing macros/utils/required_tests/tests_per_model.sql
[0m09:38:22.530972 [debug] [MainThread]: Parsing macros/utils/errors/error_required_docs.sql
[0m09:38:22.532655 [debug] [MainThread]: Parsing macros/utils/errors/error_invalid_config_docs.sql
[0m09:38:22.533395 [debug] [MainThread]: Parsing macros/utils/errors/error_required_tests.sql
[0m09:38:22.534053 [debug] [MainThread]: Parsing macros/utils/errors/error_invalid_config_tests.sql
[0m09:38:22.534697 [debug] [MainThread]: Parsing macros/maintenance_operation.sql
[0m09:38:22.545507 [debug] [MainThread]: Parsing macros/dbt_utils/cross_db_utils/concat.sql
[0m09:38:22.545852 [debug] [MainThread]: Parsing macros/dbt_utils/cross_db_utils/datatypes.sql
[0m09:38:22.546063 [debug] [MainThread]: Parsing macros/dbt_utils/cross_db_utils/dateadd.sql
[0m09:38:22.549644 [debug] [MainThread]: Parsing macros/dbt_utils/cross_db_utils/datediff.sql
[0m09:38:22.558636 [debug] [MainThread]: Parsing macros/dbt_utils/cross_db_utils/current_timestamp.sql
[0m09:38:22.559002 [debug] [MainThread]: Parsing macros/dbt_utils/cross_db_utils/split_part.sql
[0m09:38:22.559717 [debug] [MainThread]: Parsing macros/dbt_utils/sql/get_relations_by_prefix.sql
[0m09:38:22.562540 [debug] [MainThread]: Parsing macros/etc/assert_not_null.sql
[0m09:38:22.563197 [debug] [MainThread]: Parsing macros/snowplow/convert_timezone.sql
[0m09:38:22.563545 [debug] [MainThread]: Parsing macros/query_to_list.sql
[0m09:38:22.564242 [debug] [MainThread]: Parsing macros/inject_regression_logic.sql
[0m09:38:22.566050 [debug] [MainThread]: Parsing macros/results_values.sql
[0m09:38:22.567169 [debug] [MainThread]: Parsing macros/profile_schema.sql
[0m09:38:22.569875 [debug] [MainThread]: Parsing macros/generate_schema_name.sql
[0m09:38:22.571199 [debug] [MainThread]: Parsing macros/enabled_vars.sql
[0m09:38:22.571691 [debug] [MainThread]: Parsing macros/percentile.sql
[0m09:38:22.573835 [debug] [MainThread]: Parsing macros/pivot_json_extract.sql
[0m09:38:22.574765 [debug] [MainThread]: Parsing macros/persist_pass_through_columns.sql
[0m09:38:22.575524 [debug] [MainThread]: Parsing macros/json_parse.sql
[0m09:38:22.578482 [debug] [MainThread]: Parsing macros/max_bool.sql
[0m09:38:22.579231 [debug] [MainThread]: Parsing macros/calculated_fields.sql
[0m09:38:22.579692 [debug] [MainThread]: Parsing macros/seed_data_helper.sql
[0m09:38:22.580484 [debug] [MainThread]: Parsing macros/fill_pass_through_columns.sql
[0m09:38:22.581422 [debug] [MainThread]: Parsing macros/string_agg.sql
[0m09:38:22.582568 [debug] [MainThread]: Parsing macros/timestamp_diff.sql
[0m09:38:22.588764 [debug] [MainThread]: Parsing macros/try_cast.sql
[0m09:38:22.591209 [debug] [MainThread]: Parsing macros/source_relation.sql
[0m09:38:22.592516 [debug] [MainThread]: Parsing macros/first_value.sql
[0m09:38:22.593684 [debug] [MainThread]: Parsing macros/add_dbt_source_relation.sql
[0m09:38:22.594067 [debug] [MainThread]: Parsing macros/add_pass_through_columns.sql
[0m09:38:22.595413 [debug] [MainThread]: Parsing macros/union_relations.sql
[0m09:38:22.600726 [debug] [MainThread]: Parsing macros/snowflake_seed_data.sql
[0m09:38:22.601311 [debug] [MainThread]: Parsing macros/fill_staging_columns.sql
[0m09:38:22.603865 [debug] [MainThread]: Parsing macros/json_extract.sql
[0m09:38:22.605477 [debug] [MainThread]: Parsing macros/collect_freshness.sql
[0m09:38:22.607436 [debug] [MainThread]: Parsing macros/timestamp_add.sql
[0m09:38:22.609178 [debug] [MainThread]: Parsing macros/ceiling.sql
[0m09:38:22.609813 [debug] [MainThread]: Parsing macros/remove_prefix_from_columns.sql
[0m09:38:22.610561 [debug] [MainThread]: Parsing macros/union_data.sql
[0m09:38:22.614870 [debug] [MainThread]: Parsing macros/dummy_coalesce_value.sql
[0m09:38:22.616554 [debug] [MainThread]: Parsing macros/array_agg.sql
[0m09:38:22.617135 [debug] [MainThread]: Parsing macros/empty_variable_warning.sql
[0m09:38:22.617638 [debug] [MainThread]: Parsing macros/enabled_vars_one_true.sql
[0m09:38:22.618124 [debug] [MainThread]: Parsing macros/query_to_list.sql
[0m09:38:22.618743 [debug] [MainThread]: Parsing macros/inject_regression_logic.sql
[0m09:38:22.620605 [debug] [MainThread]: Parsing macros/profile_schema.sql
[0m09:38:22.623222 [debug] [MainThread]: Parsing macros/wire_results_values.sql
[0m09:38:22.624385 [debug] [MainThread]: Parsing macros/generate_schema_name.sql
[0m09:38:22.625689 [debug] [MainThread]: Parsing macros/get_issue_link_columns.sql
[0m09:38:22.626554 [debug] [MainThread]: Parsing macros/get_issue_columns.sql
[0m09:38:22.630473 [debug] [MainThread]: Parsing macros/get_status_columns.sql
[0m09:38:22.631345 [debug] [MainThread]: Parsing macros/get_status_category_columns.sql
[0m09:38:22.631944 [debug] [MainThread]: Parsing macros/get_issue_field_history_columns.sql
[0m09:38:22.633400 [debug] [MainThread]: Parsing macros/get_comment_columns.sql
[0m09:38:22.634642 [debug] [MainThread]: Parsing macros/get_field_columns.sql
[0m09:38:22.635461 [debug] [MainThread]: Parsing macros/get_version_columns.sql
[0m09:38:22.636846 [debug] [MainThread]: Parsing macros/get_field_option_columns.sql
[0m09:38:22.637625 [debug] [MainThread]: Parsing macros/get_issue_multiselect_history_columns.sql
[0m09:38:22.639249 [debug] [MainThread]: Parsing macros/get_epic_columns.sql
[0m09:38:22.640215 [debug] [MainThread]: Parsing macros/get_issue_type_columns.sql
[0m09:38:22.641016 [debug] [MainThread]: Parsing macros/get_user_columns.sql
[0m09:38:22.642038 [debug] [MainThread]: Parsing macros/get_project_columns.sql
[0m09:38:22.643242 [debug] [MainThread]: Parsing macros/get_resolution_columns.sql
[0m09:38:22.643938 [debug] [MainThread]: Parsing macros/get_component_columns.sql
[0m09:38:22.644735 [debug] [MainThread]: Parsing macros/get_priority_columns.sql
[0m09:38:22.645434 [debug] [MainThread]: Parsing macros/get_sprint_columns.sql
[0m09:38:22.967424 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__issue_board.sql
[0m09:38:22.976004 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__issue_board.sql
[0m09:38:22.976870 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__fields.sql
[0m09:38:22.979785 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__fields.sql
[0m09:38:22.980463 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__issues.sql
[0m09:38:22.983165 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__issues.sql
[0m09:38:22.983791 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__epics.sql
[0m09:38:22.987254 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__epics.sql
[0m09:38:22.987972 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__boards.sql
[0m09:38:22.990734 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__boards.sql
[0m09:38:22.991388 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__users.sql
[0m09:38:22.994317 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__users.sql
[0m09:38:22.995002 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__issues_field_history.sql
[0m09:38:22.997757 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__issues_field_history.sql
[0m09:38:22.998429 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__sprints.sql
[0m09:38:23.001272 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__sprints.sql
[0m09:38:23.002136 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__statuses.sql
[0m09:38:23.006564 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__statuses.sql
[0m09:38:23.007343 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__project_board.sql
[0m09:38:23.010501 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__project_board.sql
[0m09:38:23.011259 [debug] [MainThread]: 1603: static parser failed on staging/stg_jira/stg_jira__projects.sql
[0m09:38:23.014406 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_jira/stg_jira__projects.sql
[0m09:38:23.015643 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_jira/int_jira__sprints.sql
[0m09:38:23.017232 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_jira/int_jira__projects.sql
[0m09:38:23.018787 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_jira/int_jira__epics.sql
[0m09:38:23.020513 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_jira/int_jira__users.sql
[0m09:38:23.022298 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_jira/int_jira__issues.sql
[0m09:38:23.023862 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_jira/int_jira__daily_issue_field_history.sql
[0m09:38:23.025488 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_jira/int_jira__fields.sql
[0m09:38:23.028467 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_jira/int_jira__issues_field_history.sql
[0m09:38:23.030012 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_jira/intermediate/int_jira_intermediate__issues.sql
[0m09:38:23.034254 [debug] [MainThread]: 1603: static parser failed on integration/int_jira/intermediate/int_jira_intermediate__issues_pivot.sql
[0m09:38:23.047257 [debug] [MainThread]: 1602: parser fallback to jinja rendering on integration/int_jira/intermediate/int_jira_intermediate__issues_pivot.sql
[0m09:38:23.049291 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_jira/intermediate/int_jira__boards.sql
[0m09:38:23.051165 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_issues_xa.sql
[0m09:38:23.063303 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_issues_xa.sql
[0m09:38:23.064136 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_issues_board_bridge.sql
[0m09:38:23.069757 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_issues_board_bridge.sql
[0m09:38:23.070471 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_sprints_dim.sql
[0m09:38:23.074847 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_sprints_dim.sql
[0m09:38:23.075530 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_fields_dim.sql
[0m09:38:23.079336 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_fields_dim.sql
[0m09:38:23.080216 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_daily_issue_field_history_fact.sql
[0m09:38:23.085832 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_daily_issue_field_history_fact.sql
[0m09:38:23.086792 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_issues_sprint_bridge.sql
[0m09:38:23.092807 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_issues_sprint_bridge.sql
[0m09:38:23.093606 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_projects_fact.sql
[0m09:38:23.098413 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_projects_fact.sql
[0m09:38:23.099153 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_epics_dim.sql
[0m09:38:23.102846 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_epics_dim.sql
[0m09:38:23.103570 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_users_dim.sql
[0m09:38:23.107359 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_users_dim.sql
[0m09:38:23.108185 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_issues_fact.sql
[0m09:38:23.119679 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_issues_fact.sql
[0m09:38:23.120557 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__jira_issues_field_history_fact.sql
[0m09:38:23.126505 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__jira_issues_field_history_fact.sql
[0m09:38:23.349324 [debug] [MainThread]: 1603: static parser failed on jira__daily_issue_field_history.sql
[0m09:38:23.364321 [debug] [MainThread]: 1602: parser fallback to jinja rendering on jira__daily_issue_field_history.sql
[0m09:38:23.365140 [debug] [MainThread]: 1603: static parser failed on jira__user_enhanced.sql
[0m09:38:23.370617 [debug] [MainThread]: 1602: parser fallback to jinja rendering on jira__user_enhanced.sql
[0m09:38:23.371574 [debug] [MainThread]: 1603: static parser failed on jira__issue_enhanced.sql
[0m09:38:23.381697 [debug] [MainThread]: 1602: parser fallback to jinja rendering on jira__issue_enhanced.sql
[0m09:38:23.382449 [debug] [MainThread]: 1603: static parser failed on jira__project_enhanced.sql
[0m09:38:23.388119 [debug] [MainThread]: 1602: parser fallback to jinja rendering on jira__project_enhanced.sql
[0m09:38:23.388896 [debug] [MainThread]: 1603: static parser failed on intermediate/int_jira__issue_type_parents.sql
[0m09:38:23.392710 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/int_jira__issue_type_parents.sql
[0m09:38:23.393431 [debug] [MainThread]: 1603: static parser failed on intermediate/int_jira__issue_epic.sql
[0m09:38:23.398212 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/int_jira__issue_epic.sql
[0m09:38:23.398965 [debug] [MainThread]: 1603: static parser failed on intermediate/int_jira__user_metrics.sql
[0m09:38:23.408255 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/int_jira__user_metrics.sql
[0m09:38:23.409185 [debug] [MainThread]: 1603: static parser failed on intermediate/int_jira__issue_join.sql
[0m09:38:23.418791 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/int_jira__issue_join.sql
[0m09:38:23.419539 [debug] [MainThread]: 1699: static parser successfully parsed intermediate/int_jira__issue_assign_resolution.sql
[0m09:38:23.421064 [debug] [MainThread]: 1603: static parser failed on intermediate/int_jira__issue_versions.sql
[0m09:38:23.425285 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/int_jira__issue_versions.sql
[0m09:38:23.425947 [debug] [MainThread]: 1603: static parser failed on intermediate/int_jira__issue_users.sql
[0m09:38:23.439092 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/int_jira__issue_users.sql
[0m09:38:23.439849 [debug] [MainThread]: 1603: static parser failed on intermediate/int_jira__issue_sprint.sql
[0m09:38:23.444144 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/int_jira__issue_sprint.sql
[0m09:38:23.444980 [debug] [MainThread]: 1603: static parser failed on intermediate/int_jira__issue_comments.sql
[0m09:38:23.449525 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/int_jira__issue_comments.sql
[0m09:38:23.450418 [debug] [MainThread]: 1603: static parser failed on intermediate/int_jira__project_metrics.sql
[0m09:38:23.459602 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/int_jira__project_metrics.sql
[0m09:38:23.460375 [debug] [MainThread]: 1603: static parser failed on intermediate/field_history/int_jira__issue_multiselect_history.sql
[0m09:38:23.463956 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/field_history/int_jira__issue_multiselect_history.sql
[0m09:38:23.464760 [debug] [MainThread]: 1603: static parser failed on intermediate/field_history/int_jira__pivot_daily_field_history.sql
[0m09:38:23.471089 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/field_history/int_jira__pivot_daily_field_history.sql
[0m09:38:23.471880 [debug] [MainThread]: 1603: static parser failed on intermediate/field_history/int_jira__issue_calendar_spine.sql
[0m09:38:23.496686 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/field_history/int_jira__issue_calendar_spine.sql
[0m09:38:23.497574 [debug] [MainThread]: 1603: static parser failed on intermediate/field_history/int_jira__agg_multiselect_history.sql
[0m09:38:23.503704 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/field_history/int_jira__agg_multiselect_history.sql
[0m09:38:23.504639 [debug] [MainThread]: 1603: static parser failed on intermediate/field_history/int_jira__field_history_scd.sql
[0m09:38:23.509582 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/field_history/int_jira__field_history_scd.sql
[0m09:38:23.510339 [debug] [MainThread]: 1603: static parser failed on intermediate/field_history/int_jira__combine_field_histories.sql
[0m09:38:23.516098 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/field_history/int_jira__combine_field_histories.sql
[0m09:38:23.516973 [debug] [MainThread]: 1603: static parser failed on intermediate/field_history/int_jira__issue_field_history.sql
[0m09:38:23.520331 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/field_history/int_jira__issue_field_history.sql
[0m09:38:23.521220 [debug] [MainThread]: 1603: static parser failed on intermediate/field_history/int_jira__daily_field_history.sql
[0m09:38:23.527705 [debug] [MainThread]: 1602: parser fallback to jinja rendering on intermediate/field_history/int_jira__daily_field_history.sql
[0m09:38:23.535312 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__clients.sql
[0m09:38:23.540115 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__clients.sql
[0m09:38:23.540828 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__invoice_line_items.sql
[0m09:38:23.544532 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__invoice_line_items.sql
[0m09:38:23.545227 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__projects.sql
[0m09:38:23.596408 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__projects.sql
[0m09:38:23.597149 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__roles.sql
[0m09:38:23.599894 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__roles.sql
[0m09:38:23.600565 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__time_sheet_external_reference.sql
[0m09:38:23.603606 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__time_sheet_external_reference.sql
[0m09:38:23.604458 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__tasks.sql
[0m09:38:23.608290 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__tasks.sql
[0m09:38:23.609069 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__time_sheets.sql
[0m09:38:23.613955 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__time_sheets.sql
[0m09:38:23.614697 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__project_users.sql
[0m09:38:23.618417 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__project_users.sql
[0m09:38:23.619160 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__employee.sql
[0m09:38:23.622402 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__employee.sql
[0m09:38:23.623250 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__projects_tasks.sql
[0m09:38:23.626046 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__projects_tasks.sql
[0m09:38:23.626789 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__expenses.sql
[0m09:38:23.630055 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__expenses.sql
[0m09:38:23.630724 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__employee_roles.sql
[0m09:38:23.633488 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__employee_roles.sql
[0m09:38:23.634210 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__invoices.sql
[0m09:38:23.638599 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__invoices.sql
[0m09:38:23.639330 [debug] [MainThread]: 1603: static parser failed on staging/stg_harvest/stg_harvest__external_reference.sql
[0m09:38:23.642729 [debug] [MainThread]: 1602: parser fallback to jinja rendering on staging/stg_harvest/stg_harvest__external_reference.sql
[0m09:38:23.643545 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_harvest/int_harvest__invoice_line_items.sql
[0m09:38:23.645123 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_harvest/int_harvest__expenses.sql
[0m09:38:23.646765 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_harvest/int_harvest__invoices.sql
[0m09:38:23.648419 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_harvest/int_harvest__time_sheets.sql
[0m09:38:23.650044 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_harvest/int_harvest__clients.sql
[0m09:38:23.651516 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_harvest/int_harvest__projects.sql
[0m09:38:23.653317 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_harvest/int_harvest__employees.sql
[0m09:38:23.654815 [debug] [MainThread]: 1699: static parser successfully parsed integration/int_harvest/int_harvest__tasks.sql
[0m09:38:23.656298 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__harvest_clients_dim.sql
[0m09:38:23.660711 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__harvest_clients_dim.sql
[0m09:38:23.661606 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__harvest_invoice_line_items_fact.sql
[0m09:38:23.667250 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__harvest_invoice_line_items_fact.sql
[0m09:38:23.667972 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__harvest_time_sheets_fact.sql
[0m09:38:23.674777 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__harvest_time_sheets_fact.sql
[0m09:38:23.675558 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__harvest_projects_fact.sql
[0m09:38:23.680225 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__harvest_projects_fact.sql
[0m09:38:23.680937 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__harvest_expenses_fact.sql
[0m09:38:23.688575 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__harvest_expenses_fact.sql
[0m09:38:23.689366 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__harvest_employees_dim.sql
[0m09:38:23.693698 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__harvest_employees_dim.sql
[0m09:38:23.694500 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__harvest_invoices_xa.sql
[0m09:38:23.700319 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__harvest_invoices_xa.sql
[0m09:38:23.701015 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__harvest_tasks_dim.sql
[0m09:38:23.704665 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__harvest_tasks_dim.sql
[0m09:38:23.705385 [debug] [MainThread]: 1603: static parser failed on warehouse/wh_delivery/wh_delivery__harvest_invoices_fact.sql
[0m09:38:23.710912 [debug] [MainThread]: 1602: parser fallback to jinja rendering on warehouse/wh_delivery/wh_delivery__harvest_invoices_fact.sql
[0m09:38:23.904958 [debug] [MainThread]: 1603: static parser failed on stg_jira__comment.sql
[0m09:38:23.919568 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__comment.sql
[0m09:38:23.920278 [debug] [MainThread]: 1603: static parser failed on stg_jira__project.sql
[0m09:38:23.927556 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__project.sql
[0m09:38:23.928273 [debug] [MainThread]: 1603: static parser failed on stg_jira__issue_field_history.sql
[0m09:38:23.937885 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__issue_field_history.sql
[0m09:38:23.938772 [debug] [MainThread]: 1603: static parser failed on stg_jira__version.sql
[0m09:38:23.946139 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__version.sql
[0m09:38:23.946883 [debug] [MainThread]: 1603: static parser failed on stg_jira__sprint.sql
[0m09:38:23.955261 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__sprint.sql
[0m09:38:23.956029 [debug] [MainThread]: 1603: static parser failed on stg_jira__field_option.sql
[0m09:38:23.961769 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__field_option.sql
[0m09:38:23.962474 [debug] [MainThread]: 1603: static parser failed on stg_jira__field.sql
[0m09:38:23.968607 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__field.sql
[0m09:38:23.969347 [debug] [MainThread]: 1603: static parser failed on stg_jira__resolution.sql
[0m09:38:23.975158 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__resolution.sql
[0m09:38:23.975879 [debug] [MainThread]: 1603: static parser failed on stg_jira__status.sql
[0m09:38:23.982309 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__status.sql
[0m09:38:23.983196 [debug] [MainThread]: 1603: static parser failed on stg_jira__issue.sql
[0m09:38:24.001479 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__issue.sql
[0m09:38:24.002201 [debug] [MainThread]: 1603: static parser failed on stg_jira__status_category.sql
[0m09:38:24.007246 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__status_category.sql
[0m09:38:24.007905 [debug] [MainThread]: 1603: static parser failed on stg_jira__issue_multiselect_history.sql
[0m09:38:24.016356 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__issue_multiselect_history.sql
[0m09:38:24.016966 [debug] [MainThread]: 1603: static parser failed on stg_jira__issue_type.sql
[0m09:38:24.022300 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__issue_type.sql
[0m09:38:24.023138 [debug] [MainThread]: 1603: static parser failed on stg_jira__issue_link.sql
[0m09:38:24.028988 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__issue_link.sql
[0m09:38:24.029764 [debug] [MainThread]: 1603: static parser failed on stg_jira__component.sql
[0m09:38:24.036897 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__component.sql
[0m09:38:24.037595 [debug] [MainThread]: 1603: static parser failed on stg_jira__user.sql
[0m09:38:24.044122 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__user.sql
[0m09:38:24.044758 [debug] [MainThread]: 1603: static parser failed on stg_jira__priority.sql
[0m09:38:24.050343 [debug] [MainThread]: 1602: parser fallback to jinja rendering on stg_jira__priority.sql
[0m09:38:24.051025 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__version_tmp.sql
[0m09:38:24.054109 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__version_tmp.sql
[0m09:38:24.054740 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__status_category_tmp.sql
[0m09:38:24.058965 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__status_category_tmp.sql
[0m09:38:24.059854 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__field_option_tmp.sql
[0m09:38:24.063277 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__field_option_tmp.sql
[0m09:38:24.064080 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__issue_multiselect_history_tmp.sql
[0m09:38:24.067299 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__issue_multiselect_history_tmp.sql
[0m09:38:24.067935 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__issue_type_tmp.sql
[0m09:38:24.070721 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__issue_type_tmp.sql
[0m09:38:24.071413 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__sprint_tmp.sql
[0m09:38:24.074652 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__sprint_tmp.sql
[0m09:38:24.075297 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__status_tmp.sql
[0m09:38:24.078835 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__status_tmp.sql
[0m09:38:24.079447 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__project_tmp.sql
[0m09:38:24.082246 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__project_tmp.sql
[0m09:38:24.082856 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__comment_tmp.sql
[0m09:38:24.085601 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__comment_tmp.sql
[0m09:38:24.086303 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__issue_field_history_tmp.sql
[0m09:38:24.089079 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__issue_field_history_tmp.sql
[0m09:38:24.089845 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__issue_link_tmp.sql
[0m09:38:24.093119 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__issue_link_tmp.sql
[0m09:38:24.093873 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__field_tmp.sql
[0m09:38:24.097164 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__field_tmp.sql
[0m09:38:24.098742 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__user_tmp.sql
[0m09:38:24.101917 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__user_tmp.sql
[0m09:38:24.102652 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__issue_tmp.sql
[0m09:38:24.105735 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__issue_tmp.sql
[0m09:38:24.106438 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__priority_tmp.sql
[0m09:38:24.109499 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__priority_tmp.sql
[0m09:38:24.110162 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__component_tmp.sql
[0m09:38:24.113190 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__component_tmp.sql
[0m09:38:24.113806 [debug] [MainThread]: 1603: static parser failed on tmp/stg_jira__resolution_tmp.sql
[0m09:38:24.116551 [debug] [MainThread]: 1602: parser fallback to jinja rendering on tmp/stg_jira__resolution_tmp.sql
[0m09:38:27.051633 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.ra_development.warehouse
- models.ra_development.integration
- models.ra_development.staging

[0m09:38:27.069295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1271e67c0>]}
[0m09:38:27.218272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1271b2a30>]}
[0m09:38:27.218549 [info ] [MainThread]: Found 120 models, 887 tests, 0 snapshots, 0 analyses, 611 macros, 0 operations, 0 seed files, 42 sources, 0 exposures, 0 metrics
[0m09:38:27.218694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12720aa90>]}
[0m09:38:27.232065 [info ] [MainThread]: 
[0m09:38:27.232512 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m09:38:27.236383 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development"
[0m09:38:27.236754 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development"
[0m09:38:27.237110 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development"
[0m09:38:27.237380 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development"
[0m09:38:27.237474 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:38:27.237759 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development"
[0m09:38:27.238090 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:38:27.238300 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development"
[0m09:38:27.238386 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:38:27.238509 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:38:27.238658 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:38:27.238816 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:38:29.266484 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development_lewis_analytics_dev_integration"
[0m09:38:29.267050 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development_lewis_analytics_dev_staging"
[0m09:38:29.267555 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development_lewis_analytics_dev_jira_source"
[0m09:38:29.267675 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:38:29.268162 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development_lewis_analytics_dev_jira"
[0m09:38:29.268296 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:38:29.268780 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development_lewis_analytics_dev_int_jira"
[0m09:38:29.268893 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:38:29.269277 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ra-development_lewis_analytics_dev"
[0m09:38:29.269503 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:38:29.269846 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:38:29.270093 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:38:29.578286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126fae6d0>]}
[0m09:38:29.578981 [info ] [MainThread]: Concurrency: 8 threads (target='dev')
[0m09:38:29.579185 [info ] [MainThread]: 
[0m09:38:29.586855 [debug] [Thread-1  ]: Began running node model.jira_source.stg_jira__comment_tmp
[0m09:38:29.587057 [debug] [Thread-2  ]: Began running node model.jira_source.stg_jira__component_tmp
[0m09:38:29.587191 [debug] [Thread-3  ]: Began running node model.jira_source.stg_jira__field_option_tmp
[0m09:38:29.587291 [debug] [Thread-4  ]: Began running node model.jira_source.stg_jira__field_tmp
[0m09:38:29.587468 [info ] [Thread-1  ]: 1 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__comment_tmp  [RUN]
[0m09:38:29.587573 [debug] [Thread-5  ]: Began running node model.jira_source.stg_jira__issue_field_history_tmp
[0m09:38:29.587734 [debug] [Thread-6  ]: Began running node model.jira_source.stg_jira__issue_link_tmp
[0m09:38:29.587850 [debug] [Thread-7  ]: Began running node model.jira_source.stg_jira__issue_multiselect_history_tmp
[0m09:38:29.587955 [debug] [Thread-8  ]: Began running node model.jira_source.stg_jira__issue_tmp
[0m09:38:29.588077 [info ] [Thread-2  ]: 2 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__component_tmp  [RUN]
[0m09:38:29.588245 [info ] [Thread-3  ]: 3 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__field_option_tmp  [RUN]
[0m09:38:29.588395 [info ] [Thread-4  ]: 4 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__field_tmp  [RUN]
[0m09:38:29.588917 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__comment_tmp"
[0m09:38:29.589038 [info ] [Thread-5  ]: 5 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__issue_field_history_tmp  [RUN]
[0m09:38:29.589190 [info ] [Thread-6  ]: 6 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__issue_link_tmp  [RUN]
[0m09:38:29.589325 [info ] [Thread-7  ]: 7 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__issue_multiselect_history_tmp  [RUN]
[0m09:38:29.589462 [info ] [Thread-8  ]: 8 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__issue_tmp  [RUN]
[0m09:38:29.589891 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__component_tmp"
[0m09:38:29.590306 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__field_option_tmp"
[0m09:38:29.590696 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__field_tmp"
[0m09:38:29.590794 [debug] [Thread-1  ]: Began compiling node model.jira_source.stg_jira__comment_tmp
[0m09:38:29.591188 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__issue_field_history_tmp"
[0m09:38:29.591552 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__issue_link_tmp"
[0m09:38:29.591946 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__issue_multiselect_history_tmp"
[0m09:38:29.592314 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__issue_tmp"
[0m09:38:29.592433 [debug] [Thread-2  ]: Began compiling node model.jira_source.stg_jira__component_tmp
[0m09:38:29.592537 [debug] [Thread-3  ]: Began compiling node model.jira_source.stg_jira__field_option_tmp
[0m09:38:29.592629 [debug] [Thread-4  ]: Began compiling node model.jira_source.stg_jira__field_tmp
[0m09:38:29.592728 [debug] [Thread-1  ]: Compiling model.jira_source.stg_jira__comment_tmp
[0m09:38:29.592816 [debug] [Thread-5  ]: Began compiling node model.jira_source.stg_jira__issue_field_history_tmp
[0m09:38:29.592902 [debug] [Thread-6  ]: Began compiling node model.jira_source.stg_jira__issue_link_tmp
[0m09:38:29.592986 [debug] [Thread-7  ]: Began compiling node model.jira_source.stg_jira__issue_multiselect_history_tmp
[0m09:38:29.593069 [debug] [Thread-8  ]: Began compiling node model.jira_source.stg_jira__issue_tmp
[0m09:38:29.593153 [debug] [Thread-2  ]: Compiling model.jira_source.stg_jira__component_tmp
[0m09:38:29.593260 [debug] [Thread-3  ]: Compiling model.jira_source.stg_jira__field_option_tmp
[0m09:38:29.593399 [debug] [Thread-4  ]: Compiling model.jira_source.stg_jira__field_tmp
[0m09:38:29.596863 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira_source.stg_jira__comment_tmp"
[0m09:38:29.597021 [debug] [Thread-5  ]: Compiling model.jira_source.stg_jira__issue_field_history_tmp
[0m09:38:29.597146 [debug] [Thread-6  ]: Compiling model.jira_source.stg_jira__issue_link_tmp
[0m09:38:29.597253 [debug] [Thread-7  ]: Compiling model.jira_source.stg_jira__issue_multiselect_history_tmp
[0m09:38:29.597346 [debug] [Thread-8  ]: Compiling model.jira_source.stg_jira__issue_tmp
[0m09:38:29.600641 [debug] [Thread-2  ]: Writing injected SQL for node "model.jira_source.stg_jira__component_tmp"
[0m09:38:29.603593 [debug] [Thread-3  ]: Writing injected SQL for node "model.jira_source.stg_jira__field_option_tmp"
[0m09:38:29.606350 [debug] [Thread-4  ]: Writing injected SQL for node "model.jira_source.stg_jira__field_tmp"
[0m09:38:29.610401 [debug] [Thread-5  ]: Writing injected SQL for node "model.jira_source.stg_jira__issue_field_history_tmp"
[0m09:38:29.613841 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira_source.stg_jira__issue_link_tmp"
[0m09:38:29.617329 [debug] [Thread-7  ]: Writing injected SQL for node "model.jira_source.stg_jira__issue_multiselect_history_tmp"
[0m09:38:29.620559 [debug] [Thread-8  ]: Writing injected SQL for node "model.jira_source.stg_jira__issue_tmp"
[0m09:38:29.621502 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:29.621605 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:29.621713 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:29.621830 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:29.621936 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:29.622080 [debug] [Thread-2  ]: Began executing node model.jira_source.stg_jira__component_tmp
[0m09:38:29.622147 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:29.622260 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:29.622351 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:29.622417 [debug] [Thread-4  ]: Began executing node model.jira_source.stg_jira__field_tmp
[0m09:38:29.622494 [debug] [Thread-1  ]: Began executing node model.jira_source.stg_jira__comment_tmp
[0m09:38:29.622569 [debug] [Thread-3  ]: Began executing node model.jira_source.stg_jira__field_option_tmp
[0m09:38:29.622639 [debug] [Thread-6  ]: Began executing node model.jira_source.stg_jira__issue_link_tmp
[0m09:38:29.639143 [debug] [Thread-2  ]: Writing runtime sql for node "model.jira_source.stg_jira__component_tmp"
[0m09:38:29.639265 [debug] [Thread-5  ]: Began executing node model.jira_source.stg_jira__issue_field_history_tmp
[0m09:38:29.639367 [debug] [Thread-7  ]: Began executing node model.jira_source.stg_jira__issue_multiselect_history_tmp
[0m09:38:29.639443 [debug] [Thread-8  ]: Began executing node model.jira_source.stg_jira__issue_tmp
[0m09:38:29.642579 [debug] [Thread-4  ]: Writing runtime sql for node "model.jira_source.stg_jira__field_tmp"
[0m09:38:29.644709 [debug] [Thread-1  ]: Writing runtime sql for node "model.jira_source.stg_jira__comment_tmp"
[0m09:38:29.647138 [debug] [Thread-3  ]: Writing runtime sql for node "model.jira_source.stg_jira__field_option_tmp"
[0m09:38:29.649459 [debug] [Thread-6  ]: Writing runtime sql for node "model.jira_source.stg_jira__issue_link_tmp"
[0m09:38:29.652274 [debug] [Thread-5  ]: Writing runtime sql for node "model.jira_source.stg_jira__issue_field_history_tmp"
[0m09:38:29.655648 [debug] [Thread-7  ]: Writing runtime sql for node "model.jira_source.stg_jira__issue_multiselect_history_tmp"
[0m09:38:29.657850 [debug] [Thread-8  ]: Writing runtime sql for node "model.jira_source.stg_jira__issue_tmp"
[0m09:38:29.658510 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:29.658608 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:29.658801 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:29.658886 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m09:38:29.659105 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:29.659235 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:29.659363 [debug] [Thread-7  ]: Opening a new connection, currently in state init
[0m09:38:29.659457 [debug] [Thread-8  ]: Opening a new connection, currently in state init
[0m09:38:29.757679 [debug] [Thread-1  ]: On model.jira_source.stg_jira__comment_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__comment_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__comment_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`comment`;


[0m09:38:29.769004 [debug] [Thread-3  ]: On model.jira_source.stg_jira__field_option_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__field_option_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field_option_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`field_option`;


[0m09:38:29.774586 [debug] [Thread-5  ]: On model.jira_source.stg_jira__issue_field_history_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__issue_field_history_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_field_history_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`issue_field_history`;


[0m09:38:29.785470 [debug] [Thread-7  ]: On model.jira_source.stg_jira__issue_multiselect_history_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__issue_multiselect_history_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_multiselect_history_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`issue_multiselect_history`;


[0m09:38:29.786136 [debug] [Thread-2  ]: On model.jira_source.stg_jira__component_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__component_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__component_tmp`
  OPTIONS(
      description=""""""
    )
  as 

select * 
from `ra-development`.`fivetran_jira`.`component`;


[0m09:38:29.787126 [debug] [Thread-4  ]: On model.jira_source.stg_jira__field_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__field_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`field`;


[0m09:38:29.789724 [debug] [Thread-6  ]: On model.jira_source.stg_jira__issue_link_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__issue_link_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_link_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`issue_link`;


[0m09:38:29.793149 [debug] [Thread-8  ]: On model.jira_source.stg_jira__issue_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__issue_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`issue`;


[0m09:38:30.462343 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:187ed557-3692-444b-a18e-edcf22cc23ea:europe-west2&page=queryresults
[0m09:38:30.463283 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:9af65aaa-f3c3-46b4-9f17-c881fd463787:europe-west2&page=queryresults
[0m09:38:30.477108 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:84817c6f-bef1-44b8-93a4-4c012c823be6:europe-west2&page=queryresults
[0m09:38:30.481252 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:30.482845 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:c55bdd0f-2f54-42d0-8f11-d0bf7f337ebf:europe-west2&page=queryresults
[0m09:38:30.483556 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:78a0d07d-504e-422c-a367-7877a441ed0f:europe-west2&page=queryresults
[0m09:38:30.485138 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:30.486023 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:481a8b15-1e62-4a97-84d0-c130d1fbba3c:europe-west2&page=queryresults
[0m09:38:30.487302 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:30.487783 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127231790>]}
[0m09:38:30.489000 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:30.490237 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:30.490674 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127231460>]}
[0m09:38:30.491805 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:30.492232 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127213640>]}
[0m09:38:30.492518 [info ] [Thread-4  ]: 4 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__field_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.90s]
[0m09:38:30.493403 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127231f40>]}
[0m09:38:30.493817 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12721c070>]}
[0m09:38:30.494533 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:3622c1cb-2d2d-4477-9aa3-ff6417825208:europe-west2&page=queryresults
[0m09:38:30.494831 [info ] [Thread-3  ]: 3 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__field_option_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.90s]
[0m09:38:30.495291 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12721caf0>]}
[0m09:38:30.495638 [debug] [Thread-4  ]: Finished running node model.jira_source.stg_jira__field_tmp
[0m09:38:30.495843 [info ] [Thread-1  ]: 1 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__comment_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.90s]
[0m09:38:30.496036 [info ] [Thread-5  ]: 5 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__issue_field_history_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.90s]
[0m09:38:30.497248 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:30.497413 [info ] [Thread-2  ]: 2 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__component_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.90s]
[0m09:38:30.497654 [debug] [Thread-3  ]: Finished running node model.jira_source.stg_jira__field_option_tmp
[0m09:38:30.497830 [info ] [Thread-6  ]: 6 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__issue_link_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.90s]
[0m09:38:30.497961 [debug] [Thread-4  ]: Began running node model.jira_source.stg_jira__issue_type_tmp
[0m09:38:30.498300 [debug] [Thread-1  ]: Finished running node model.jira_source.stg_jira__comment_tmp
[0m09:38:30.498622 [debug] [Thread-5  ]: Finished running node model.jira_source.stg_jira__issue_field_history_tmp
[0m09:38:30.498990 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12721c640>]}
[0m09:38:30.499246 [debug] [Thread-2  ]: Finished running node model.jira_source.stg_jira__component_tmp
[0m09:38:30.499363 [debug] [Thread-3  ]: Began running node model.jira_source.stg_jira__priority_tmp
[0m09:38:30.499575 [debug] [Thread-6  ]: Finished running node model.jira_source.stg_jira__issue_link_tmp
[0m09:38:30.499795 [info ] [Thread-4  ]: 9 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__issue_type_tmp  [RUN]
[0m09:38:30.499954 [debug] [Thread-1  ]: Began running node model.jira_source.stg_jira__project_tmp
[0m09:38:30.500142 [debug] [Thread-5  ]: Began running node model.jira_source.stg_jira__resolution_tmp
[0m09:38:30.500425 [info ] [Thread-7  ]: 7 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__issue_multiselect_history_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.91s]
[0m09:38:30.500594 [debug] [Thread-2  ]: Began running node model.jira_source.stg_jira__sprint_tmp
[0m09:38:30.500732 [info ] [Thread-3  ]: 10 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__priority_tmp  [RUN]
[0m09:38:30.500910 [debug] [Thread-6  ]: Began running node model.jira_source.stg_jira__status_category_tmp
[0m09:38:30.501440 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__issue_type_tmp"
[0m09:38:30.501598 [info ] [Thread-1  ]: 11 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__project_tmp  [RUN]
[0m09:38:30.501912 [info ] [Thread-5  ]: 12 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__resolution_tmp  [RUN]
[0m09:38:30.502216 [debug] [Thread-7  ]: Finished running node model.jira_source.stg_jira__issue_multiselect_history_tmp
[0m09:38:30.502357 [info ] [Thread-2  ]: 13 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__sprint_tmp  [RUN]
[0m09:38:30.502771 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__priority_tmp"
[0m09:38:30.502911 [info ] [Thread-6  ]: 14 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__status_category_tmp  [RUN]
[0m09:38:30.503032 [debug] [Thread-4  ]: Began compiling node model.jira_source.stg_jira__issue_type_tmp
[0m09:38:30.503428 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__project_tmp"
[0m09:38:30.503798 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__resolution_tmp"
[0m09:38:30.503918 [debug] [Thread-7  ]: Began running node model.jira_source.stg_jira__status_tmp
[0m09:38:30.504300 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__sprint_tmp"
[0m09:38:30.504469 [debug] [Thread-3  ]: Began compiling node model.jira_source.stg_jira__priority_tmp
[0m09:38:30.504921 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__status_category_tmp"
[0m09:38:30.505069 [debug] [Thread-4  ]: Compiling model.jira_source.stg_jira__issue_type_tmp
[0m09:38:30.505558 [debug] [Thread-1  ]: Began compiling node model.jira_source.stg_jira__project_tmp
[0m09:38:30.507032 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:abcba35e-6323-4386-a2b8-d8d47ea5b8f6:europe-west2&page=queryresults
[0m09:38:30.507171 [debug] [Thread-5  ]: Began compiling node model.jira_source.stg_jira__resolution_tmp
[0m09:38:30.507323 [info ] [Thread-7  ]: 15 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__status_tmp  [RUN]
[0m09:38:30.507421 [debug] [Thread-2  ]: Began compiling node model.jira_source.stg_jira__sprint_tmp
[0m09:38:30.507512 [debug] [Thread-3  ]: Compiling model.jira_source.stg_jira__priority_tmp
[0m09:38:30.507598 [debug] [Thread-6  ]: Began compiling node model.jira_source.stg_jira__status_category_tmp
[0m09:38:30.510157 [debug] [Thread-1  ]: Compiling model.jira_source.stg_jira__project_tmp
[0m09:38:30.511485 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:30.512682 [debug] [Thread-5  ]: Compiling model.jira_source.stg_jira__resolution_tmp
[0m09:38:30.513198 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__status_tmp"
[0m09:38:30.513309 [debug] [Thread-2  ]: Compiling model.jira_source.stg_jira__sprint_tmp
[0m09:38:30.517273 [debug] [Thread-3  ]: Writing injected SQL for node "model.jira_source.stg_jira__priority_tmp"
[0m09:38:30.518882 [debug] [Thread-6  ]: Compiling model.jira_source.stg_jira__status_category_tmp
[0m09:38:30.521914 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira_source.stg_jira__project_tmp"
[0m09:38:30.522923 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12721cf70>]}
[0m09:38:30.526175 [debug] [Thread-5  ]: Writing injected SQL for node "model.jira_source.stg_jira__resolution_tmp"
[0m09:38:30.526394 [debug] [Thread-7  ]: Began compiling node model.jira_source.stg_jira__status_tmp
[0m09:38:30.529737 [debug] [Thread-2  ]: Writing injected SQL for node "model.jira_source.stg_jira__sprint_tmp"
[0m09:38:30.533801 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira_source.stg_jira__status_category_tmp"
[0m09:38:30.538951 [debug] [Thread-4  ]: Writing injected SQL for node "model.jira_source.stg_jira__issue_type_tmp"
[0m09:38:30.539204 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:30.539406 [info ] [Thread-8  ]: 8 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__issue_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.93s]
[0m09:38:30.539568 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:30.539671 [debug] [Thread-7  ]: Compiling model.jira_source.stg_jira__status_tmp
[0m09:38:30.539882 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:30.540045 [debug] [Thread-3  ]: Began executing node model.jira_source.stg_jira__priority_tmp
[0m09:38:30.540158 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:30.540372 [debug] [Thread-8  ]: Finished running node model.jira_source.stg_jira__issue_tmp
[0m09:38:30.540460 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:30.540549 [debug] [Thread-1  ]: Began executing node model.jira_source.stg_jira__project_tmp
[0m09:38:30.540635 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:30.543030 [debug] [Thread-7  ]: Writing injected SQL for node "model.jira_source.stg_jira__status_tmp"
[0m09:38:30.543155 [debug] [Thread-5  ]: Began executing node model.jira_source.stg_jira__resolution_tmp
[0m09:38:30.545379 [debug] [Thread-3  ]: Writing runtime sql for node "model.jira_source.stg_jira__priority_tmp"
[0m09:38:30.545476 [debug] [Thread-2  ]: Began executing node model.jira_source.stg_jira__sprint_tmp
[0m09:38:30.545582 [debug] [Thread-8  ]: Began running node model.jira_source.stg_jira__user_tmp
[0m09:38:30.545739 [debug] [Thread-6  ]: Began executing node model.jira_source.stg_jira__status_category_tmp
[0m09:38:30.547938 [debug] [Thread-1  ]: Writing runtime sql for node "model.jira_source.stg_jira__project_tmp"
[0m09:38:30.548052 [debug] [Thread-4  ]: Began executing node model.jira_source.stg_jira__issue_type_tmp
[0m09:38:30.550164 [debug] [Thread-5  ]: Writing runtime sql for node "model.jira_source.stg_jira__resolution_tmp"
[0m09:38:30.552880 [debug] [Thread-2  ]: Writing runtime sql for node "model.jira_source.stg_jira__sprint_tmp"
[0m09:38:30.553013 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:30.553157 [info ] [Thread-8  ]: 16 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__user_tmp  [RUN]
[0m09:38:30.555346 [debug] [Thread-6  ]: Writing runtime sql for node "model.jira_source.stg_jira__status_category_tmp"
[0m09:38:30.555590 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:30.557865 [debug] [Thread-4  ]: Writing runtime sql for node "model.jira_source.stg_jira__issue_type_tmp"
[0m09:38:30.557998 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:30.558170 [debug] [Thread-7  ]: Began executing node model.jira_source.stg_jira__status_tmp
[0m09:38:30.558374 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:30.558631 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__user_tmp"
[0m09:38:30.558708 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m09:38:30.559025 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:30.559109 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:30.561162 [debug] [Thread-7  ]: Writing runtime sql for node "model.jira_source.stg_jira__status_tmp"
[0m09:38:30.561469 [debug] [Thread-8  ]: Began compiling node model.jira_source.stg_jira__user_tmp
[0m09:38:30.563248 [debug] [Thread-8  ]: Compiling model.jira_source.stg_jira__user_tmp
[0m09:38:30.568004 [debug] [Thread-8  ]: Writing injected SQL for node "model.jira_source.stg_jira__user_tmp"
[0m09:38:30.571075 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:30.571178 [debug] [Thread-8  ]: Began executing node model.jira_source.stg_jira__user_tmp
[0m09:38:30.573971 [debug] [Thread-8  ]: Writing runtime sql for node "model.jira_source.stg_jira__user_tmp"
[0m09:38:30.574290 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:30.579470 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:30.665447 [debug] [Thread-2  ]: On model.jira_source.stg_jira__sprint_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__sprint_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__sprint_tmp`
  OPTIONS(
      description=""""""
    )
  as 

select * 
from `ra-development`.`fivetran_jira`.`sprint`;


[0m09:38:30.679564 [debug] [Thread-3  ]: On model.jira_source.stg_jira__priority_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__priority_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__priority_tmp`
  OPTIONS(
      description=""""""
    )
  as 

select * from `ra-development`.`fivetran_jira`.`priority`;


[0m09:38:30.690661 [debug] [Thread-4  ]: On model.jira_source.stg_jira__issue_type_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__issue_type_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_type_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`issue_type`;


[0m09:38:30.692085 [debug] [Thread-1  ]: On model.jira_source.stg_jira__project_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__project_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__project_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`project`;


[0m09:38:30.696171 [debug] [Thread-8  ]: On model.jira_source.stg_jira__user_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__user_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__user_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`user`;


[0m09:38:30.698067 [debug] [Thread-7  ]: On model.jira_source.stg_jira__status_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__status_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__status_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`status`;


[0m09:38:30.699098 [debug] [Thread-5  ]: On model.jira_source.stg_jira__resolution_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__resolution_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__resolution_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`resolution`;


[0m09:38:30.700954 [debug] [Thread-6  ]: On model.jira_source.stg_jira__status_category_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__status_category_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__status_category_tmp`
  OPTIONS(
      description=""""""
    )
  as select * 
from `ra-development`.`fivetran_jira`.`status_category`;


[0m09:38:31.368781 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:b4e914f8-f2e8-402b-8043-79ae7f81bad2:europe-west2&page=queryresults
[0m09:38:31.371543 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:31.372471 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127213d90>]}
[0m09:38:31.372763 [info ] [Thread-3  ]: 10 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__priority_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.87s]
[0m09:38:31.373305 [debug] [Thread-3  ]: Finished running node model.jira_source.stg_jira__priority_tmp
[0m09:38:31.373466 [debug] [Thread-3  ]: Began running node model.jira_source.stg_jira__version_tmp
[0m09:38:31.374238 [info ] [Thread-3  ]: 17 of 110 START sql view model lewis_analytics_dev_jira_source.stg_jira__version_tmp  [RUN]
[0m09:38:31.375003 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__version_tmp"
[0m09:38:31.375369 [debug] [Thread-3  ]: Began compiling node model.jira_source.stg_jira__version_tmp
[0m09:38:31.375494 [debug] [Thread-3  ]: Compiling model.jira_source.stg_jira__version_tmp
[0m09:38:31.379366 [debug] [Thread-3  ]: Writing injected SQL for node "model.jira_source.stg_jira__version_tmp"
[0m09:38:31.381149 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:f8345d21-529d-4ac3-86ff-b840b6c571eb:europe-west2&page=queryresults
[0m09:38:31.382407 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:31.382973 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12762c550>]}
[0m09:38:31.383317 [info ] [Thread-2  ]: 13 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__sprint_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.88s]
[0m09:38:31.383630 [debug] [Thread-2  ]: Finished running node model.jira_source.stg_jira__sprint_tmp
[0m09:38:31.383730 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:31.383848 [debug] [Thread-2  ]: Began running node model.wire_harvest.stg_harvest__clients
[0m09:38:31.384050 [debug] [Thread-3  ]: Began executing node model.jira_source.stg_jira__version_tmp
[0m09:38:31.384254 [info ] [Thread-2  ]: 18 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__clients  [RUN]
[0m09:38:31.387944 [debug] [Thread-3  ]: Writing runtime sql for node "model.jira_source.stg_jira__version_tmp"
[0m09:38:31.388532 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__clients"
[0m09:38:31.388675 [debug] [Thread-2  ]: Began compiling node model.wire_harvest.stg_harvest__clients
[0m09:38:31.388781 [debug] [Thread-2  ]: Compiling model.wire_harvest.stg_harvest__clients
[0m09:38:31.392432 [debug] [Thread-2  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__clients"
[0m09:38:31.393154 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:31.393926 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:565a624e-0d73-4fcf-8a11-a87703e37208:europe-west2&page=queryresults
[0m09:38:31.395226 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:31.395668 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1271970d0>]}
[0m09:38:31.395914 [info ] [Thread-1  ]: 11 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__project_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.89s]
[0m09:38:31.396182 [debug] [Thread-1  ]: Finished running node model.jira_source.stg_jira__project_tmp
[0m09:38:31.396463 [debug] [Thread-1  ]: Began running node model.wire_harvest.stg_harvest__employee
[0m09:38:31.396849 [info ] [Thread-1  ]: 19 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__employee  [RUN]
[0m09:38:31.397211 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:31.397623 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__employee"
[0m09:38:31.397760 [debug] [Thread-2  ]: Began executing node model.wire_harvest.stg_harvest__clients
[0m09:38:31.397874 [debug] [Thread-1  ]: Began compiling node model.wire_harvest.stg_harvest__employee
[0m09:38:31.399093 [debug] [Thread-1  ]: Compiling model.wire_harvest.stg_harvest__employee
[0m09:38:31.403258 [debug] [Thread-1  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__employee"
[0m09:38:31.405583 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:31.405752 [debug] [Thread-1  ]: Began executing node model.wire_harvest.stg_harvest__employee
[0m09:38:31.406396 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:a4d8b0ba-eb5d-4008-8931-454d9208f9e3:europe-west2&page=queryresults
[0m09:38:31.410894 [debug] [Thread-2  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__clients"
[0m09:38:31.414550 [debug] [Thread-1  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__employee"
[0m09:38:31.416290 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:31.417078 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:622167e2-e3d8-4cc5-9f2d-bf374f6305e3:europe-west2&page=queryresults
[0m09:38:31.417689 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12762c9d0>]}
[0m09:38:31.418888 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:31.419541 [info ] [Thread-5  ]: 12 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__resolution_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.91s]
[0m09:38:31.419931 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12711f4c0>]}
[0m09:38:31.420319 [debug] [Thread-5  ]: Finished running node model.jira_source.stg_jira__resolution_tmp
[0m09:38:31.420437 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m09:38:31.420562 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:31.420822 [info ] [Thread-8  ]: 16 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__user_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.86s]
[0m09:38:31.420957 [debug] [Thread-5  ]: Began running node model.wire_harvest.stg_harvest__employee_roles
[0m09:38:31.421551 [debug] [Thread-8  ]: Finished running node model.jira_source.stg_jira__user_tmp
[0m09:38:31.421708 [info ] [Thread-5  ]: 20 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__employee_roles  [RUN]
[0m09:38:31.421914 [debug] [Thread-8  ]: Began running node model.wire_harvest.stg_harvest__expenses
[0m09:38:31.422719 [info ] [Thread-8  ]: 21 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__expenses  [RUN]
[0m09:38:31.422507 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__employee_roles"
[0m09:38:31.423112 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__expenses"
[0m09:38:31.423227 [debug] [Thread-5  ]: Began compiling node model.wire_harvest.stg_harvest__employee_roles
[0m09:38:31.423349 [debug] [Thread-8  ]: Began compiling node model.wire_harvest.stg_harvest__expenses
[0m09:38:31.423461 [debug] [Thread-5  ]: Compiling model.wire_harvest.stg_harvest__employee_roles
[0m09:38:31.423568 [debug] [Thread-8  ]: Compiling model.wire_harvest.stg_harvest__expenses
[0m09:38:31.426910 [debug] [Thread-5  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__employee_roles"
[0m09:38:31.430537 [debug] [Thread-8  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__expenses"
[0m09:38:31.431762 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:31.431889 [debug] [Thread-5  ]: Began executing node model.wire_harvest.stg_harvest__employee_roles
[0m09:38:31.434659 [debug] [Thread-5  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__employee_roles"
[0m09:38:31.435598 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:31.435717 [debug] [Thread-8  ]: Began executing node model.wire_harvest.stg_harvest__expenses
[0m09:38:31.439566 [debug] [Thread-8  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__expenses"
[0m09:38:31.441492 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:5eb6b112-db40-44b0-b771-4a820085c2dd:europe-west2&page=queryresults
[0m09:38:31.442586 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:31.443154 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127180a60>]}
[0m09:38:31.443836 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:b1f1d5ca-51e2-45f2-a306-0477dea5cf0e:europe-west2&page=queryresults
[0m09:38:31.444097 [info ] [Thread-4  ]: 9 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__issue_type_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.94s]
[0m09:38:31.444277 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:31.445247 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:31.445367 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:31.445594 [debug] [Thread-4  ]: Finished running node model.jira_source.stg_jira__issue_type_tmp
[0m09:38:31.445990 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1276a2be0>]}
[0m09:38:31.447056 [debug] [Thread-4  ]: Began running node model.wire_harvest.stg_harvest__external_reference
[0m09:38:31.447856 [info ] [Thread-7  ]: 15 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__status_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.93s]
[0m09:38:31.448201 [info ] [Thread-4  ]: 22 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__external_reference  [RUN]
[0m09:38:31.449159 [debug] [Thread-7  ]: Finished running node model.jira_source.stg_jira__status_tmp
[0m09:38:31.450259 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__external_reference"
[0m09:38:31.457560 [debug] [Thread-4  ]: Began compiling node model.wire_harvest.stg_harvest__external_reference
[0m09:38:31.457934 [debug] [Thread-4  ]: Compiling model.wire_harvest.stg_harvest__external_reference
[0m09:38:31.450571 [debug] [Thread-7  ]: Began running node model.wire_harvest.stg_harvest__invoice_line_items
[0m09:38:31.464765 [info ] [Thread-7  ]: 23 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__invoice_line_items  [RUN]
[0m09:38:31.464286 [debug] [Thread-4  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__external_reference"
[0m09:38:31.466213 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__invoice_line_items"
[0m09:38:31.474967 [debug] [Thread-7  ]: Began compiling node model.wire_harvest.stg_harvest__invoice_line_items
[0m09:38:31.475563 [debug] [Thread-7  ]: Compiling model.wire_harvest.stg_harvest__invoice_line_items
[0m09:38:31.480896 [debug] [Thread-7  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__invoice_line_items"
[0m09:38:31.481426 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:31.482141 [debug] [Thread-4  ]: Began executing node model.wire_harvest.stg_harvest__external_reference
[0m09:38:31.484467 [debug] [Thread-4  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__external_reference"
[0m09:38:31.485836 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:31.486523 [debug] [Thread-7  ]: Began executing node model.wire_harvest.stg_harvest__invoice_line_items
[0m09:38:31.488620 [debug] [Thread-7  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__invoice_line_items"
[0m09:38:31.489435 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:31.490170 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:31.496967 [debug] [Thread-3  ]: On model.jira_source.stg_jira__version_tmp: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__version_tmp"} */


  create or replace view `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__version_tmp`
  OPTIONS(
      description=""""""
    )
  as 

select * 
from `ra-development`.`fivetran_jira`.`version`;


[0m09:38:31.523070 [debug] [Thread-2  ]: On model.wire_harvest.stg_harvest__clients: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__clients"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__clients`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`clients`    

),

deduplicated as (

   select unique.*
    from (
        select
            array_agg (
                original
                order by _sdc_batched_at desc
                limit 1
            )[offset(0)] unique
        from source original
        group by id
    )

),

base as (

   select

      cast(id as numeric) as harvest_client_natural_key,

      lower(cast(currency as string)) as harvest_client_currency,
      lower(replace(replace(replace(name,'limited',''),'ltd',''),', inc.','')) as harvest_client_name,

      cast(is_active as boolean) as harvest_client_is_active,

      cast(created_at as timestamp) as harvest_client_created_at_ts,
      cast(updated_at as timestamp) as harvest_client_updated_at_ts

   from deduplicated

)

select * from base;


[0m09:38:31.526189 [debug] [Thread-1  ]: On model.wire_harvest.stg_harvest__employee: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__employee"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__employee`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`users`    

),

deduplicated as (

   select unique.*
    from (
        select
            array_agg (
                original
                order by _sdc_batched_at desc
                limit 1
            )[offset(0)] unique
        from source original
        group by id
    )

),

base as (

   select

      cast(id as numeric) as harvest_employee_natural_key,

      lower(cast(first_name as string)) as harvest_employee_first_name,
      lower(cast(last_name as string)) as harvest_employee_last_name,
      lower(cast(first_name as string)) || " " || lower(cast(last_name as string)) as harvest_employee_full_name,
     
      lower(cast(email as string)) as harvest_employee_email,

      cast(weekly_capacity as numeric) as harvest_employee_weekly_capacity,
      cast(cost_rate as numeric) as harvest_employee_cost_rate,
      cast(default_hourly_rate as numeric) as harvest_employee_default_hourly_rate,

      cast(is_contractor as boolean) as harvest_employee_is_contractor,
      cast(is_active as boolean) as harvest_employee_is_active,
      
      cast(created_at as timestamp) as harvest_employee_created_at_ts,
      cast(updated_at as timestamp) as harvest_employee_updated_at_ts

   from deduplicated

)

select * from base;


[0m09:38:31.542394 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:fee2535d-2a2f-41d1-b6a1-88b72da9fe77:europe-west2&page=queryresults
[0m09:38:31.542647 [debug] [Thread-5  ]: On model.wire_harvest.stg_harvest__employee_roles: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__employee_roles"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__employee_roles`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`user_roles`

),

base as (

   select

      cast(user_id as numeric) as harvest_employee_natural_key,
      cast(role_id as numeric) as harvest_role_natural_key,

   from source

)

select * from base;


[0m09:38:31.543819 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:31.545559 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1271bb940>]}
[0m09:38:31.545974 [info ] [Thread-6  ]: 14 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__status_category_tmp  [[32mCREATE VIEW (0 processed)[0m in 1.04s]
[0m09:38:31.546221 [debug] [Thread-6  ]: Finished running node model.jira_source.stg_jira__status_category_tmp
[0m09:38:31.546406 [debug] [Thread-8  ]: On model.wire_harvest.stg_harvest__expenses: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__expenses"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__expenses`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`expenses`    

),

deduplicated as (

   select unique.*
    from (
        select
            array_agg (
                original
                order by updated_at desc
                limit 1
            )[offset(0)] unique
        from source original
        group by id
    )

),

base as (

   select

      cast(id as numeric) as harvest_expense_natural_key,
      cast(expense_category_id as numeric) as harvest_expense_category_natural_key,
      cast(client_id as numeric) as harvest_client_natural_key,
      cast(invoice_id as numeric) as harvest_invoice_natural_key,
      cast(project_id as numeric) as harvest_project_natural_key,
      cast(user_assignment_id as numeric) as harvest_employee_assignment_natural_key,
      cast(user_id as numeric) as harvest_employee_natural_key,

      lower(cast(notes as string)) as harvest_expense_notes,
      lower(cast(receipt_file_name as string)) as harvest_expense_receipt_file_name,
      lower(cast(locked_reason as string)) as harvest_expense_locked_reason,
      lower(cast(receipt_content_type as string)) as harvest_expense_receipt_content_type,
      lower(cast(receipt_url as string)) as harvest_expense_receipt_url,

      nullif(cast(total_cost as numeric),0) as harvest_expense_total_cost,
      nullif(cast(receipt_file_size as numeric),0) as harvest_expense_receipt_file_size,
      nullif(cast(units as numeric),0) as harvest_expense_units,

      cast(is_closed as boolean) as harvest_expense_is_closed,
      cast(billable as boolean) as harvest_expense_billable,
      cast(is_billed as boolean) as harvest_expense_is_billed,
      cast(is_locked as boolean) as harvest_expense_is_locked,

      cast(created_at as timestamp) as harvest_expense_created_at,
      cast(updated_at as timestamp) as harvest_expense_updated_at,
      cast(spent_date as timestamp) as harvest_expense_spent_date

   from deduplicated

)

select * from base;


[0m09:38:31.546498 [debug] [Thread-6  ]: Began running node model.wire_harvest.stg_harvest__invoices
[0m09:38:31.547447 [info ] [Thread-6  ]: 24 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__invoices  [RUN]
[0m09:38:31.548465 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__invoices"
[0m09:38:31.548623 [debug] [Thread-6  ]: Began compiling node model.wire_harvest.stg_harvest__invoices
[0m09:38:31.548754 [debug] [Thread-6  ]: Compiling model.wire_harvest.stg_harvest__invoices
[0m09:38:31.551979 [debug] [Thread-6  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__invoices"
[0m09:38:31.553482 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:31.553824 [debug] [Thread-6  ]: Began executing node model.wire_harvest.stg_harvest__invoices
[0m09:38:31.557231 [debug] [Thread-6  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__invoices"
[0m09:38:31.558862 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:31.572224 [debug] [Thread-4  ]: On model.wire_harvest.stg_harvest__external_reference: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__external_reference"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__external_reference`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`external_reference`    

),

deduplicated as (

   select unique.*
    from (
        select
            array_agg (
                original
                order by _sdc_batched_at desc
                limit 1
            )[offset(0)] unique
        from source original
        group by id, _sdc_sequence
    )

),

base as (

   select

      cast(id as numeric) as harvest_external_reference_natural_key,
      cast(group_id as numeric) as harvest_external_reference_group_natural_key,

      last_value(permalink) over (partition by id order by _sdc_batched_at asc rows between unbounded preceding and unbounded following) as harvest_external_reference_permalink,

      lower(regexp_extract(permalink, '([a-zA-Z]+-[0-9]+)')) as harvest_external_reference_jira_issue_key,
      
      lower(cast(service as string)) as harvest_external_reference_platform

   from deduplicated

)

select * from base;


[0m09:38:31.580908 [debug] [Thread-7  ]: On model.wire_harvest.stg_harvest__invoice_line_items: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__invoice_line_items"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__invoice_line_items`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`invoice_line_items`    

),

deduplicated as (

   select unique.*
    from (
        select
            array_agg (
                original
                order by _sdc_batched_at desc
                limit 1
            )[offset(0)] unique
        from source original
        group by id
    )

),

base as (

   select

      cast(id as numeric) as harvest_invoice_line_item_natural_key,
      cast(project_id as numeric) as harvest_project_natural_key,
      cast(invoice_id as numeric) as harvest_invoice_natural_key,

      lower(cast(kind as string)) as harvest_invoice_line_item_kind,
      lower(cast(description as string)) as harvest_invoice_line_item_description,

      ifnull(cast(amount as numeric),0) as harvest_invoice_line_item_amount,
      ifnull(cast(unit_price as numeric),0) as harvest_invoice_line_item_unit_price,
      ifnull(cast(quantity as numeric),0) as harvest_invoice_line_item_quantity,

      ifnull((case when lower(kind) = 'service' then amount end),0) as harvest_invoice_line_item_services_amount_billed,
      ifnull((case when lower(kind) = 'license referral fee' then amount end),0) as harvest_invoice_line_item_license_referral_fee_amount_billed,
      ifnull((case when lower(kind) = 'product' then amount end),0) as harvest_invoice_line_item_expenses_amount_billed,
      ifnull((case when lower(kind) = 'support' then amount end),0) as harvest_invoice_line_item_support_amount_billed,

      cast(taxed as boolean) as harvest_invoice_line_item_is_taxed

   from deduplicated

)

select * from base;


[0m09:38:31.631638 [debug] [Thread-6  ]: On model.wire_harvest.stg_harvest__invoices: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__invoices"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__invoices`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`invoices`    

),

deduplicated as (

   select unique.*
    from (
        select
            array_agg (
                original
                order by _sdc_batched_at desc
                limit 1
            )[offset(0)] unique
        from source original
        group by id
    )

),

base as (

   select

      cast(id as numeric) as harvest_invoice_natural_key,
      cast(client_id as numeric) as harvest_client_natural_key,
      cast(creator_id as numeric) as harvest_creator_natural_key,
      
      lower(cast(client_key as string)) as harvest_invoice_client_key,

      lower(cast(number as string)) as harvest_invoice_number,
      lower(cast(purchase_order as string)) as harvest_invoice_purchase_order,
      lower(cast(state as string)) as harvest_invoice_state,
      lower(cast(notes as string)) as harvest_invoice_notes,
      lower(cast(subject as string)) as harvest_invoice_subject,
      lower(cast(currency as string)) as harvest_invoice_currency,
      lower(cast(payment_term as string)) as harvest_invoice_payment_term,

      nullif(cast(amount as numeric),0) as harvest_invoice_amount,
      nullif(cast(due_amount as numeric),0) as harvest_invoice_due_amount,

      nullif(cast(discount_amount as numeric),0) as harvest_invoice_discount_amount,
      nullif(cast(discount as numeric),0) as harvest_invoice_discount,

      nullif(cast(tax_amount as numeric),0) as harvest_invoice_tax_amount,
      nullif(cast(tax as numeric),0) as harvest_invoice_tax,

      cast(period_start as timestamp) as harvest_invoice_period_start,
      cast(period_end as timestamp) as harvest_invoice_period_end,

      cast(paid_date as timestamp) as harvest_invoice_paid_date,
      cast(issue_date as timestamp) as harvest_invoice_issue_date,
      cast(due_date as timestamp) as harvest_invoice_due_date,

      cast(created_at as timestamp) as harvest_invoice_created_at,
      cast(sent_at as timestamp) as harvest_invoice_sent_at,
      cast(paid_at as timestamp) as harvest_invoice_paid_at,
      cast(updated_at as timestamp) as harvest_invoice_updated_at

   from deduplicated

)

select * from base;


[0m09:38:32.189437 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:b0d81125-573b-47b8-a00e-dd1f9d764a5f:europe-west2&page=queryresults
[0m09:38:32.191937 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:32.192703 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13298e0a0>]}
[0m09:38:32.193843 [info ] [Thread-3  ]: 17 of 110 OK created sql view model lewis_analytics_dev_jira_source.stg_jira__version_tmp  [[32mCREATE VIEW (0 processed)[0m in 0.82s]
[0m09:38:32.194310 [debug] [Thread-3  ]: Finished running node model.jira_source.stg_jira__version_tmp
[0m09:38:32.194566 [debug] [Thread-3  ]: Began running node model.wire_harvest.stg_harvest__project_users
[0m09:38:32.194896 [info ] [Thread-3  ]: 25 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__project_users  [RUN]
[0m09:38:32.196333 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__project_users"
[0m09:38:32.196561 [debug] [Thread-3  ]: Began compiling node model.wire_harvest.stg_harvest__project_users
[0m09:38:32.196688 [debug] [Thread-3  ]: Compiling model.wire_harvest.stg_harvest__project_users
[0m09:38:32.200479 [debug] [Thread-3  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__project_users"
[0m09:38:32.201904 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:32.202111 [debug] [Thread-3  ]: Began executing node model.wire_harvest.stg_harvest__project_users
[0m09:38:32.206767 [debug] [Thread-3  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__project_users"
[0m09:38:32.208153 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:32.214345 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:5b572ee1-fb41-49c1-9932-5f9f9e0e893c:europe-west2&page=queryresults
[0m09:38:32.236214 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:7bad1699-024e-4b1a-94e8-5725a38db1ed:europe-west2&page=queryresults
[0m09:38:32.239428 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:3f935af1-4931-401f-99b0-c2e7ffcf1571:europe-west2&page=queryresults
[0m09:38:32.242546 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:92a5cd5d-bdc7-4d29-889b-854bcdd218f9:europe-west2&page=queryresults
[0m09:38:32.254494 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:2ad770b7-5558-4d77-8416-9f418d5c8314:europe-west2&page=queryresults
[0m09:38:32.271732 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:fb7d51c6-5d37-4144-ab3d-48537cdf75af:europe-west2&page=queryresults
[0m09:38:32.298971 [debug] [Thread-3  ]: On model.wire_harvest.stg_harvest__project_users: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__project_users"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__project_users`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`project_users`    

),

base as (

   select

      cast(id as numeric) as harvest_project_user_natural_key,
      cast(user_id as numeric) as harvest_employee_natural_key,
      cast(project_id as numeric) as harvest_project_natural_key,

      cast(hourly_rate as numeric) as harvest_project_user_hourly_rate,
      cast(budget as numeric) as harvest_project_user_budget,

      cast(is_active as boolean) as harvest_project_user_is_active,

      cast(created_at as timestamp) as harvest_project_user_created_at,
      cast(updated_at as timestamp) as harvest_project_user_updated_at,


   from source

)

select * from base;


[0m09:38:32.328623 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:61ffd9fa-f5c7-438a-90e1-8d274d6b009c:europe-west2&page=queryresults
[0m09:38:32.516399 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:32.517022 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127ed3280>]}
[0m09:38:32.517300 [info ] [Thread-8  ]: 21 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__expenses  [[32mCREATE VIEW (0 processed)[0m in 1.09s]
[0m09:38:32.517666 [debug] [Thread-8  ]: Finished running node model.wire_harvest.stg_harvest__expenses
[0m09:38:32.517803 [debug] [Thread-8  ]: Began running node model.wire_harvest.stg_harvest__projects
[0m09:38:32.518055 [info ] [Thread-8  ]: 26 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__projects  [RUN]
[0m09:38:32.518660 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__projects"
[0m09:38:32.518793 [debug] [Thread-8  ]: Began compiling node model.wire_harvest.stg_harvest__projects
[0m09:38:32.518905 [debug] [Thread-8  ]: Compiling model.wire_harvest.stg_harvest__projects
[0m09:38:32.523506 [debug] [Thread-8  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__projects"
[0m09:38:32.524390 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:32.524847 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127eac760>]}
[0m09:38:32.525119 [info ] [Thread-2  ]: 18 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__clients  [[32mCREATE VIEW (0 processed)[0m in 1.14s]
[0m09:38:32.525417 [debug] [Thread-2  ]: Finished running node model.wire_harvest.stg_harvest__clients
[0m09:38:32.525569 [debug] [Thread-2  ]: Began running node model.wire_harvest.stg_harvest__projects_tasks
[0m09:38:32.525811 [info ] [Thread-2  ]: 27 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__projects_tasks  [RUN]
[0m09:38:32.525930 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:32.526440 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__projects_tasks"
[0m09:38:32.526561 [debug] [Thread-8  ]: Began executing node model.wire_harvest.stg_harvest__projects
[0m09:38:32.526667 [debug] [Thread-2  ]: Began compiling node model.wire_harvest.stg_harvest__projects_tasks
[0m09:38:32.530243 [debug] [Thread-8  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__projects"
[0m09:38:32.530383 [debug] [Thread-2  ]: Compiling model.wire_harvest.stg_harvest__projects_tasks
[0m09:38:32.534346 [debug] [Thread-2  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__projects_tasks"
[0m09:38:32.534756 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:32.534898 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:32.535101 [debug] [Thread-2  ]: Began executing node model.wire_harvest.stg_harvest__projects_tasks
[0m09:38:32.540389 [debug] [Thread-2  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__projects_tasks"
[0m09:38:32.541533 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:32.542053 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126f7ee20>]}
[0m09:38:32.542836 [info ] [Thread-5  ]: 20 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__employee_roles  [[32mCREATE VIEW (0 processed)[0m in 1.12s]
[0m09:38:32.543064 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m09:38:32.543621 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:32.543876 [debug] [Thread-5  ]: Finished running node model.wire_harvest.stg_harvest__employee_roles
[0m09:38:32.544381 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x132983d90>]}
[0m09:38:32.544579 [debug] [Thread-5  ]: Began running node model.wire_harvest.stg_harvest__roles
[0m09:38:32.545078 [info ] [Thread-1  ]: 19 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__employee  [[32mCREATE VIEW (0 processed)[0m in 1.15s]
[0m09:38:32.545260 [info ] [Thread-5  ]: 28 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__roles .. [RUN]
[0m09:38:32.545599 [debug] [Thread-1  ]: Finished running node model.wire_harvest.stg_harvest__employee
[0m09:38:32.546342 [debug] [Thread-1  ]: Began running node model.wire_harvest.stg_harvest__tasks
[0m09:38:32.546124 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__roles"
[0m09:38:32.546771 [info ] [Thread-1  ]: 29 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__tasks .. [RUN]
[0m09:38:32.547818 [debug] [Thread-5  ]: Began compiling node model.wire_harvest.stg_harvest__roles
[0m09:38:32.548493 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__tasks"
[0m09:38:32.549067 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:32.549206 [debug] [Thread-5  ]: Compiling model.wire_harvest.stg_harvest__roles
[0m09:38:32.549342 [debug] [Thread-1  ]: Began compiling node model.wire_harvest.stg_harvest__tasks
[0m09:38:32.549873 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12721c250>]}
[0m09:38:32.556151 [debug] [Thread-5  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__roles"
[0m09:38:32.557330 [debug] [Thread-1  ]: Compiling model.wire_harvest.stg_harvest__tasks
[0m09:38:32.557893 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:32.558168 [info ] [Thread-4  ]: 22 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__external_reference  [[32mCREATE VIEW (0 processed)[0m in 1.10s]
[0m09:38:32.562655 [debug] [Thread-1  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__tasks"
[0m09:38:32.563826 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127ec8cd0>]}
[0m09:38:32.563990 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:32.565074 [debug] [Thread-4  ]: Finished running node model.wire_harvest.stg_harvest__external_reference
[0m09:38:32.565787 [info ] [Thread-7  ]: 23 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__invoice_line_items  [[32mCREATE VIEW (0 processed)[0m in 1.10s]
[0m09:38:32.566015 [debug] [Thread-5  ]: Began executing node model.wire_harvest.stg_harvest__roles
[0m09:38:32.566196 [debug] [Thread-4  ]: Began running node model.wire_harvest.stg_harvest__time_sheet_external_reference
[0m09:38:32.571698 [info ] [Thread-4  ]: 30 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__time_sheet_external_reference  [RUN]
[0m09:38:32.566597 [debug] [Thread-7  ]: Finished running node model.wire_harvest.stg_harvest__invoice_line_items
[0m09:38:32.570401 [debug] [Thread-5  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__roles"
[0m09:38:32.572243 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__time_sheet_external_reference"
[0m09:38:32.566775 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:32.572708 [debug] [Thread-7  ]: Began running node model.wire_harvest.stg_harvest__time_sheets
[0m09:38:32.573452 [debug] [Thread-4  ]: Began compiling node model.wire_harvest.stg_harvest__time_sheet_external_reference
[0m09:38:32.573582 [debug] [Thread-1  ]: Began executing node model.wire_harvest.stg_harvest__tasks
[0m09:38:32.573787 [info ] [Thread-7  ]: 31 of 110 START sql view model lewis_analytics_dev_staging.stg_harvest__time_sheets  [RUN]
[0m09:38:32.573965 [debug] [Thread-4  ]: Compiling model.wire_harvest.stg_harvest__time_sheet_external_reference
[0m09:38:32.574085 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:32.577166 [debug] [Thread-1  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__tasks"
[0m09:38:32.577618 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.wire_harvest.stg_harvest__time_sheets"
[0m09:38:32.581497 [debug] [Thread-4  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__time_sheet_external_reference"
[0m09:38:32.582210 [debug] [Thread-7  ]: Began compiling node model.wire_harvest.stg_harvest__time_sheets
[0m09:38:32.582814 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:32.583128 [debug] [Thread-7  ]: Compiling model.wire_harvest.stg_harvest__time_sheets
[0m09:38:32.589316 [debug] [Thread-7  ]: Writing injected SQL for node "model.wire_harvest.stg_harvest__time_sheets"
[0m09:38:32.589592 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:32.589806 [debug] [Thread-4  ]: Began executing node model.wire_harvest.stg_harvest__time_sheet_external_reference
[0m09:38:32.593753 [debug] [Thread-4  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__time_sheet_external_reference"
[0m09:38:32.594186 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:32.594294 [debug] [Thread-7  ]: Began executing node model.wire_harvest.stg_harvest__time_sheets
[0m09:38:32.596569 [debug] [Thread-7  ]: Writing runtime sql for node "model.wire_harvest.stg_harvest__time_sheets"
[0m09:38:32.597151 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:32.597382 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:32.609721 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:32.610463 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126fa1e50>]}
[0m09:38:32.647123 [debug] [Thread-2  ]: On model.wire_harvest.stg_harvest__projects_tasks: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__projects_tasks"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__projects_tasks`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`project_tasks`    

),

base as (

   select

      cast(id as numeric) as harvest_project_task_natural_key,
      cast(project_id as numeric) as harvest_project_natural_key,
      cast(task_id as numeric) as harvest_task_natural_key,

      cast(hourly_rate as numeric) as harvest_project_task_hourly_rate,
      cast(budget as numeric) as harvest_project_task_budget,

      cast(is_active as boolean) as harvest_project_task_is_active,
      cast(billable as boolean) as harvest_project_task_is_billable,

      cast(created_at as timestamp) as harvest_project_task_created_at,
      cast(updated_at as timestamp) as harvest_project_task_updated_at

   from source

)

select * from base;


[0m09:38:32.658192 [debug] [Thread-8  ]: On model.wire_harvest.stg_harvest__projects: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__projects"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__projects`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`projects`    

),

deduplicated as (

   select unique.*
    from (
        select
            array_agg (
                original
                order by updated_at desc
                limit 1
            )[offset(0)] unique
        from source original
        group by id
    )

),

base as (

   select

      cast(id as numeric) as harvest_project_natural_key,
      cast(client_id as numeric) as harvest_client_natural_key,

      lower(cast(name as string)) as harvest_project_name,
      lower(cast(code as string)) as harvest_project_code,
      lower(cast(notes as string)) as harvest_project_notes,

      lower(cast(bill_by as string)) as harvest_project_bill_by,
      lower(cast(budget_by as string)) as harvest_project_budget_by,

      cast(hourly_rate as numeric) as harvest_project_hourly_rate,
      cast(cost_budget as numeric) as harvest_project_cost_budget,
      cast(fee as numeric) as harvest_project_fee,
      cast(budget as numeric) as harvest_project_budget,
      cast(over_budget_notification_percentage as numeric) as harvest_project_over_budget_notification_percentage,

      cast(show_budget_to_all as boolean) as harvest_project_show_budget_to_all,
      cast(cost_budget_include_expenses as boolean) as harvest_project_cost_budget_include_expenses,
      cast(budget_is_monthly as boolean) as harvest_project_budget_is_monthly,
      cast(notify_when_over_budget as boolean) as harvest_project_notify_when_over_budget,
      cast(is_billable as boolean) as harvest_project_is_billable,
      cast(is_fixed_fee as boolean) as harvest_project_is_fixed_fee,
      cast(is_active as boolean) as harvest_project_is_active,

      cast(over_budget_notification_date as timestamp) as harvest_project_over_budget_notification_date,
      cast(created_at as timestamp) as harvest_project_created_at,
      cast(ends_on as timestamp) as harvest_project_ends_on,
      cast(updated_at as timestamp) as harvest_project_updated_at,
      cast(starts_on as timestamp) as harvest_project_starts_on

   from deduplicated

)

select * from base;


[0m09:38:32.674591 [debug] [Thread-5  ]: On model.wire_harvest.stg_harvest__roles: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__roles"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__roles`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`roles`    

),

base as (

   select

      cast(id as numeric) as harvest_role_natural_key,

      lower(cast(name as string)) as harvest_role_name,

      cast(created_at as timestamp) as harvest_role_created_at_ts,
      cast(updated_at as timestamp) as harvest_role_updated_at_ts

   from source

)

select * from base;


[0m09:38:32.685881 [debug] [Thread-1  ]: On model.wire_harvest.stg_harvest__tasks: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__tasks"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__tasks`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`tasks`    

),

deduplicated as (

   select unique.*
    from (
        select
            array_agg (
                original
                order by _sdc_batched_at desc
                limit 1
            )[offset(0)] unique
        from source original
        group by id
    )

),

base as (

   select

      cast(id as numeric) as harvest_task_natural_key,

      lower(cast(name as string)) as harvest_task_name,

      cast(default_hourly_rate as numeric) as harvest_task_default_hourly_rate,

      cast(billable_by_default as boolean) as harvest_task_is_billable_by_default,
      cast(is_default as boolean) as harvest_task_is_default,
      cast(is_active as boolean) as harvest_task_is_active,

      cast(created_at as timestamp) as harvest_task_created_at_ts,
      cast(updated_at as timestamp) as harvest_task_updated_at_ts

   from deduplicated

)

select * from base;


[0m09:38:32.688831 [debug] [Thread-7  ]: On model.wire_harvest.stg_harvest__time_sheets: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__time_sheets"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__time_sheets`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`stitch_harvest`.`time_entries`    

),

deduplicated as (

    select unique.*
    from (
        select
            array_agg (
                original
                order by updated_at desc
                limit 1
            )[offset(0)] unique
        from source original
        group by id
    )

),

base as (

    select distinct
        
        
    
to_hex(md5(cast(coalesce(cast(id as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(updated_at as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_timesheet_sk,

        cast(id as numeric) harvest_timesheet_natural_key,
        cast(user_id as numeric) as harvest_employee_natural_key,
        cast(task_id as numeric) as harvest_task_natural_key,
        cast(task_assignment_id as numeric) as harvest_task_assignment_natural_key,
        cast(user_assignment_id as numeric) as harvest_employee_assignment_natural_key,
        cast(invoice_id as numeric) as harvest_invoice_natural_key,
        cast(project_id as numeric) as harvest_project_natural_key,
        cast(external_reference_id as numeric) as harvest_external_reference_natural_key,
        cast(client_id as numeric) as harvest_client_natural_key,

        lower(cast(notes as string)) harvest_timesheet_notes,
        lower(cast(locked_reason as string)) harvest_timesheet_locked_reason,

        cast(billable_rate as numeric) as harvest_timesheet_billable_rate,
        cast(cost_rate as numeric) as harvest_timesheet_cost_rate,
        cast(hours as numeric) as harvest_timesheet_hours,
        cast(budgeted as numeric) as harvest_timesheet_hours_budgeted,

        cast(billable as boolean) as harvest_timesheet_is_billable,
        cast(is_closed as boolean) as harvest_timesheet_is_closed,
        cast(is_running as boolean) as harvest_timesheet_is_running,
        cast(is_billed as boolean) as harvest_timesheet_is_billed,
        cast(is_locked as boolean) as harvest_timesheet_is_locked,

        cast(started_time as string) as harvest_timesheet_started_at,
        cast(timer_started_at as timestamp) as harvest_timesheet_timer_started_at_ts,
        cast(created_at as timestamp) as harvest_timesheet_created_at_ts,
        cast(updated_at as timestamp) as harvest_timesheet_updated_at_ts,
        cast(spent_date as timestamp) as harvest_timesheet_spent_at_ts
    
    from deduplicated  

)

select * from base;


[0m09:38:32.699146 [debug] [Thread-4  ]: On model.wire_harvest.stg_harvest__time_sheet_external_reference: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.stg_harvest__time_sheet_external_reference"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__time_sheet_external_reference`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

   select * from `ra-development`.`stitch_harvest`.`time_entry_external_reference`    

),

base as (

   select

      cast(time_entry_id as numeric) as harvest_timesheet_natural_key,
      cast(external_reference_id as numeric) as harvest_external_reference_natural_key,

   from source

)

select * from base;


[0m09:38:32.972439 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:5a8965d2-75f4-4992-a267-646fbcaaecf2:europe-west2&page=queryresults
[0m09:38:33.037897 [info ] [Thread-6  ]: 24 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__invoices  [[32mCREATE VIEW (0 processed)[0m in 1.06s]
[0m09:38:33.038878 [debug] [Thread-6  ]: Finished running node model.wire_harvest.stg_harvest__invoices
[0m09:38:33.039163 [debug] [Thread-6  ]: Began running node model.wire_jira.stg_jira__boards
[0m09:38:33.039693 [info ] [Thread-6  ]: 32 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__boards .... [RUN]
[0m09:38:33.040874 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__boards"
[0m09:38:33.041120 [debug] [Thread-6  ]: Began compiling node model.wire_jira.stg_jira__boards
[0m09:38:33.041314 [debug] [Thread-6  ]: Compiling model.wire_jira.stg_jira__boards
[0m09:38:33.168226 [debug] [Thread-6  ]: Writing injected SQL for node "model.wire_jira.stg_jira__boards"
[0m09:38:33.168787 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:33.168885 [debug] [Thread-6  ]: Began executing node model.wire_jira.stg_jira__boards
[0m09:38:33.179758 [debug] [Thread-6  ]: Writing runtime sql for node "model.wire_jira.stg_jira__boards"
[0m09:38:33.180364 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:33.248709 [debug] [Thread-6  ]: On model.wire_jira.stg_jira__boards: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__boards"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__boards`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`board`    

),

base as (

    select
	
        lower(cast(id as string)) as jira_board_natural_key,

        lower(cast(name as string)) as jira_board_name,
        lower(cast(type as string)) as jira_board_type

    from source

)

select * from base;


[0m09:38:33.309355 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:2f54dd63-38f7-40a6-ae77-c3519cb935de:europe-west2&page=queryresults
[0m09:38:33.315699 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:7a3275fd-de3c-4b98-b772-bd0b11f3c4b1:europe-west2&page=queryresults
[0m09:38:33.329118 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:f1a64bfb-7e97-4b3c-b814-ca90057b9482:europe-west2&page=queryresults
[0m09:38:33.342068 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:58f532f5-8ca0-4670-b627-65b292be2d92:europe-west2&page=queryresults
[0m09:38:33.364944 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:d2b19d8d-92cf-436c-98c6-0b4aac3ca491:europe-west2&page=queryresults
[0m09:38:33.369562 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:33.370293 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133296be0>]}
[0m09:38:33.371001 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:c4b6ee28-9851-4845-ad23-a63d6316fcd5:europe-west2&page=queryresults
[0m09:38:33.371239 [info ] [Thread-3  ]: 25 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__project_users  [[32mCREATE VIEW (0 processed)[0m in 1.17s]
[0m09:38:33.373118 [debug] [Thread-3  ]: Finished running node model.wire_harvest.stg_harvest__project_users
[0m09:38:33.373264 [debug] [Thread-3  ]: Began running node model.wire_jira.stg_jira__epics
[0m09:38:33.373761 [info ] [Thread-3  ]: 33 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__epics ..... [RUN]
[0m09:38:33.374182 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__epics"
[0m09:38:33.374272 [debug] [Thread-3  ]: Began compiling node model.wire_jira.stg_jira__epics
[0m09:38:33.374474 [debug] [Thread-3  ]: Compiling model.wire_jira.stg_jira__epics
[0m09:38:33.377555 [debug] [Thread-3  ]: Writing injected SQL for node "model.wire_jira.stg_jira__epics"
[0m09:38:33.378257 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:33.378391 [debug] [Thread-3  ]: Began executing node model.wire_jira.stg_jira__epics
[0m09:38:33.381261 [debug] [Thread-3  ]: Writing runtime sql for node "model.wire_jira.stg_jira__epics"
[0m09:38:33.381631 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:33.452804 [debug] [Thread-3  ]: On model.wire_jira.stg_jira__epics: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__epics"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__epics`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`epic`    

),

base as (

    select
	
        cast(id as numeric) as jira_epic_natural_key,

        lower(cast(name as string)) as jira_epic_name,
        lower(cast(summary as string)) as jira_epic_summary,
        cast(done as boolean) as jira_epic_is_done,
        lower(cast(key as string)) as jira_epic_key
 
    from source

)

select * from base;


[0m09:38:33.576342 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:33.576952 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133638670>]}
[0m09:38:33.577228 [info ] [Thread-8  ]: 26 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__projects  [[32mCREATE VIEW (0 processed)[0m in 1.06s]
[0m09:38:33.577610 [debug] [Thread-8  ]: Finished running node model.wire_harvest.stg_harvest__projects
[0m09:38:33.577751 [debug] [Thread-8  ]: Began running node model.wire_jira.stg_jira__fields
[0m09:38:33.577902 [info ] [Thread-8  ]: 34 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__fields .... [RUN]
[0m09:38:33.578508 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__fields"
[0m09:38:33.578912 [debug] [Thread-8  ]: Began compiling node model.wire_jira.stg_jira__fields
[0m09:38:33.579081 [debug] [Thread-8  ]: Compiling model.wire_jira.stg_jira__fields
[0m09:38:33.584289 [debug] [Thread-8  ]: Writing injected SQL for node "model.wire_jira.stg_jira__fields"
[0m09:38:33.584762 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:33.584886 [debug] [Thread-8  ]: Began executing node model.wire_jira.stg_jira__fields
[0m09:38:33.588072 [debug] [Thread-8  ]: Writing runtime sql for node "model.wire_jira.stg_jira__fields"
[0m09:38:33.588416 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:33.603883 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:33.604307 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127ec2040>]}
[0m09:38:33.604510 [info ] [Thread-2  ]: 27 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__projects_tasks  [[32mCREATE VIEW (0 processed)[0m in 1.08s]
[0m09:38:33.604762 [debug] [Thread-2  ]: Finished running node model.wire_harvest.stg_harvest__projects_tasks
[0m09:38:33.604868 [debug] [Thread-2  ]: Began running node model.wire_jira.stg_jira__issue_board
[0m09:38:33.605059 [info ] [Thread-2  ]: 35 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__issue_board  [RUN]
[0m09:38:33.605424 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__issue_board"
[0m09:38:33.605507 [debug] [Thread-2  ]: Began compiling node model.wire_jira.stg_jira__issue_board
[0m09:38:33.605586 [debug] [Thread-2  ]: Compiling model.wire_jira.stg_jira__issue_board
[0m09:38:33.608213 [debug] [Thread-2  ]: Writing injected SQL for node "model.wire_jira.stg_jira__issue_board"
[0m09:38:33.608520 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:33.608609 [debug] [Thread-2  ]: Began executing node model.wire_jira.stg_jira__issue_board
[0m09:38:33.610867 [debug] [Thread-2  ]: Writing runtime sql for node "model.wire_jira.stg_jira__issue_board"
[0m09:38:33.611095 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m09:38:33.615575 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:33.615990 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127ece1c0>]}
[0m09:38:33.616193 [info ] [Thread-5  ]: 28 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__roles  [[32mCREATE VIEW (0 processed)[0m in 1.07s]
[0m09:38:33.616429 [debug] [Thread-5  ]: Finished running node model.wire_harvest.stg_harvest__roles
[0m09:38:33.616533 [debug] [Thread-5  ]: Began running node model.wire_jira.stg_jira__issues
[0m09:38:33.616642 [info ] [Thread-5  ]: 36 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__issues .... [RUN]
[0m09:38:33.616966 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__issues"
[0m09:38:33.617127 [debug] [Thread-5  ]: Began compiling node model.wire_jira.stg_jira__issues
[0m09:38:33.617236 [debug] [Thread-5  ]: Compiling model.wire_jira.stg_jira__issues
[0m09:38:33.620345 [debug] [Thread-5  ]: Writing injected SQL for node "model.wire_jira.stg_jira__issues"
[0m09:38:33.620793 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:33.620884 [debug] [Thread-5  ]: Began executing node model.wire_jira.stg_jira__issues
[0m09:38:33.624324 [debug] [Thread-5  ]: Writing runtime sql for node "model.wire_jira.stg_jira__issues"
[0m09:38:33.625181 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:33.625518 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127eb81c0>]}
[0m09:38:33.625715 [info ] [Thread-1  ]: 29 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__tasks  [[32mCREATE VIEW (0 processed)[0m in 1.08s]
[0m09:38:33.625956 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:33.626157 [debug] [Thread-1  ]: Finished running node model.wire_harvest.stg_harvest__tasks
[0m09:38:33.626277 [debug] [Thread-1  ]: Began running node model.wire_jira.stg_jira__issues_field_history
[0m09:38:33.626663 [info ] [Thread-1  ]: 37 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__issues_field_history  [RUN]
[0m09:38:33.627235 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__issues_field_history"
[0m09:38:33.627314 [debug] [Thread-1  ]: Began compiling node model.wire_jira.stg_jira__issues_field_history
[0m09:38:33.627384 [debug] [Thread-1  ]: Compiling model.wire_jira.stg_jira__issues_field_history
[0m09:38:33.630217 [debug] [Thread-1  ]: Writing injected SQL for node "model.wire_jira.stg_jira__issues_field_history"
[0m09:38:33.630600 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:33.630683 [debug] [Thread-1  ]: Began executing node model.wire_jira.stg_jira__issues_field_history
[0m09:38:33.632799 [debug] [Thread-1  ]: Writing runtime sql for node "model.wire_jira.stg_jira__issues_field_history"
[0m09:38:33.633008 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:33.638630 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:33.639549 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133675b50>]}
[0m09:38:33.639971 [info ] [Thread-4  ]: 30 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__time_sheet_external_reference  [[32mCREATE VIEW (0 processed)[0m in 1.07s]
[0m09:38:33.640502 [debug] [Thread-4  ]: Finished running node model.wire_harvest.stg_harvest__time_sheet_external_reference
[0m09:38:33.641101 [debug] [Thread-4  ]: Began running node model.wire_jira.stg_jira__project_board
[0m09:38:33.641575 [info ] [Thread-4  ]: 38 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__project_board  [RUN]
[0m09:38:33.642520 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__project_board"
[0m09:38:33.643037 [debug] [Thread-4  ]: Began compiling node model.wire_jira.stg_jira__project_board
[0m09:38:33.643234 [debug] [Thread-4  ]: Compiling model.wire_jira.stg_jira__project_board
[0m09:38:33.646307 [debug] [Thread-4  ]: Writing injected SQL for node "model.wire_jira.stg_jira__project_board"
[0m09:38:33.647280 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:33.647575 [debug] [Thread-4  ]: Began executing node model.wire_jira.stg_jira__project_board
[0m09:38:33.650402 [debug] [Thread-4  ]: Writing runtime sql for node "model.wire_jira.stg_jira__project_board"
[0m09:38:33.651916 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:33.654102 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126fd2730>]}
[0m09:38:33.654910 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:33.655548 [info ] [Thread-7  ]: 31 of 110 OK created sql view model lewis_analytics_dev_staging.stg_harvest__time_sheets  [[32mCREATE VIEW (0 processed)[0m in 1.08s]
[0m09:38:33.656647 [debug] [Thread-7  ]: Finished running node model.wire_harvest.stg_harvest__time_sheets
[0m09:38:33.657068 [debug] [Thread-7  ]: Began running node model.wire_jira.stg_jira__projects
[0m09:38:33.657918 [info ] [Thread-7  ]: 39 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__projects .. [RUN]
[0m09:38:33.660607 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__projects"
[0m09:38:33.660936 [debug] [Thread-7  ]: Began compiling node model.wire_jira.stg_jira__projects
[0m09:38:33.661185 [debug] [Thread-7  ]: Compiling model.wire_jira.stg_jira__projects
[0m09:38:33.667815 [debug] [Thread-7  ]: Writing injected SQL for node "model.wire_jira.stg_jira__projects"
[0m09:38:33.668189 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:33.668274 [debug] [Thread-7  ]: Began executing node model.wire_jira.stg_jira__projects
[0m09:38:33.671671 [debug] [Thread-7  ]: Writing runtime sql for node "model.wire_jira.stg_jira__projects"
[0m09:38:33.671910 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:33.672841 [debug] [Thread-8  ]: On model.wire_jira.stg_jira__fields: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__fields"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__fields`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`field`    

),

base as (

    select
	
        lower(cast(id as string)) as jira_field_natural_key,

        lower(cast(name as string)) as jira_field_name,

        cast(is_array as boolean) as jira_field_is_array,
        cast(is_custom as boolean) as jira_field_is_custom

    from source

)

select * from base;


[0m09:38:33.685051 [debug] [Thread-2  ]: On model.wire_jira.stg_jira__issue_board: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__issue_board"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__issue_board`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`issue_board`    

),

base as (

    select
	
        lower(cast(board_id as string)) as jira_board_natural_key,	
        cast(issue_id as numeric) as jira_issue_natural_key

    from source

)

select * from base;


[0m09:38:33.709016 [debug] [Thread-1  ]: On model.wire_jira.stg_jira__issues_field_history: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__issues_field_history"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__issues_field_history`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`issue_field_history`    

),

base as (

    select

        lower(cast(field_id as string)) as jira_field_natural_key,
        lower(cast(author_id as string)) as jira_issue_field_history_author_natural_key,
        cast(issue_id as numeric) as jira_issue_natural_key,

        lower(cast(value as string)) as jira_issue_field_history_value,
   
        cast(is_active as boolean) as jira_issue_field_history_is_active,

        cast(time as timestamp) as jira_issue_field_history_timestamp        
        
    from source

)

select * from base;


[0m09:38:33.719460 [debug] [Thread-5  ]: On model.wire_jira.stg_jira__issues: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__issues"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__issues`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`issue`    

),

base as (

    select

        cast(id as numeric) as jira_issue_natural_key,
        cast(parent_id as numeric) as jira_issue_parent_natural_key,
        cast(status as numeric) as jira_status_natural_key,

        lower(cast(summary as string)) as jira_issue_summary,
        lower(cast(description as string)) as jira_issue_description,
        lower(cast(project as string)) as jira_issue_project,
        lower(cast(assignee as string)) as jira_issue_assignee,
        lower(cast(reporter as string)) as jira_issue_reporter,
        lower(cast(priority as string)) as jira_issue_priority,
        lower(cast(creator as string)) as jira_issue_creator,
        lower(cast(issue_type as string)) as jira_issue_issue_type,
        lower(cast(key as string)) as jira_issue_key,

        cast(original_estimate as numeric) as jira_issue_original_estimate,
        cast(remaining_estimate as numeric) as jira_issue_remaining_estimate,

        cast(status_category_changed as timestamp) as jira_issue_status_category_changed_at_ts,
        cast(resolved as timestamp) as jira_issue_resolved_at_ts,
        cast(last_viewed as timestamp) as jira_issue_last_viewed_at_ts,
        cast(due_date as timestamp) as jira_issue_due_date_at_ts,
        cast(created as timestamp) as jira_issue_created_at_ts,
        cast(updated as timestamp) as jira_issue_updated_at_ts

    from source

)

select * from base;


[0m09:38:33.750012 [debug] [Thread-4  ]: On model.wire_jira.stg_jira__project_board: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__project_board"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__project_board`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`project_board`    

),

base as (

    select
	
        lower(cast(board_id as string)) as jira_board_natural_key,	
        cast(project_id as numeric) as jira_project_natural_key

    from source

)

select * from base;


[0m09:38:33.752329 [debug] [Thread-7  ]: On model.wire_jira.stg_jira__projects: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__projects"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__projects`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`project`    

),

base as (

    select

        cast(id as numeric) as jira_project_natural_key,
        lower(cast(lead_id as string)) as jira_project_lead_natural_key,

        lower(cast(name as string)) as jira_project_name,
        lower(cast(description as string)) as jira_project_description,
        lower(cast(key as string)) as jira_project_key,
        lower(cast(project_type_key as string)) as jira_project_project_type_key
        
    from source

)

select * from base;


[0m09:38:33.901082 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:5acd4b66-a13d-4ba9-882b-5f1ccc3e8f23:europe-west2&page=queryresults
[0m09:38:34.108980 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:968fc872-a335-4b6f-b7f2-07b109149de2:europe-west2&page=queryresults
[0m09:38:34.161598 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:34.162835 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127e8efd0>]}
[0m09:38:34.163433 [info ] [Thread-6  ]: 32 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__boards  [[32mCREATE VIEW (0 processed)[0m in 1.12s]
[0m09:38:34.164042 [debug] [Thread-6  ]: Finished running node model.wire_jira.stg_jira__boards
[0m09:38:34.164302 [debug] [Thread-6  ]: Began running node model.wire_jira.stg_jira__sprints
[0m09:38:34.164761 [info ] [Thread-6  ]: 40 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__sprints ... [RUN]
[0m09:38:34.165639 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__sprints"
[0m09:38:34.165878 [debug] [Thread-6  ]: Began compiling node model.wire_jira.stg_jira__sprints
[0m09:38:34.166031 [debug] [Thread-6  ]: Compiling model.wire_jira.stg_jira__sprints
[0m09:38:34.171126 [debug] [Thread-6  ]: Writing injected SQL for node "model.wire_jira.stg_jira__sprints"
[0m09:38:34.171760 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:34.171949 [debug] [Thread-6  ]: Began executing node model.wire_jira.stg_jira__sprints
[0m09:38:34.176741 [debug] [Thread-6  ]: Writing runtime sql for node "model.wire_jira.stg_jira__sprints"
[0m09:38:34.177371 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:34.185790 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:eeffba22-1c9e-4572-86d6-6b831f33b232:europe-west2&page=queryresults
[0m09:38:34.272502 [debug] [Thread-6  ]: On model.wire_jira.stg_jira__sprints: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__sprints"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__sprints`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`sprint`    

),

base as (

    select
	
        cast(id as string) as jira_sprint_natural_key,
        lower(cast(board_id as string)) as jira_sprint_board_natural_key,

        lower(cast(name as string)) as jira_sprint_name,
        lower(cast(goal as string)) as jira_sprint_goal,
        lower(cast(state as string)) as jira_sprint_state,

        cast(start_date as date) as jira_start_at_date,
        cast(complete_date as date) as jira_complete_at_date,
        cast(end_date as date) as jira_end_at_date

    from source

)

select * from base;


[0m09:38:34.362040 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:7261a994-a435-459e-84e6-3cac25206730:europe-west2&page=queryresults
[0m09:38:34.374589 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:dd31434d-a68a-4e46-8eae-fc7cfcdebe30:europe-west2&page=queryresults
[0m09:38:34.389613 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:34.390121 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126fd29d0>]}
[0m09:38:34.390382 [info ] [Thread-3  ]: 33 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__epics  [[32mCREATE VIEW (0 processed)[0m in 1.02s]
[0m09:38:34.390693 [debug] [Thread-3  ]: Finished running node model.wire_jira.stg_jira__epics
[0m09:38:34.390824 [debug] [Thread-3  ]: Began running node model.wire_jira.stg_jira__statuses
[0m09:38:34.391101 [info ] [Thread-3  ]: 41 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__statuses .. [RUN]
[0m09:38:34.391663 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__statuses"
[0m09:38:34.391787 [debug] [Thread-3  ]: Began compiling node model.wire_jira.stg_jira__statuses
[0m09:38:34.391895 [debug] [Thread-3  ]: Compiling model.wire_jira.stg_jira__statuses
[0m09:38:34.396221 [debug] [Thread-3  ]: Writing injected SQL for node "model.wire_jira.stg_jira__statuses"
[0m09:38:34.396593 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:34.396699 [debug] [Thread-3  ]: Began executing node model.wire_jira.stg_jira__statuses
[0m09:38:34.399450 [debug] [Thread-3  ]: Writing runtime sql for node "model.wire_jira.stg_jira__statuses"
[0m09:38:34.399726 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:34.412480 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:1edb6ccb-fa61-459c-9728-f98185b3d8b3:europe-west2&page=queryresults
[0m09:38:34.437329 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:98542412-600b-4c82-bffe-a6a5b4308860:europe-west2&page=queryresults
[0m09:38:34.473196 [debug] [Thread-3  ]: On model.wire_jira.stg_jira__statuses: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__statuses"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__statuses`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`status`    

),

base as (

    select
	
        cast(id as numeric) as jira_status_natural_key,
        cast(status_category_id as numeric) as jira_status_category_natural_key,

        lower(cast(description as string)) as jira_status_description,
        lower(cast(name as string)) as jira_status_name
        
    from source

)

select * from base;


[0m09:38:34.474800 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:34.475407 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ffc670>]}
[0m09:38:34.475648 [info ] [Thread-7  ]: 39 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__projects  [[32mCREATE VIEW (0 processed)[0m in 0.82s]
[0m09:38:34.475888 [debug] [Thread-7  ]: Finished running node model.wire_jira.stg_jira__projects
[0m09:38:34.476014 [debug] [Thread-7  ]: Began running node model.wire_jira.stg_jira__users
[0m09:38:34.476114 [info ] [Thread-7  ]: 42 of 110 START sql view model lewis_analytics_dev_staging.stg_jira__users ..... [RUN]
[0m09:38:34.476409 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.wire_jira.stg_jira__users"
[0m09:38:34.476593 [debug] [Thread-7  ]: Began compiling node model.wire_jira.stg_jira__users
[0m09:38:34.476686 [debug] [Thread-7  ]: Compiling model.wire_jira.stg_jira__users
[0m09:38:34.479228 [debug] [Thread-7  ]: Writing injected SQL for node "model.wire_jira.stg_jira__users"
[0m09:38:34.479944 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:34.480050 [debug] [Thread-7  ]: Began executing node model.wire_jira.stg_jira__users
[0m09:38:34.482777 [debug] [Thread-7  ]: Writing runtime sql for node "model.wire_jira.stg_jira__users"
[0m09:38:34.483296 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:34.552337 [debug] [Thread-7  ]: On model.wire_jira.stg_jira__users: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.stg_jira__users"} */


  create or replace view `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__users`
  OPTIONS(
      description=""""""
    )
  as 

with source as (

    select * from `ra-development`.`fivetran_jira`.`user`    

),

base as (

    select
	
        lower(cast(id as string)) as jira_user_natural_key,

        lower(cast(name as string)) as jira_user_name,
        lower(cast(email as string)) as jira_user_email,
        lower(cast(locale as string)) as jira_user_locale,
        lower(cast(time_zone as string)) as jira_user_time_zone

    from source

)

select * from base;


[0m09:38:34.629553 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:f93c9984-ee7e-4911-bf22-fd5493f26788:europe-west2&page=queryresults
[0m09:38:34.640309 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:34.640809 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126901c10>]}
[0m09:38:34.641087 [info ] [Thread-8  ]: 34 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__fields  [[32mCREATE VIEW (0 processed)[0m in 1.06s]
[0m09:38:34.641383 [debug] [Thread-8  ]: Finished running node model.wire_jira.stg_jira__fields
[0m09:38:34.641512 [debug] [Thread-8  ]: Began running node model.jira_source.stg_jira__field
[0m09:38:34.641758 [info ] [Thread-8  ]: 43 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__field  [RUN]
[0m09:38:34.642290 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__field"
[0m09:38:34.642408 [debug] [Thread-8  ]: Began compiling node model.jira_source.stg_jira__field
[0m09:38:34.642513 [debug] [Thread-8  ]: Compiling model.jira_source.stg_jira__field
[0m09:38:34.647738 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:34.696760 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:34.697153 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126dff190>]}
[0m09:38:34.697326 [info ] [Thread-4  ]: 38 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__project_board  [[32mCREATE VIEW (0 processed)[0m in 1.06s]
[0m09:38:34.697530 [debug] [Thread-4  ]: Finished running node model.wire_jira.stg_jira__project_board
[0m09:38:34.697625 [debug] [Thread-4  ]: Began running node model.jira_source.stg_jira__field_option
[0m09:38:34.697722 [info ] [Thread-4  ]: 44 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__field_option  [RUN]
[0m09:38:34.698000 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__field_option"
[0m09:38:34.698070 [debug] [Thread-4  ]: Began compiling node model.jira_source.stg_jira__field_option
[0m09:38:34.698136 [debug] [Thread-4  ]: Compiling model.jira_source.stg_jira__field_option
[0m09:38:34.700589 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:34.704357 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:34.704710 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127b72fa0>]}
[0m09:38:34.704884 [info ] [Thread-1  ]: 37 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__issues_field_history  [[32mCREATE VIEW (0 processed)[0m in 1.08s]
[0m09:38:34.705092 [debug] [Thread-1  ]: Finished running node model.wire_jira.stg_jira__issues_field_history
[0m09:38:34.705612 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:34.705703 [debug] [Thread-1  ]: Began running node model.jira_source.stg_jira__comment
[0m09:38:34.706016 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126fd24f0>]}
[0m09:38:34.706182 [info ] [Thread-1  ]: 45 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__comment  [RUN]
[0m09:38:34.706395 [info ] [Thread-2  ]: 35 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__issue_board  [[32mCREATE VIEW (0 processed)[0m in 1.10s]
[0m09:38:34.706717 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__comment"
[0m09:38:34.706926 [debug] [Thread-2  ]: Finished running node model.wire_jira.stg_jira__issue_board
[0m09:38:34.707027 [debug] [Thread-1  ]: Began compiling node model.jira_source.stg_jira__comment
[0m09:38:34.707125 [debug] [Thread-2  ]: Began running node model.jira_source.stg_jira__issue_field_history
[0m09:38:34.707268 [debug] [Thread-1  ]: Compiling model.jira_source.stg_jira__comment
[0m09:38:34.707383 [info ] [Thread-2  ]: 46 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__issue_field_history  [RUN]
[0m09:38:34.710154 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:34.710474 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__issue_field_history"
[0m09:38:34.710578 [debug] [Thread-2  ]: Began compiling node model.jira_source.stg_jira__issue_field_history
[0m09:38:34.710648 [debug] [Thread-2  ]: Compiling model.jira_source.stg_jira__issue_field_history
[0m09:38:34.714116 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m09:38:34.885243 [debug] [Thread-8  ]: Writing injected SQL for node "model.jira_source.stg_jira__field"
[0m09:38:34.885653 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:34.885761 [debug] [Thread-8  ]: Began executing node model.jira_source.stg_jira__field
[0m09:38:34.920434 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:54024b22-77b3-470f-8b79-97e260ad7613:europe-west2&page=queryresults
[0m09:38:34.922468 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:34.923153 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1329ba520>]}
[0m09:38:34.923738 [info ] [Thread-5  ]: 36 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__issues  [[32mCREATE VIEW (0 processed)[0m in 1.31s]
[0m09:38:34.924126 [debug] [Thread-5  ]: Finished running node model.wire_jira.stg_jira__issues
[0m09:38:34.924248 [debug] [Thread-5  ]: Began running node model.jira_source.stg_jira__component
[0m09:38:34.924452 [info ] [Thread-5  ]: 47 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__component  [RUN]
[0m09:38:34.925146 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__component"
[0m09:38:34.925253 [debug] [Thread-5  ]: Began compiling node model.jira_source.stg_jira__component
[0m09:38:34.925353 [debug] [Thread-5  ]: Compiling model.jira_source.stg_jira__component
[0m09:38:34.930045 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:34.944975 [debug] [Thread-4  ]: Writing injected SQL for node "model.jira_source.stg_jira__field_option"
[0m09:38:34.945312 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:34.945403 [debug] [Thread-4  ]: Began executing node model.jira_source.stg_jira__field_option
[0m09:38:34.949533 [debug] [Thread-2  ]: Writing injected SQL for node "model.jira_source.stg_jira__issue_field_history"
[0m09:38:34.949997 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:34.950087 [debug] [Thread-2  ]: Began executing node model.jira_source.stg_jira__issue_field_history
[0m09:38:34.957148 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira_source.stg_jira__comment"
[0m09:38:34.957392 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:34.957470 [debug] [Thread-1  ]: Began executing node model.jira_source.stg_jira__comment
[0m09:38:34.993898 [debug] [Thread-8  ]: Writing runtime sql for node "model.jira_source.stg_jira__field"
[0m09:38:34.994274 [debug] [Thread-8  ]: On model.jira_source.stg_jira__field: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__field"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field`
    
    
    OPTIONS(
      description="""Table of all issue fields."""
    )
    as (
      with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    is_array
    
 as 
    
    is_array
    
, 
    
    
    is_custom
    
 as 
    
    is_custom
    
, 
    
    
    name
    
 as 
    
    name
    



    from base
),

final as (
    
    select 
        cast(id as STRING) as field_id,
        is_array,
        is_custom,
        name as field_name,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:35.043459 [debug] [Thread-1  ]: Writing runtime sql for node "model.jira_source.stg_jira__comment"
[0m09:38:35.044288 [debug] [Thread-4  ]: Writing runtime sql for node "model.jira_source.stg_jira__field_option"
[0m09:38:35.044643 [debug] [Thread-4  ]: On model.jira_source.stg_jira__field_option: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__field_option"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field_option`
    
    
    OPTIONS(
      description="""Table of all options related to custom fields."""
    )
    as (
      with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field_option_tmp`
),

fields as (

    select
        
    
    
    id
    
 as 
    
    id
    
, 
    
    
    parent_id
    
 as 
    
    parent_id
    
, 
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    name
    
 as 
    
    name
    



    from base
),

final as (
    
    select 
        id as field_id,
        parent_id as parent_field_id,
        name as field_option_name
    from fields
)

select * 
from final
    );
  
[0m09:38:35.044755 [debug] [Thread-1  ]: On model.jira_source.stg_jira__comment: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__comment"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__comment`
    
    
    OPTIONS(
      description="""Table of comments made on issues."""
    )
    as (
      with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__comment_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    author_id
    
 as 
    
    author_id
    
, 
    
    
    body
    
 as 
    
    body
    
, 
    
    
    created
    
 as 
    
    created
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    is_public
    
 as 
    
    is_public
    
, 
    
    
    issue_id
    
 as 
    
    issue_id
    
, 
    
    
    update_author_id
    
 as 
    
    update_author_id
    
, 
    
    
    updated
    
 as 
    
    updated
    



    from base
),

final as (
    
    select 
        author_id as author_user_id,
        body,
        cast(created as TIMESTAMP) as created_at,
        id as comment_id,
        issue_id,
        is_public,
        update_author_id as last_update_user_id,
        cast(updated as TIMESTAMP) as last_updated_at,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:35.054957 [debug] [Thread-2  ]: Writing runtime sql for node "model.jira_source.stg_jira__issue_field_history"
[0m09:38:35.055294 [debug] [Thread-2  ]: On model.jira_source.stg_jira__issue_field_history: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__issue_field_history"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_field_history`
    
    
    OPTIONS(
      description="""Table of every value that each **custom non-array** (not multiselect) field has been set to."""
    )
    as (
      with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_field_history_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    field_id
    
 as 
    
    field_id
    
, 
    
    
    issue_id
    
 as 
    
    issue_id
    
, 
    
    
    value
    
 as 
    
    value
    
, 
    
    
    time
    
 as 
    
    time
    



    from base
),

final as (
    
    select 
        cast(field_id as STRING) as field_id,
        issue_id,
        cast(time as TIMESTAMP)
         as updated_at,
        value as field_value,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:35.127113 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:3c44a608-c965-4115-92f5-293899a59a65:europe-west2&page=queryresults
[0m09:38:35.189985 [debug] [Thread-5  ]: Writing injected SQL for node "model.jira_source.stg_jira__component"
[0m09:38:35.190621 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:35.190795 [debug] [Thread-5  ]: Began executing node model.jira_source.stg_jira__component
[0m09:38:35.199901 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:35.200569 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ffc9d0>]}
[0m09:38:35.201707 [info ] [Thread-6  ]: 40 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__sprints  [[32mCREATE VIEW (0 processed)[0m in 1.04s]
[0m09:38:35.202348 [debug] [Thread-6  ]: Finished running node model.wire_jira.stg_jira__sprints
[0m09:38:35.202582 [debug] [Thread-6  ]: Began running node model.jira_source.stg_jira__issue_link
[0m09:38:35.203256 [info ] [Thread-6  ]: 48 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__issue_link  [RUN]
[0m09:38:35.204504 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__issue_link"
[0m09:38:35.204742 [debug] [Thread-6  ]: Began compiling node model.jira_source.stg_jira__issue_link
[0m09:38:35.205157 [debug] [Thread-6  ]: Compiling model.jira_source.stg_jira__issue_link
[0m09:38:35.210356 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:35.264888 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:4d503240-5f1d-4be8-b624-395cbf8bb8cb:europe-west2&page=queryresults
[0m09:38:35.292505 [debug] [Thread-5  ]: Writing runtime sql for node "model.jira_source.stg_jira__component"
[0m09:38:35.293994 [debug] [Thread-5  ]: On model.jira_source.stg_jira__component: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__component"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__component`
    
    
    OPTIONS(
      description="""Table of project components (subsections to group issues)."""
    )
    as (
      

with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__component_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    description
    
 as 
    
    description
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    name
    
 as 
    
    name
    
, 
    
    
    project_id
    
 as 
    
    project_id
    



    from base
),

final as (
    
    select 
        description as component_description,
        id as component_id,
        name as component_name,
        project_id,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:35.392003 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:35.392537 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ffcca0>]}
[0m09:38:35.392830 [info ] [Thread-3  ]: 41 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__statuses  [[32mCREATE VIEW (0 processed)[0m in 1.00s]
[0m09:38:35.393198 [debug] [Thread-3  ]: Finished running node model.wire_jira.stg_jira__statuses
[0m09:38:35.393347 [debug] [Thread-3  ]: Began running node model.jira_source.stg_jira__issue_multiselect_history
[0m09:38:35.393591 [info ] [Thread-3  ]: 49 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__issue_multiselect_history  [RUN]
[0m09:38:35.394106 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__issue_multiselect_history"
[0m09:38:35.394226 [debug] [Thread-3  ]: Began compiling node model.jira_source.stg_jira__issue_multiselect_history
[0m09:38:35.394337 [debug] [Thread-3  ]: Compiling model.jira_source.stg_jira__issue_multiselect_history
[0m09:38:35.399641 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:35.461958 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira_source.stg_jira__issue_link"
[0m09:38:35.462301 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:35.462388 [debug] [Thread-6  ]: Began executing node model.jira_source.stg_jira__issue_link
[0m09:38:35.529142 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:35.529624 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12703f130>]}
[0m09:38:35.529862 [info ] [Thread-7  ]: 42 of 110 OK created sql view model lewis_analytics_dev_staging.stg_jira__users  [[32mCREATE VIEW (0 processed)[0m in 1.05s]
[0m09:38:35.530147 [debug] [Thread-7  ]: Finished running node model.wire_jira.stg_jira__users
[0m09:38:35.530274 [debug] [Thread-7  ]: Began running node model.jira_source.stg_jira__issue
[0m09:38:35.530488 [info ] [Thread-7  ]: 50 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__issue  [RUN]
[0m09:38:35.530927 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__issue"
[0m09:38:35.531043 [debug] [Thread-7  ]: Began compiling node model.jira_source.stg_jira__issue
[0m09:38:35.531131 [debug] [Thread-7  ]: Compiling model.jira_source.stg_jira__issue
[0m09:38:35.535777 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:35.554186 [debug] [Thread-6  ]: Writing runtime sql for node "model.jira_source.stg_jira__issue_link"
[0m09:38:35.554642 [debug] [Thread-6  ]: On model.jira_source.stg_jira__issue_link: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__issue_link"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_link`
    
    
    OPTIONS(
      description="""Table of relationships (links) created between issues. Issue links can include blockers, clones/duplicates, and general relationships.\n"""
    )
    as (
      with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_link_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    issue_id
    
 as 
    
    issue_id
    
, 
    
    
    related_issue_id
    
 as 
    
    related_issue_id
    
, 
    
    
    relationship
    
 as 
    
    relationship
    



    from base
),

final as (
    
    select 
        issue_id,
        related_issue_id,
        relationship,
        _fivetran_synced 
    from fields
)

select * 
from final
    );
  
[0m09:38:35.650178 [debug] [Thread-3  ]: Writing injected SQL for node "model.jira_source.stg_jira__issue_multiselect_history"
[0m09:38:35.650596 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:35.650712 [debug] [Thread-3  ]: Began executing node model.jira_source.stg_jira__issue_multiselect_history
[0m09:38:35.749231 [debug] [Thread-3  ]: Writing runtime sql for node "model.jira_source.stg_jira__issue_multiselect_history"
[0m09:38:35.749805 [debug] [Thread-3  ]: On model.jira_source.stg_jira__issue_multiselect_history: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__issue_multiselect_history"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_multiselect_history`
    
    
    OPTIONS(
      description="""Table of every value that each array-type (multiselect) field has been set to. Each row will pertain to **one** value.\n"""
    )
    as (
      with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_multiselect_history_tmp`
),

fields as (

    select
        
    
    
    _fivetran_id
    
 as 
    
    _fivetran_id
    
, 
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    field_id
    
 as 
    
    field_id
    
, 
    
    
    issue_id
    
 as 
    
    issue_id
    
, 
    
    
    value
    
 as 
    
    value
    
, 
    
    
    time
    
 as 
    
    time
    



    from base
),

final as (
    
    select 
        _fivetran_id,
        cast(field_id as STRING) as field_id,
        issue_id,
        
        cast(time as TIMESTAMP)
         as updated_at,
        value as field_value,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:35.812896 [debug] [Thread-7  ]: Writing injected SQL for node "model.jira_source.stg_jira__issue"
[0m09:38:35.813416 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:35.813567 [debug] [Thread-7  ]: Began executing node model.jira_source.stg_jira__issue
[0m09:38:35.907608 [debug] [Thread-7  ]: Writing runtime sql for node "model.jira_source.stg_jira__issue"
[0m09:38:35.908474 [debug] [Thread-7  ]: On model.jira_source.stg_jira__issue: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__issue"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue`
    
    
    OPTIONS(
      description="""Table of all issues in your organization's Jira (captures soft deletes)."""
    )
    as (
      with base as (
    
    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_tmp`
    where not coalesce(_fivetran_deleted, false)
),

fields as (

    select 
        
    
    
    _fivetran_deleted
    
 as 
    
    _fivetran_deleted
    
, 
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    _original_estimate
    
 as 
    
    _original_estimate
    
, 
    
    
    _remaining_estimate
    
 as 
    
    _remaining_estimate
    
, 
    
    
    _time_spent
    
 as 
    
    _time_spent
    
, 
    
    
    assignee
    
 as 
    
    assignee
    
, 
    
    
    created
    
 as 
    
    created
    
, 
    
    
    creator
    
 as 
    
    creator
    
, 
    
    
    description
    
 as 
    
    description
    
, 
    
    
    due_date
    
 as 
    
    due_date
    
, 
    
    
    environment
    
 as 
    
    environment
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    issue_type
    
 as 
    
    issue_type
    
, 
    
    
    key
    
 as 
    
    key
    
, 
    
    
    original_estimate
    
 as 
    
    original_estimate
    
, 
    
    
    parent_id
    
 as 
    
    parent_id
    
, 
    
    
    priority
    
 as 
    
    priority
    
, 
    
    
    project
    
 as 
    
    project
    
, 
    
    
    remaining_estimate
    
 as 
    
    remaining_estimate
    
, 
    
    
    reporter
    
 as 
    
    reporter
    
, 
    
    
    resolution
    
 as 
    
    resolution
    
, 
    
    
    resolved
    
 as 
    
    resolved
    
, 
    
    
    status
    
 as 
    
    status
    
, 
    
    
    status_category_changed
    
 as 
    
    status_category_changed
    
, 
    
    
    summary
    
 as 
    
    summary
    
, 
    
    
    time_spent
    
 as 
    
    time_spent
    
, 
    
    
    updated
    
 as 
    
    updated
    
, 
    
    
    work_ratio
    
 as 
    
    work_ratio
    



    from base
),

final as (

    select
        coalesce(original_estimate, _original_estimate) as original_estimate_seconds,
        coalesce(remaining_estimate, _remaining_estimate) as remaining_estimate_seconds,
        coalesce(time_spent, _time_spent) as time_spent_seconds,
        assignee as assignee_user_id,
        cast(created as TIMESTAMP) as created_at,
        cast(resolved  as TIMESTAMP) as resolved_at,
        creator as creator_user_id,
        description as issue_description,
        due_date,
        environment,
        id as issue_id,
        issue_type as issue_type_id,
        key as issue_key,
        parent_id as parent_issue_id,
        priority as priority_id,
        project as project_id,
        reporter as reporter_user_id,
        resolution as resolution_id,
        status as status_id,
        cast(status_category_changed as TIMESTAMP) as status_changed_at,
        summary as issue_name,
        cast(updated as TIMESTAMP) as updated_at,
        work_ratio,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:36.769513 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:c7eb659b-cbc3-42f3-b173-f65ccf377875:europe-west2&page=queryresults
[0m09:38:36.803282 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:6cb4a573-9eb8-4840-a7f4-0599b62563ab:europe-west2&page=queryresults
[0m09:38:36.851081 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:2f94a11d-acca-46f1-a0d1-5ef93aaf4803:europe-west2&page=queryresults
[0m09:38:37.061637 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:37.063093 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ffc100>]}
[0m09:38:37.063743 [info ] [Thread-8  ]: 43 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__field  [[32mCREATE TABLE (138.0 rows, 5.7 KB processed)[0m in 2.42s]
[0m09:38:37.064512 [debug] [Thread-8  ]: Finished running node model.jira_source.stg_jira__field
[0m09:38:37.065517 [debug] [Thread-8  ]: Began running node model.jira_source.stg_jira__priority
[0m09:38:37.066246 [info ] [Thread-8  ]: 51 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__priority  [RUN]
[0m09:38:37.066917 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:b08cf283-9990-42a9-8ea7-0406197a753d:europe-west2&page=queryresults
[0m09:38:37.067630 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__priority"
[0m09:38:37.069568 [debug] [Thread-8  ]: Began compiling node model.jira_source.stg_jira__priority
[0m09:38:37.070327 [debug] [Thread-8  ]: Compiling model.jira_source.stg_jira__priority
[0m09:38:37.074826 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:37.075849 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:b538fded-8521-4387-8a81-f020d11b976d:europe-west2&page=queryresults
[0m09:38:37.098457 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:37.099002 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1336aaf70>]}
[0m09:38:37.099278 [info ] [Thread-1  ]: 45 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__comment  [[32mCREATE TABLE (7.7k rows, 3.5 MB processed)[0m in 2.39s]
[0m09:38:37.099635 [debug] [Thread-1  ]: Finished running node model.jira_source.stg_jira__comment
[0m09:38:37.099782 [debug] [Thread-1  ]: Began running node model.jira_source.stg_jira__sprint
[0m09:38:37.100050 [info ] [Thread-1  ]: 52 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__sprint  [RUN]
[0m09:38:37.100609 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__sprint"
[0m09:38:37.100733 [debug] [Thread-1  ]: Began compiling node model.jira_source.stg_jira__sprint
[0m09:38:37.100848 [debug] [Thread-1  ]: Compiling model.jira_source.stg_jira__sprint
[0m09:38:37.105937 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:37.116298 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:37.116796 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1275d2940>]}
[0m09:38:37.117052 [info ] [Thread-4  ]: 44 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__field_option  [[32mCREATE TABLE (29.0 rows, 880.0 Bytes processed)[0m in 2.42s]
[0m09:38:37.117362 [debug] [Thread-4  ]: Finished running node model.jira_source.stg_jira__field_option
[0m09:38:37.117497 [debug] [Thread-4  ]: Began running node model.jira_source.stg_jira__project
[0m09:38:37.117731 [info ] [Thread-4  ]: 53 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__project  [RUN]
[0m09:38:37.118206 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__project"
[0m09:38:37.118316 [debug] [Thread-4  ]: Began compiling node model.jira_source.stg_jira__project
[0m09:38:37.118426 [debug] [Thread-4  ]: Compiling model.jira_source.stg_jira__project
[0m09:38:37.122201 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:37.333845 [debug] [Thread-8  ]: Writing injected SQL for node "model.jira_source.stg_jira__priority"
[0m09:38:37.334393 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:37.334855 [debug] [Thread-8  ]: Began executing node model.jira_source.stg_jira__priority
[0m09:38:37.338314 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:37.339165 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126f86550>]}
[0m09:38:37.339501 [info ] [Thread-6  ]: 48 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__issue_link  [[32mCREATE TABLE (506.0 rows, 18.8 KB processed)[0m in 2.14s]
[0m09:38:37.339847 [debug] [Thread-6  ]: Finished running node model.jira_source.stg_jira__issue_link
[0m09:38:37.339999 [debug] [Thread-6  ]: Began running node model.jira_source.stg_jira__resolution
[0m09:38:37.340442 [info ] [Thread-6  ]: 54 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__resolution  [RUN]
[0m09:38:37.341225 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__resolution"
[0m09:38:37.341364 [debug] [Thread-6  ]: Began compiling node model.jira_source.stg_jira__resolution
[0m09:38:37.341494 [debug] [Thread-6  ]: Compiling model.jira_source.stg_jira__resolution
[0m09:38:37.346290 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:37.358540 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira_source.stg_jira__sprint"
[0m09:38:37.358904 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:37.359021 [debug] [Thread-1  ]: Began executing node model.jira_source.stg_jira__sprint
[0m09:38:37.372062 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:37.372454 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126f862b0>]}
[0m09:38:37.372645 [info ] [Thread-5  ]: 47 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__component  [[32mCREATE TABLE (16.0 rows, 1.0 KB processed)[0m in 2.45s]
[0m09:38:37.372937 [debug] [Thread-5  ]: Finished running node model.jira_source.stg_jira__component
[0m09:38:37.373069 [debug] [Thread-5  ]: Began running node model.jira_source.stg_jira__user
[0m09:38:37.373244 [info ] [Thread-5  ]: 55 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__user . [RUN]
[0m09:38:37.373572 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__user"
[0m09:38:37.373650 [debug] [Thread-5  ]: Began compiling node model.jira_source.stg_jira__user
[0m09:38:37.373726 [debug] [Thread-5  ]: Compiling model.jira_source.stg_jira__user
[0m09:38:37.376850 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:37.381015 [debug] [Thread-4  ]: Writing injected SQL for node "model.jira_source.stg_jira__project"
[0m09:38:37.381429 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:37.381522 [debug] [Thread-4  ]: Began executing node model.jira_source.stg_jira__project
[0m09:38:37.433446 [debug] [Thread-8  ]: Writing runtime sql for node "model.jira_source.stg_jira__priority"
[0m09:38:37.433808 [debug] [Thread-8  ]: On model.jira_source.stg_jira__priority: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__priority"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__priority`
    
    
    OPTIONS(
      description="""Table of issue priority levels (global)."""
    )
    as (
      

with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__priority_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    description
    
 as 
    
    description
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    name
    
 as 
    
    name
    



    from base
),

final as (
    
    select 
        description as priority_description,
        id as priority_id,
        name as priority_name,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:37.453888 [debug] [Thread-1  ]: Writing runtime sql for node "model.jira_source.stg_jira__sprint"
[0m09:38:37.454670 [debug] [Thread-1  ]: On model.jira_source.stg_jira__sprint: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__sprint"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__sprint`
    
    
    OPTIONS(
      description="""Table of all sprints."""
    )
    as (
      

with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__sprint_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    board_id
    
 as 
    
    board_id
    
, 
    
    
    complete_date
    
 as 
    
    complete_date
    
, 
    
    
    end_date
    
 as 
    
    end_date
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    name
    
 as 
    
    name
    
, 
    
    
    start_date
    
 as 
    
    start_date
    



    from base
),

final as (
    
    select 
        id as sprint_id,
        name as sprint_name,
        board_id,
        cast(complete_date as TIMESTAMP) as completed_at,
        cast(end_date as TIMESTAMP) as ended_at,
        cast(start_date as TIMESTAMP) as started_at,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:37.477433 [debug] [Thread-4  ]: Writing runtime sql for node "model.jira_source.stg_jira__project"
[0m09:38:37.478247 [debug] [Thread-4  ]: On model.jira_source.stg_jira__project: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__project"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__project`
    
    
    OPTIONS(
      description="""Table of all projects in your organization."""
    )
    as (
      with base as (
    
    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__project_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    description
    
 as 
    
    description
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    key
    
 as 
    
    key
    
, 
    
    
    lead_id
    
 as 
    
    lead_id
    
, 
    
    
    name
    
 as 
    
    name
    
, 
    
    
    permission_scheme_id
    
 as 
    
    permission_scheme_id
    
, 
    
    
    project_category_id
    
 as 
    
    project_category_id
    



    from base

),

final as (

    select 
        description as project_description,
        id as project_id,
        key as project_key,
        lead_id as project_lead_user_id,
        name as project_name,
        project_category_id,
        permission_scheme_id,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:37.618180 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira_source.stg_jira__resolution"
[0m09:38:37.618784 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:37.618971 [debug] [Thread-6  ]: Began executing node model.jira_source.stg_jira__resolution
[0m09:38:37.634603 [debug] [Thread-5  ]: Writing injected SQL for node "model.jira_source.stg_jira__user"
[0m09:38:37.635108 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:37.635257 [debug] [Thread-5  ]: Began executing node model.jira_source.stg_jira__user
[0m09:38:37.680425 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:5856e884-220e-414b-afbf-32ce0abf0dba:europe-west2&page=queryresults
[0m09:38:37.709756 [debug] [Thread-6  ]: Writing runtime sql for node "model.jira_source.stg_jira__resolution"
[0m09:38:37.710686 [debug] [Thread-6  ]: On model.jira_source.stg_jira__resolution: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__resolution"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__resolution`
    
    
    OPTIONS(
      description="""Table storing the types of resolutions used by your organization."""
    )
    as (
      with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__resolution_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    description
    
 as 
    
    description
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    name
    
 as 
    
    name
    



    from base
),

final as (
    
    select 
        description as resolution_description,
        id as resolution_id,
        name as resolution_name,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:37.723976 [debug] [Thread-5  ]: Writing runtime sql for node "model.jira_source.stg_jira__user"
[0m09:38:37.724414 [debug] [Thread-5  ]: On model.jira_source.stg_jira__user: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__user"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__user`
    
    
    OPTIONS(
      description="""Table of users associated with your organization."""
    )
    as (
      with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__user_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    email
    
 as 
    
    email
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    locale
    
 as 
    
    locale
    
, 
    
    
    name
    
 as 
    
    name
    
, 
    
    
    time_zone
    
 as 
    
    time_zone
    
, 
    
    
    username
    
 as 
    
    username
    



    from base
),

final as (

    select 
        email,
        id as user_id,
        locale,
        name as user_display_name,
        time_zone,
        username,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:37.794977 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:298cc932-7144-4a40-a36e-ca0ceca85b3d:europe-west2&page=queryresults
[0m09:38:37.960595 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:04cb8abb-7751-48a7-943c-5283493a7f13:europe-west2&page=queryresults
[0m09:38:37.963525 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:37.963962 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13296cbe0>]}
[0m09:38:37.964296 [info ] [Thread-7  ]: 50 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__issue  [[32mCREATE TABLE (4.8k rows, 1.9 MB processed)[0m in 2.43s]
[0m09:38:37.964781 [debug] [Thread-7  ]: Finished running node model.jira_source.stg_jira__issue
[0m09:38:37.965052 [debug] [Thread-7  ]: Began running node model.jira_source.stg_jira__issue_type
[0m09:38:37.965204 [info ] [Thread-7  ]: 56 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__issue_type  [RUN]
[0m09:38:37.966582 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__issue_type"
[0m09:38:37.967061 [debug] [Thread-7  ]: Began compiling node model.jira_source.stg_jira__issue_type
[0m09:38:37.967405 [debug] [Thread-7  ]: Compiling model.jira_source.stg_jira__issue_type
[0m09:38:37.972325 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:38.079710 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:38.080138 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ffc280>]}
[0m09:38:38.080332 [info ] [Thread-3  ]: 49 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__issue_multiselect_history  [[32mCREATE TABLE (85.4k rows, 5.8 MB processed)[0m in 2.69s]
[0m09:38:38.080553 [debug] [Thread-3  ]: Finished running node model.jira_source.stg_jira__issue_multiselect_history
[0m09:38:38.080651 [debug] [Thread-3  ]: Began running node model.jira_source.stg_jira__status
[0m09:38:38.080750 [info ] [Thread-3  ]: 57 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__status  [RUN]
[0m09:38:38.081057 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__status"
[0m09:38:38.081130 [debug] [Thread-3  ]: Began compiling node model.jira_source.stg_jira__status
[0m09:38:38.081200 [debug] [Thread-3  ]: Compiling model.jira_source.stg_jira__status
[0m09:38:38.083817 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:38.214408 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:38.215805 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ddc8e0>]}
[0m09:38:38.216089 [info ] [Thread-2  ]: 46 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__issue_field_history  [[32mCREATE TABLE (457.4k rows, 20.9 MB processed)[0m in 3.51s]
[0m09:38:38.218295 [debug] [Thread-2  ]: Finished running node model.jira_source.stg_jira__issue_field_history
[0m09:38:38.218407 [debug] [Thread-2  ]: Began running node model.jira_source.stg_jira__status_category
[0m09:38:38.218635 [info ] [Thread-2  ]: 58 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__status_category  [RUN]
[0m09:38:38.219088 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__status_category"
[0m09:38:38.221170 [debug] [Thread-2  ]: Began compiling node model.jira_source.stg_jira__status_category
[0m09:38:38.221266 [debug] [Thread-2  ]: Compiling model.jira_source.stg_jira__status_category
[0m09:38:38.224650 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m09:38:38.228261 [debug] [Thread-7  ]: Writing injected SQL for node "model.jira_source.stg_jira__issue_type"
[0m09:38:38.228561 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:38.228650 [debug] [Thread-7  ]: Began executing node model.jira_source.stg_jira__issue_type
[0m09:38:38.323425 [debug] [Thread-7  ]: Writing runtime sql for node "model.jira_source.stg_jira__issue_type"
[0m09:38:38.323862 [debug] [Thread-7  ]: On model.jira_source.stg_jira__issue_type: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__issue_type"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_type`
    
    
    OPTIONS(
      description="""Table containing information about issue types. Issue types can have identical names in different projects, but they may have  differing descriptions.\n"""
    )
    as (
      with base as (

    select * from 
    `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_type_tmp`
),

fields as (

    select 
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    description
    
 as 
    
    description
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    name
    
 as 
    
    name
    
, 
    
    
    subtask
    
 as 
    
    subtask
    



    from base
),

final as (

    select
        description,
        id as issue_type_id,
        name as issue_type_name,
        subtask as is_subtask,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:38.336313 [debug] [Thread-3  ]: Writing injected SQL for node "model.jira_source.stg_jira__status"
[0m09:38:38.336652 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:38.336755 [debug] [Thread-3  ]: Began executing node model.jira_source.stg_jira__status
[0m09:38:38.433497 [debug] [Thread-3  ]: Writing runtime sql for node "model.jira_source.stg_jira__status"
[0m09:38:38.433960 [debug] [Thread-3  ]: On model.jira_source.stg_jira__status: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__status"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__status`
    
    
    OPTIONS(
      description="""Table of project-level statuses (which may have the same umbrella `status_category`)."""
    )
    as (
      with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__status_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    description
    
 as 
    
    description
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    name
    
 as 
    
    name
    
, 
    
    
    status_category_id
    
 as 
    
    status_category_id
    



    from base
),

final as (

    select
        description as status_description,
        id as status_id,
        name as status_name,
        status_category_id,
        _fivetran_synced
    from fields
)

select * 
from final
    );
  
[0m09:38:38.478916 [debug] [Thread-2  ]: Writing injected SQL for node "model.jira_source.stg_jira__status_category"
[0m09:38:38.479335 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:38.479451 [debug] [Thread-2  ]: Began executing node model.jira_source.stg_jira__status_category
[0m09:38:38.564242 [debug] [Thread-2  ]: Writing runtime sql for node "model.jira_source.stg_jira__status_category"
[0m09:38:38.565215 [debug] [Thread-2  ]: On model.jira_source.stg_jira__status_category: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__status_category"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__status_category`
    
    
    OPTIONS(
      description="""Table of umbrella status categories."""
    )
    as (
      with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__status_category_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    name
    
 as 
    
    name
    



    from base
),

final as (
    
    select 
        id as status_category_id,
        name as status_category_name
    from fields
)

select * 
from final
    );
  
[0m09:38:38.987241 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:2a7f01a2-88f2-4dd7-9219-144e99e7e094:europe-west2&page=queryresults
[0m09:38:39.220825 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:99f6d459-86e0-4893-9f9b-7e24da24ac00:europe-west2&page=queryresults
[0m09:38:39.262549 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:db7ed053-010a-40b3-b56a-202739ad28fa:europe-west2&page=queryresults
[0m09:38:39.267852 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:39.269273 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1329af940>]}
[0m09:38:39.270102 [info ] [Thread-1  ]: 52 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__sprint  [[32mCREATE TABLE (254.0 rows, 15.5 KB processed)[0m in 2.17s]
[0m09:38:39.270592 [debug] [Thread-1  ]: Finished running node model.jira_source.stg_jira__sprint
[0m09:38:39.270770 [debug] [Thread-1  ]: Began running node model.jira_source.stg_jira__version
[0m09:38:39.271219 [info ] [Thread-1  ]: 59 of 110 START sql table model lewis_analytics_dev_jira_source.stg_jira__version  [RUN]
[0m09:38:39.271981 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira_source.stg_jira__version"
[0m09:38:39.272115 [debug] [Thread-1  ]: Began compiling node model.jira_source.stg_jira__version
[0m09:38:39.272238 [debug] [Thread-1  ]: Compiling model.jira_source.stg_jira__version
[0m09:38:39.388262 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:39.522768 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:559f22d9-5168-4096-93af-c6c255cc3fdd:europe-west2&page=queryresults
[0m09:38:39.527451 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:b6d6c45a-24be-441a-8ad8-050bdae2c9f1:europe-west2&page=queryresults
[0m09:38:39.569140 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:39.569690 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133c59d90>]}
[0m09:38:39.569956 [info ] [Thread-8  ]: 51 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__priority  [[32mCREATE TABLE (4.0 rows, 250.0 Bytes processed)[0m in 2.50s]
[0m09:38:39.570277 [debug] [Thread-8  ]: Finished running node model.jira_source.stg_jira__priority
[0m09:38:39.570413 [debug] [Thread-8  ]: Began running node model.wire_harvest.int_harvest__expenses
[0m09:38:39.570646 [info ] [Thread-8  ]: 60 of 110 START sql view model lewis_analytics_dev_integration.int_harvest__expenses  [RUN]
[0m09:38:39.571093 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.wire_harvest.int_harvest__expenses"
[0m09:38:39.571197 [debug] [Thread-8  ]: Began compiling node model.wire_harvest.int_harvest__expenses
[0m09:38:39.571293 [debug] [Thread-8  ]: Compiling model.wire_harvest.int_harvest__expenses
[0m09:38:39.574315 [debug] [Thread-8  ]: Writing injected SQL for node "model.wire_harvest.int_harvest__expenses"
[0m09:38:39.574782 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:39.574887 [debug] [Thread-8  ]: Began executing node model.wire_harvest.int_harvest__expenses
[0m09:38:39.577669 [debug] [Thread-8  ]: Writing runtime sql for node "model.wire_harvest.int_harvest__expenses"
[0m09:38:39.578067 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:39.630120 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:39.630493 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133bfacd0>]}
[0m09:38:39.630669 [info ] [Thread-4  ]: 53 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__project  [[32mCREATE TABLE (83.0 rows, 7.4 KB processed)[0m in 2.51s]
[0m09:38:39.630884 [debug] [Thread-4  ]: Finished running node model.jira_source.stg_jira__project
[0m09:38:39.630977 [debug] [Thread-4  ]: Began running node model.wire_harvest.int_harvest__clients
[0m09:38:39.631074 [info ] [Thread-4  ]: 61 of 110 START sql view model lewis_analytics_dev_integration.int_harvest__clients  [RUN]
[0m09:38:39.631350 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.wire_harvest.int_harvest__clients"
[0m09:38:39.631420 [debug] [Thread-4  ]: Began compiling node model.wire_harvest.int_harvest__clients
[0m09:38:39.631490 [debug] [Thread-4  ]: Compiling model.wire_harvest.int_harvest__clients
[0m09:38:39.633494 [debug] [Thread-4  ]: Writing injected SQL for node "model.wire_harvest.int_harvest__clients"
[0m09:38:39.633864 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:39.633948 [debug] [Thread-4  ]: Began executing node model.wire_harvest.int_harvest__clients
[0m09:38:39.636598 [debug] [Thread-4  ]: Writing runtime sql for node "model.wire_harvest.int_harvest__clients"
[0m09:38:39.637046 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:39.648405 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira_source.stg_jira__version"
[0m09:38:39.648725 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:39.648815 [debug] [Thread-1  ]: Began executing node model.jira_source.stg_jira__version
[0m09:38:39.652048 [debug] [Thread-8  ]: On model.wire_harvest.int_harvest__expenses: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.int_harvest__expenses"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__expenses`
  OPTIONS(
      description=""""""
    )
  as with stg_harvest__expenses as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__expenses`

)

select * from stg_harvest__expenses;


[0m09:38:39.706504 [debug] [Thread-4  ]: On model.wire_harvest.int_harvest__clients: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.int_harvest__clients"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__clients`
  OPTIONS(
      description=""""""
    )
  as with stg_harvest__clients as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__clients`

)

select * from stg_harvest__clients;


[0m09:38:39.743899 [debug] [Thread-1  ]: Writing runtime sql for node "model.jira_source.stg_jira__version"
[0m09:38:39.744299 [debug] [Thread-1  ]: On model.jira_source.stg_jira__version: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira_source.stg_jira__version"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__version`
    
    
    OPTIONS(
      description="""Table of project versions in your organization."""
    )
    as (
      

with base as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__version_tmp`
),

fields as (

    select
        
    
    
    _fivetran_synced
    
 as 
    
    _fivetran_synced
    
, 
    
    
    archived
    
 as 
    
    archived
    
, 
    
    
    description
    
 as 
    
    description
    
, 
    
    
    id
    
 as 
    
    id
    
, 
    
    
    name
    
 as 
    
    name
    
, 
    
    
    overdue
    
 as 
    
    overdue
    
, 
    
    
    project_id
    
 as 
    
    project_id
    
, 
    
    
    release_date
    
 as 
    
    release_date
    
, 
    
    
    released
    
 as 
    
    released
    
, 
    
    
    start_date
    
 as 
    
    start_date
    



    from base
),

final as (
    
    select 
        archived as is_archived,
        description,
        id as version_id,
        name as version_name,
        overdue as is_overdue,
        project_id,
        cast(release_date as TIMESTAMP) as release_date,
        released as is_released,
        cast(start_date as TIMESTAMP) as start_date
    from fields
)

select * 
from final
    );
  
[0m09:38:39.824881 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:39.825315 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:39.826197 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133c55df0>]}
[0m09:38:39.826730 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1337b1160>]}
[0m09:38:39.909681 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:42319292-d070-400e-b81f-459321a906b3:europe-west2&page=queryresults
[0m09:38:40.077328 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:080508c2-e31f-45d0-b1c7-cf251de6a9f4:europe-west2&page=queryresults
[0m09:38:40.096725 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:dcc78a21-5dc6-47db-aad6-593213b94425:europe-west2&page=queryresults
[0m09:38:40.184409 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:40.185455 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133c79ca0>]}
[0m09:38:40.260141 [info ] [Thread-5  ]: 55 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__user  [[32mCREATE TABLE (109.0 rows, 8.3 KB processed)[0m in 2.45s]
[0m09:38:40.260568 [info ] [Thread-6  ]: 54 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__resolution  [[32mCREATE TABLE (7.0 rows, 743.0 Bytes processed)[0m in 2.49s]
[0m09:38:40.260885 [info ] [Thread-3  ]: 57 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__status  [[32mCREATE TABLE (286.0 rows, 11.9 KB processed)[0m in 2.10s]
[0m09:38:40.261562 [debug] [Thread-5  ]: Finished running node model.jira_source.stg_jira__user
[0m09:38:40.262115 [debug] [Thread-6  ]: Finished running node model.jira_source.stg_jira__resolution
[0m09:38:40.262649 [debug] [Thread-3  ]: Finished running node model.jira_source.stg_jira__status
[0m09:38:40.263008 [debug] [Thread-5  ]: Began running node model.wire_harvest.int_harvest__employees
[0m09:38:40.263501 [debug] [Thread-6  ]: Began running node model.wire_harvest.int_harvest__invoice_line_items
[0m09:38:40.264000 [debug] [Thread-3  ]: Began running node model.wire_harvest.int_harvest__invoices
[0m09:38:40.264406 [info ] [Thread-5  ]: 62 of 110 START sql view model lewis_analytics_dev_integration.int_harvest__employees  [RUN]
[0m09:38:40.264694 [info ] [Thread-6  ]: 63 of 110 START sql view model lewis_analytics_dev_integration.int_harvest__invoice_line_items  [RUN]
[0m09:38:40.264991 [info ] [Thread-3  ]: 64 of 110 START sql view model lewis_analytics_dev_integration.int_harvest__invoices  [RUN]
[0m09:38:40.265888 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.wire_harvest.int_harvest__employees"
[0m09:38:40.266351 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.wire_harvest.int_harvest__invoice_line_items"
[0m09:38:40.266827 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.wire_harvest.int_harvest__invoices"
[0m09:38:40.266941 [debug] [Thread-5  ]: Began compiling node model.wire_harvest.int_harvest__employees
[0m09:38:40.267035 [debug] [Thread-6  ]: Began compiling node model.wire_harvest.int_harvest__invoice_line_items
[0m09:38:40.267120 [debug] [Thread-3  ]: Began compiling node model.wire_harvest.int_harvest__invoices
[0m09:38:40.267213 [debug] [Thread-5  ]: Compiling model.wire_harvest.int_harvest__employees
[0m09:38:40.267293 [debug] [Thread-6  ]: Compiling model.wire_harvest.int_harvest__invoice_line_items
[0m09:38:40.267372 [debug] [Thread-3  ]: Compiling model.wire_harvest.int_harvest__invoices
[0m09:38:40.270408 [debug] [Thread-5  ]: Writing injected SQL for node "model.wire_harvest.int_harvest__employees"
[0m09:38:40.272860 [debug] [Thread-6  ]: Writing injected SQL for node "model.wire_harvest.int_harvest__invoice_line_items"
[0m09:38:40.275541 [debug] [Thread-3  ]: Writing injected SQL for node "model.wire_harvest.int_harvest__invoices"
[0m09:38:40.276208 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:40.276349 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:40.276477 [debug] [Thread-5  ]: Began executing node model.wire_harvest.int_harvest__employees
[0m09:38:40.276548 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:40.276637 [debug] [Thread-6  ]: Began executing node model.wire_harvest.int_harvest__invoice_line_items
[0m09:38:40.280694 [debug] [Thread-5  ]: Writing runtime sql for node "model.wire_harvest.int_harvest__employees"
[0m09:38:40.280851 [debug] [Thread-3  ]: Began executing node model.wire_harvest.int_harvest__invoices
[0m09:38:40.283326 [debug] [Thread-6  ]: Writing runtime sql for node "model.wire_harvest.int_harvest__invoice_line_items"
[0m09:38:40.287289 [debug] [Thread-3  ]: Writing runtime sql for node "model.wire_harvest.int_harvest__invoices"
[0m09:38:40.287622 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:40.288351 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:40.288646 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:40.354618 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:4e13aa58-a26f-4477-b6c5-6b1a3baa3bc2:europe-west2&page=queryresults
[0m09:38:40.357442 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:40.357939 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133e09550>]}
[0m09:38:40.359157 [info ] [Thread-7  ]: 56 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__issue_type  [[32mCREATE TABLE (289.0 rows, 22.3 KB processed)[0m in 2.39s]
[0m09:38:40.359403 [debug] [Thread-7  ]: Finished running node model.jira_source.stg_jira__issue_type
[0m09:38:40.359505 [debug] [Thread-7  ]: Began running node model.wire_harvest.int_harvest__projects
[0m09:38:40.359711 [info ] [Thread-7  ]: 65 of 110 START sql view model lewis_analytics_dev_integration.int_harvest__projects  [RUN]
[0m09:38:40.360082 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.wire_harvest.int_harvest__projects"
[0m09:38:40.360380 [debug] [Thread-7  ]: Began compiling node model.wire_harvest.int_harvest__projects
[0m09:38:40.360654 [debug] [Thread-7  ]: Compiling model.wire_harvest.int_harvest__projects
[0m09:38:40.362902 [debug] [Thread-7  ]: Writing injected SQL for node "model.wire_harvest.int_harvest__projects"
[0m09:38:40.363572 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:40.363664 [debug] [Thread-7  ]: Began executing node model.wire_harvest.int_harvest__projects
[0m09:38:40.366679 [debug] [Thread-7  ]: Writing runtime sql for node "model.wire_harvest.int_harvest__projects"
[0m09:38:40.367010 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:40.373062 [debug] [Thread-5  ]: On model.wire_harvest.int_harvest__employees: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.int_harvest__employees"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__employees`
  OPTIONS(
      description=""""""
    )
  as with stg_harvest__employee as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__employee`

)

select * from stg_harvest__employee;


[0m09:38:40.373954 [debug] [Thread-3  ]: On model.wire_harvest.int_harvest__invoices: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.int_harvest__invoices"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__invoices`
  OPTIONS(
      description=""""""
    )
  as with stg_harvest__invoices as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__invoices`

)

select * from stg_harvest__invoices;


[0m09:38:40.375198 [debug] [Thread-6  ]: On model.wire_harvest.int_harvest__invoice_line_items: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.int_harvest__invoice_line_items"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__invoice_line_items`
  OPTIONS(
      description=""""""
    )
  as with stg_harvest__invoice_line_items as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__invoice_line_items`

)

select * from stg_harvest__invoice_line_items;


[0m09:38:40.399508 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:40.399950 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133c0dd00>]}
[0m09:38:40.400208 [info ] [Thread-2  ]: 58 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__status_category  [[32mCREATE TABLE (3.0 rows, 50.0 Bytes processed)[0m in 2.18s]
[0m09:38:40.400443 [debug] [Thread-2  ]: Finished running node model.jira_source.stg_jira__status_category
[0m09:38:40.400625 [debug] [Thread-2  ]: Began running node model.wire_harvest.int_harvest__tasks
[0m09:38:40.400798 [info ] [Thread-2  ]: 66 of 110 START sql view model lewis_analytics_dev_integration.int_harvest__tasks  [RUN]
[0m09:38:40.401141 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.wire_harvest.int_harvest__tasks"
[0m09:38:40.401283 [debug] [Thread-2  ]: Began compiling node model.wire_harvest.int_harvest__tasks
[0m09:38:40.401382 [debug] [Thread-2  ]: Compiling model.wire_harvest.int_harvest__tasks
[0m09:38:40.403530 [debug] [Thread-2  ]: Writing injected SQL for node "model.wire_harvest.int_harvest__tasks"
[0m09:38:40.403913 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:40.404002 [debug] [Thread-2  ]: Began executing node model.wire_harvest.int_harvest__tasks
[0m09:38:40.406074 [debug] [Thread-2  ]: Writing runtime sql for node "model.wire_harvest.int_harvest__tasks"
[0m09:38:40.406283 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m09:38:40.434160 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:18dd0779-be2e-4deb-9bed-89bd2c4b0468:europe-west2&page=queryresults
[0m09:38:40.437999 [debug] [Thread-7  ]: On model.wire_harvest.int_harvest__projects: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.int_harvest__projects"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__projects`
  OPTIONS(
      description=""""""
    )
  as with stg_harvest__projects as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__projects`

)

select * from stg_harvest__projects;


[0m09:38:40.477006 [debug] [Thread-2  ]: On model.wire_harvest.int_harvest__tasks: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.int_harvest__tasks"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__tasks`
  OPTIONS(
      description=""""""
    )
  as with stg_harvest__tasks as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__tasks`

)

select * from stg_harvest__tasks;


[0m09:38:40.633288 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:40.633888 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127edca90>]}
[0m09:38:40.634218 [info ] [Thread-8  ]: 60 of 110 OK created sql view model lewis_analytics_dev_integration.int_harvest__expenses  [[32mCREATE VIEW (0 processed)[0m in 1.06s]
[0m09:38:40.634627 [debug] [Thread-8  ]: Finished running node model.wire_harvest.int_harvest__expenses
[0m09:38:40.634783 [debug] [Thread-8  ]: Began running node model.wire_harvest.int_harvest__time_sheets
[0m09:38:40.635066 [info ] [Thread-8  ]: 67 of 110 START sql view model lewis_analytics_dev_integration.int_harvest__time_sheets  [RUN]
[0m09:38:40.635660 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.wire_harvest.int_harvest__time_sheets"
[0m09:38:40.635781 [debug] [Thread-8  ]: Began compiling node model.wire_harvest.int_harvest__time_sheets
[0m09:38:40.635896 [debug] [Thread-8  ]: Compiling model.wire_harvest.int_harvest__time_sheets
[0m09:38:40.640532 [debug] [Thread-8  ]: Writing injected SQL for node "model.wire_harvest.int_harvest__time_sheets"
[0m09:38:40.641038 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:40.641201 [debug] [Thread-8  ]: Began executing node model.wire_harvest.int_harvest__time_sheets
[0m09:38:40.645168 [debug] [Thread-8  ]: Writing runtime sql for node "model.wire_harvest.int_harvest__time_sheets"
[0m09:38:40.645631 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:40.702682 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:40.703094 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133e610d0>]}
[0m09:38:40.703288 [info ] [Thread-4  ]: 61 of 110 OK created sql view model lewis_analytics_dev_integration.int_harvest__clients  [[32mCREATE VIEW (0 processed)[0m in 1.07s]
[0m09:38:40.703519 [debug] [Thread-4  ]: Finished running node model.wire_harvest.int_harvest__clients
[0m09:38:40.703710 [debug] [Thread-4  ]: Began running node model.wire_jira.int_jira__epics
[0m09:38:40.703883 [info ] [Thread-4  ]: 68 of 110 START sql view model lewis_analytics_dev_integration.int_jira__epics . [RUN]
[0m09:38:40.704213 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.wire_jira.int_jira__epics"
[0m09:38:40.704291 [debug] [Thread-4  ]: Began compiling node model.wire_jira.int_jira__epics
[0m09:38:40.704415 [debug] [Thread-4  ]: Compiling model.wire_jira.int_jira__epics
[0m09:38:40.707814 [debug] [Thread-4  ]: Writing injected SQL for node "model.wire_jira.int_jira__epics"
[0m09:38:40.708271 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:40.708361 [debug] [Thread-4  ]: Began executing node model.wire_jira.int_jira__epics
[0m09:38:40.710565 [debug] [Thread-4  ]: Writing runtime sql for node "model.wire_jira.int_jira__epics"
[0m09:38:40.710897 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:40.729001 [debug] [Thread-8  ]: On model.wire_harvest.int_harvest__time_sheets: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.int_harvest__time_sheets"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__time_sheets`
  OPTIONS(
      description=""""""
    )
  as with stg_harvest__time_sheets as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__time_sheets`

),

stg_harvest__time_sheet_external_reference as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__time_sheet_external_reference`

),

stg_harvest__external_reference as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_harvest__external_reference`

),

joined as (

    select 

        stg_harvest__time_sheets.harvest_timesheet_sk,
        stg_harvest__time_sheets.harvest_timesheet_natural_key,
        stg_harvest__time_sheets.harvest_employee_natural_key,
        stg_harvest__time_sheets.harvest_task_natural_key,
        stg_harvest__time_sheets.harvest_task_assignment_natural_key,
        stg_harvest__time_sheets.harvest_employee_assignment_natural_key,
        stg_harvest__time_sheets.harvest_invoice_natural_key,
        stg_harvest__time_sheets.harvest_project_natural_key,
        stg_harvest__time_sheets.harvest_external_reference_natural_key,
        stg_harvest__time_sheets.harvest_client_natural_key,

        stg_harvest__time_sheets.harvest_timesheet_notes,
        stg_harvest__time_sheets.harvest_timesheet_locked_reason,

        stg_harvest__time_sheets.harvest_timesheet_billable_rate,
        stg_harvest__time_sheets.harvest_timesheet_cost_rate,
        stg_harvest__time_sheets.harvest_timesheet_hours,
        stg_harvest__time_sheets.harvest_timesheet_hours_budgeted,

        stg_harvest__time_sheets.harvest_timesheet_is_billable,
        stg_harvest__time_sheets.harvest_timesheet_is_closed,
        stg_harvest__time_sheets.harvest_timesheet_is_running,
        stg_harvest__time_sheets.harvest_timesheet_is_billed,
        stg_harvest__time_sheets.harvest_timesheet_is_locked,

        stg_harvest__time_sheets.harvest_timesheet_created_at_ts,
        stg_harvest__time_sheets.harvest_timesheet_timer_started_at_ts,
        stg_harvest__time_sheets.harvest_timesheet_started_at,
        stg_harvest__time_sheets.harvest_timesheet_updated_at_ts,
        stg_harvest__time_sheets.harvest_timesheet_spent_at_ts,

        stg_harvest__external_reference.harvest_external_reference_permalink,
        stg_harvest__external_reference.harvest_external_reference_jira_issue_key,
        stg_harvest__external_reference.harvest_external_reference_platform
    
    
    from stg_harvest__time_sheets

    left join stg_harvest__time_sheet_external_reference
    on stg_harvest__time_sheets.harvest_timesheet_natural_key = stg_harvest__time_sheet_external_reference.harvest_timesheet_natural_key

    left join stg_harvest__external_reference
    on stg_harvest__external_reference.harvest_external_reference_natural_key = stg_harvest__time_sheet_external_reference.harvest_external_reference_natural_key

)

select * from joined;


[0m09:38:40.780558 [debug] [Thread-4  ]: On model.wire_jira.int_jira__epics: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira__epics"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira__epics`
  OPTIONS(
      description=""""""
    )
  as with stg_jira__epics as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__epics`

)

select * from stg_jira__epics;


[0m09:38:41.066754 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:7523614b-e21c-4bcf-aadf-f007bad63142:europe-west2&page=queryresults
[0m09:38:41.079629 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:ad80c612-e122-48fb-b5ba-8194ed1a5e40:europe-west2&page=queryresults
[0m09:38:41.132374 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:446cb95e-e2b7-4ac9-befc-cb0ab5195c31:europe-west2&page=queryresults
[0m09:38:41.156484 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:51d91158-f299-40ed-bca2-7000dffb6928:europe-west2&page=queryresults
[0m09:38:41.234548 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:466496c5-e7d9-47a9-8102-94d0f94b1b64:europe-west2&page=queryresults
[0m09:38:41.252638 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:3c8bd6bb-9d31-482c-8499-d7cbea2f6bab:europe-west2&page=queryresults
[0m09:38:41.328077 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:41.329284 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133e3e880>]}
[0m09:38:41.329789 [info ] [Thread-5  ]: 62 of 110 OK created sql view model lewis_analytics_dev_integration.int_harvest__employees  [[32mCREATE VIEW (0 processed)[0m in 1.06s]
[0m09:38:41.330421 [debug] [Thread-5  ]: Finished running node model.wire_harvest.int_harvest__employees
[0m09:38:41.330671 [debug] [Thread-5  ]: Began running node model.wire_jira.int_jira__fields
[0m09:38:41.331131 [info ] [Thread-5  ]: 69 of 110 START sql view model lewis_analytics_dev_integration.int_jira__fields  [RUN]
[0m09:38:41.332045 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.wire_jira.int_jira__fields"
[0m09:38:41.332216 [debug] [Thread-5  ]: Began compiling node model.wire_jira.int_jira__fields
[0m09:38:41.332347 [debug] [Thread-5  ]: Compiling model.wire_jira.int_jira__fields
[0m09:38:41.335904 [debug] [Thread-5  ]: Writing injected SQL for node "model.wire_jira.int_jira__fields"
[0m09:38:41.336368 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:41.336507 [debug] [Thread-5  ]: Began executing node model.wire_jira.int_jira__fields
[0m09:38:41.341655 [debug] [Thread-5  ]: Writing runtime sql for node "model.wire_jira.int_jira__fields"
[0m09:38:41.342124 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:41.387514 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:41.387996 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133e3e580>]}
[0m09:38:41.388237 [info ] [Thread-3  ]: 64 of 110 OK created sql view model lewis_analytics_dev_integration.int_harvest__invoices  [[32mCREATE VIEW (0 processed)[0m in 1.12s]
[0m09:38:41.388569 [debug] [Thread-3  ]: Finished running node model.wire_harvest.int_harvest__invoices
[0m09:38:41.388693 [debug] [Thread-3  ]: Began running node model.wire_jira.int_jira__boards
[0m09:38:41.388915 [info ] [Thread-3  ]: 70 of 110 START sql view model lewis_analytics_dev_integration.int_jira__boards  [RUN]
[0m09:38:41.389397 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.wire_jira.int_jira__boards"
[0m09:38:41.389510 [debug] [Thread-3  ]: Began compiling node model.wire_jira.int_jira__boards
[0m09:38:41.389626 [debug] [Thread-3  ]: Compiling model.wire_jira.int_jira__boards
[0m09:38:41.392648 [debug] [Thread-3  ]: Writing injected SQL for node "model.wire_jira.int_jira__boards"
[0m09:38:41.393104 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:41.393206 [debug] [Thread-3  ]: Began executing node model.wire_jira.int_jira__boards
[0m09:38:41.395903 [debug] [Thread-3  ]: Writing runtime sql for node "model.wire_jira.int_jira__boards"
[0m09:38:41.396399 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:41.405064 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:41.405495 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127552550>]}
[0m09:38:41.405714 [info ] [Thread-7  ]: 65 of 110 OK created sql view model lewis_analytics_dev_integration.int_harvest__projects  [[32mCREATE VIEW (0 processed)[0m in 1.05s]
[0m09:38:41.406008 [debug] [Thread-7  ]: Finished running node model.wire_harvest.int_harvest__projects
[0m09:38:41.406117 [debug] [Thread-7  ]: Began running node model.wire_jira.int_jira_intermediate__issues
[0m09:38:41.406369 [info ] [Thread-7  ]: 71 of 110 START sql view model lewis_analytics_dev_integration.int_jira_intermediate__issues  [RUN]
[0m09:38:41.406747 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.wire_jira.int_jira_intermediate__issues"
[0m09:38:41.406833 [debug] [Thread-7  ]: Began compiling node model.wire_jira.int_jira_intermediate__issues
[0m09:38:41.406931 [debug] [Thread-7  ]: Compiling model.wire_jira.int_jira_intermediate__issues
[0m09:38:41.409502 [debug] [Thread-7  ]: Writing injected SQL for node "model.wire_jira.int_jira_intermediate__issues"
[0m09:38:41.410558 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:41.410914 [debug] [Thread-7  ]: Began executing node model.wire_jira.int_jira_intermediate__issues
[0m09:38:41.413445 [debug] [Thread-7  ]: Writing runtime sql for node "model.wire_jira.int_jira_intermediate__issues"
[0m09:38:41.413768 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:41.428968 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:41.429344 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12750fb20>]}
[0m09:38:41.429523 [info ] [Thread-2  ]: 66 of 110 OK created sql view model lewis_analytics_dev_integration.int_harvest__tasks  [[32mCREATE VIEW (0 processed)[0m in 1.03s]
[0m09:38:41.429743 [debug] [Thread-2  ]: Finished running node model.wire_harvest.int_harvest__tasks
[0m09:38:41.429834 [debug] [Thread-2  ]: Began running node model.jira.int_jira__issue_calendar_spine
[0m09:38:41.429932 [info ] [Thread-2  ]: 72 of 110 START sql incremental model lewis_analytics_dev_int_jira.int_jira__issue_calendar_spine  [RUN]
[0m09:38:41.430210 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_calendar_spine"
[0m09:38:41.430282 [debug] [Thread-2  ]: Began compiling node model.jira.int_jira__issue_calendar_spine
[0m09:38:41.430352 [debug] [Thread-2  ]: Compiling model.jira.int_jira__issue_calendar_spine
[0m09:38:41.437152 [debug] [Thread-5  ]: On model.wire_jira.int_jira__fields: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira__fields"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira__fields`
  OPTIONS(
      description=""""""
    )
  as with stg_jira__fields as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__fields`

)

select * from stg_jira__fields;


[0m09:38:41.439129 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m09:38:41.467745 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:57468f08-09de-4c96-bbcf-2b2912416a48:europe-west2&page=queryresults
[0m09:38:41.471284 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:6487d8a9-936a-4f42-bb7d-b3b7ac3600ae:europe-west2&page=queryresults
[0m09:38:41.471688 [debug] [Thread-3  ]: On model.wire_jira.int_jira__boards: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira__boards"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira__boards`
  OPTIONS(
      description=""""""
    )
  as with stg_jira__boards as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__boards`

),

stg_jira__project_board as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__project_board`

),

joined as (

    select

        stg_jira__boards.jira_board_natural_key,
        stg_jira__project_board.jira_project_natural_key,

        stg_jira__boards.jira_board_name,
        stg_jira__boards.jira_board_type
    
    from stg_jira__boards

    left join stg_jira__project_board
    on stg_jira__project_board.jira_board_natural_key = stg_jira__boards.jira_board_natural_key

)

select * from joined;


[0m09:38:41.486735 [debug] [Thread-7  ]: On model.wire_jira.int_jira_intermediate__issues: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira_intermediate__issues"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira_intermediate__issues`
  OPTIONS(
      description=""""""
    )
  as with stg_jira__issues_field_history as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__issues_field_history`

),

stg_jira__fields as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__fields`

),

joined as (

    select 
    
        stg_jira__issues_field_history.jira_field_natural_key,
        stg_jira__issues_field_history.jira_issue_natural_key,

        stg_jira__issues_field_history.jira_issue_field_history_value,
        stg_jira__issues_field_history.jira_issue_field_history_is_active,

        regexp_replace(replace(replace(replace(replace(stg_jira__fields.jira_field_name
                                                            ," ", "_")
                                                            ,":","_")
                                                            ,"(","_")
                                                            ,")","_")
                                                            , r"[^a-zA-Z0-9_-]", "")
                                                            
                                                            as field_name,

        stg_jira__issues_field_history.jira_issue_field_history_timestamp
    
    from stg_jira__issues_field_history

    left join stg_jira__fields
    on stg_jira__issues_field_history.jira_field_natural_key = stg_jira__fields.jira_field_natural_key

)

select * from joined;


[0m09:38:41.507129 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:41.507693 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126faee80>]}
[0m09:38:41.507924 [info ] [Thread-6  ]: 63 of 110 OK created sql view model lewis_analytics_dev_integration.int_harvest__invoice_line_items  [[32mCREATE VIEW (0 processed)[0m in 1.24s]
[0m09:38:41.508437 [debug] [Thread-6  ]: Finished running node model.wire_harvest.int_harvest__invoice_line_items
[0m09:38:41.508744 [debug] [Thread-6  ]: Began running node model.jira.int_jira__issue_multiselect_history
[0m09:38:41.509145 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_multiselect_history"
[0m09:38:41.509312 [debug] [Thread-6  ]: Began compiling node model.jira.int_jira__issue_multiselect_history
[0m09:38:41.509580 [debug] [Thread-6  ]: Compiling model.jira.int_jira__issue_multiselect_history
[0m09:38:41.512775 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira.int_jira__issue_multiselect_history"
[0m09:38:41.513336 [debug] [Thread-2  ]: On model.jira.int_jira__issue_calendar_spine: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.int_jira__issue_calendar_spine"} */

    
    -- start at the first created issue
        select  min( created ) as min_date from `ra-development`.`fivetran_jira`.`issue`
    
  
[0m09:38:41.514311 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:41.514714 [debug] [Thread-6  ]: Finished running node model.jira.int_jira__issue_multiselect_history
[0m09:38:41.514811 [debug] [Thread-6  ]: Began running node model.jira.int_jira__issue_field_history
[0m09:38:41.515063 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_field_history"
[0m09:38:41.515251 [debug] [Thread-6  ]: Began compiling node model.jira.int_jira__issue_field_history
[0m09:38:41.515419 [debug] [Thread-6  ]: Compiling model.jira.int_jira__issue_field_history
[0m09:38:41.518527 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira.int_jira__issue_field_history"
[0m09:38:41.518868 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:41.519199 [debug] [Thread-6  ]: Finished running node model.jira.int_jira__issue_field_history
[0m09:38:41.519291 [debug] [Thread-6  ]: Began running node model.jira.int_jira__issue_comments
[0m09:38:41.519511 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_comments"
[0m09:38:41.519580 [debug] [Thread-6  ]: Began compiling node model.jira.int_jira__issue_comments
[0m09:38:41.519646 [debug] [Thread-6  ]: Compiling model.jira.int_jira__issue_comments
[0m09:38:41.522929 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira.int_jira__issue_comments"
[0m09:38:41.523407 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:41.523905 [debug] [Thread-6  ]: Finished running node model.jira.int_jira__issue_comments
[0m09:38:41.524028 [debug] [Thread-6  ]: Began running node model.wire_harvest.wh_delivery__harvest_expenses_fact
[0m09:38:41.524178 [info ] [Thread-6  ]: 73 of 110 START sql table model lewis_analytics_dev.wh_delivery__harvest_expenses_fact  [RUN]
[0m09:38:41.524462 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.wire_harvest.wh_delivery__harvest_expenses_fact"
[0m09:38:41.524527 [debug] [Thread-6  ]: Began compiling node model.wire_harvest.wh_delivery__harvest_expenses_fact
[0m09:38:41.524591 [debug] [Thread-6  ]: Compiling model.wire_harvest.wh_delivery__harvest_expenses_fact
[0m09:38:41.532445 [debug] [Thread-6  ]: Writing injected SQL for node "model.wire_harvest.wh_delivery__harvest_expenses_fact"
[0m09:38:41.533233 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:41.533559 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133b0eeb0>]}
[0m09:38:41.533778 [info ] [Thread-1  ]: 59 of 110 OK created sql table model lewis_analytics_dev_jira_source.stg_jira__version  [[32mCREATE TABLE (14.0 rows, 1.2 KB processed)[0m in 2.26s]
[0m09:38:41.534111 [debug] [Thread-1  ]: Finished running node model.jira_source.stg_jira__version
[0m09:38:41.534264 [debug] [Thread-1  ]: Began running node model.wire_harvest.wh_delivery__harvest_clients_dim
[0m09:38:41.534936 [info ] [Thread-1  ]: 74 of 110 START sql table model lewis_analytics_dev.wh_delivery__harvest_clients_dim  [RUN]
[0m09:38:41.535048 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:41.535487 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.wire_harvest.wh_delivery__harvest_clients_dim"
[0m09:38:41.535573 [debug] [Thread-6  ]: Began executing node model.wire_harvest.wh_delivery__harvest_expenses_fact
[0m09:38:41.535795 [debug] [Thread-1  ]: Began compiling node model.wire_harvest.wh_delivery__harvest_clients_dim
[0m09:38:41.537705 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:41.538162 [debug] [Thread-1  ]: Compiling model.wire_harvest.wh_delivery__harvest_clients_dim
[0m09:38:41.541066 [debug] [Thread-1  ]: Writing injected SQL for node "model.wire_harvest.wh_delivery__harvest_clients_dim"
[0m09:38:41.541633 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:41.541714 [debug] [Thread-1  ]: Began executing node model.wire_harvest.wh_delivery__harvest_clients_dim
[0m09:38:41.543506 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:41.783708 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:41.784541 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133e09700>]}
[0m09:38:41.784845 [info ] [Thread-8  ]: 67 of 110 OK created sql view model lewis_analytics_dev_integration.int_harvest__time_sheets  [[32mCREATE VIEW (0 processed)[0m in 1.15s]
[0m09:38:41.785318 [debug] [Thread-8  ]: Finished running node model.wire_harvest.int_harvest__time_sheets
[0m09:38:41.785476 [debug] [Thread-8  ]: Began running node model.wire_harvest.wh_delivery__harvest_employees_dim
[0m09:38:41.785743 [info ] [Thread-8  ]: 75 of 110 START sql table model lewis_analytics_dev.wh_delivery__harvest_employees_dim  [RUN]
[0m09:38:41.786417 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.wire_harvest.wh_delivery__harvest_employees_dim"
[0m09:38:41.786597 [debug] [Thread-8  ]: Began compiling node model.wire_harvest.wh_delivery__harvest_employees_dim
[0m09:38:41.786737 [debug] [Thread-8  ]: Compiling model.wire_harvest.wh_delivery__harvest_employees_dim
[0m09:38:41.791770 [debug] [Thread-8  ]: Writing injected SQL for node "model.wire_harvest.wh_delivery__harvest_employees_dim"
[0m09:38:41.792220 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:41.792361 [debug] [Thread-8  ]: Began executing node model.wire_harvest.wh_delivery__harvest_employees_dim
[0m09:38:41.796325 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:41.821434 [debug] [Thread-6  ]: Writing runtime sql for node "model.wire_harvest.wh_delivery__harvest_expenses_fact"
[0m09:38:41.822237 [debug] [Thread-6  ]: On model.wire_harvest.wh_delivery__harvest_expenses_fact: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.wh_delivery__harvest_expenses_fact"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_expenses_fact`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_harvest__expenses as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__expenses`

),

final as (

    select 

        
    
to_hex(md5(cast(coalesce(cast(harvest_expense_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_expense_pk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_client_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_client_fk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_invoice_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_invoice_fk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_project_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_project_fk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_employee_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_employee_fk,
            
        harvest_expense_category_natural_key,
        harvest_employee_assignment_natural_key,

        harvest_expense_notes,
        harvest_expense_receipt_file_name,
        harvest_expense_locked_reason,
        harvest_expense_receipt_content_type,
        harvest_expense_receipt_url,

        harvest_expense_total_cost,
        harvest_expense_receipt_file_size,
        harvest_expense_units,

        harvest_expense_is_closed,
        harvest_expense_billable,
        harvest_expense_is_billed,
        harvest_expense_is_locked,

        harvest_expense_created_at,
        harvest_expense_updated_at,
        harvest_expense_spent_date,

    from int_harvest__expenses

)

select * from final
    );
  
[0m09:38:41.828331 [debug] [Thread-1  ]: Writing runtime sql for node "model.wire_harvest.wh_delivery__harvest_clients_dim"
[0m09:38:41.828771 [debug] [Thread-1  ]: On model.wire_harvest.wh_delivery__harvest_clients_dim: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.wh_delivery__harvest_clients_dim"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_clients_dim`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_harvest__clients as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__clients`

),

final as (

    select 

        
    
to_hex(md5(cast(coalesce(cast(harvest_client_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_client_pk,

        harvest_client_name,
        harvest_client_currency,

        harvest_client_is_active,
        
        harvest_client_created_at_ts,
        harvest_client_updated_at_ts

    from int_harvest__clients

)

select * from final
    );
  
[0m09:38:41.839326 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:41.839745 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133e610d0>]}
[0m09:38:41.839951 [info ] [Thread-4  ]: 68 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira__epics  [[32mCREATE VIEW (0 processed)[0m in 1.14s]
[0m09:38:41.840192 [debug] [Thread-4  ]: Finished running node model.wire_jira.int_jira__epics
[0m09:38:41.840292 [debug] [Thread-4  ]: Began running node model.wire_harvest.wh_delivery__harvest_invoices_fact
[0m09:38:41.840491 [info ] [Thread-4  ]: 76 of 110 START sql table model lewis_analytics_dev.wh_delivery__harvest_invoices_fact  [RUN]
[0m09:38:41.840933 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.wire_harvest.wh_delivery__harvest_invoices_fact"
[0m09:38:41.841034 [debug] [Thread-4  ]: Began compiling node model.wire_harvest.wh_delivery__harvest_invoices_fact
[0m09:38:41.841121 [debug] [Thread-4  ]: Compiling model.wire_harvest.wh_delivery__harvest_invoices_fact
[0m09:38:41.847952 [debug] [Thread-4  ]: Writing injected SQL for node "model.wire_harvest.wh_delivery__harvest_invoices_fact"
[0m09:38:41.848281 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:41.848365 [debug] [Thread-4  ]: Began executing node model.wire_harvest.wh_delivery__harvest_invoices_fact
[0m09:38:41.850039 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:42.050258 [debug] [Thread-8  ]: Writing runtime sql for node "model.wire_harvest.wh_delivery__harvest_employees_dim"
[0m09:38:42.050794 [debug] [Thread-8  ]: On model.wire_harvest.wh_delivery__harvest_employees_dim: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.wh_delivery__harvest_employees_dim"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_employees_dim`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_harvest__employees as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__employees`

),

final as (

    select 

        
    
to_hex(md5(cast(coalesce(cast(harvest_employee_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_employee_pk,

        harvest_employee_first_name,
        harvest_employee_last_name,
        harvest_employee_full_name,
        harvest_employee_email,

        harvest_employee_weekly_capacity,
        harvest_employee_cost_rate,
        harvest_employee_default_hourly_rate,

        harvest_employee_is_contractor,
        harvest_employee_is_active,

        harvest_employee_created_at_ts,
        harvest_employee_updated_at_ts

    from int_harvest__employees

)

select * from final
    );
  
[0m09:38:42.109553 [debug] [Thread-4  ]: Writing runtime sql for node "model.wire_harvest.wh_delivery__harvest_invoices_fact"
[0m09:38:42.110116 [debug] [Thread-4  ]: On model.wire_harvest.wh_delivery__harvest_invoices_fact: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.wh_delivery__harvest_invoices_fact"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_invoices_fact`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_harvest__invoices as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__invoices`

),

final as (

    select 

        
    
to_hex(md5(cast(coalesce(cast(harvest_invoice_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_invoice_pk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_client_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_client_fk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_creator_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_employee_fk,
            
        harvest_invoice_client_key,

        harvest_invoice_number,
        harvest_invoice_purchase_order,
        harvest_invoice_state,
        harvest_invoice_notes,
        harvest_invoice_subject,
        harvest_invoice_currency,
        harvest_invoice_payment_term,

        harvest_invoice_amount,
        harvest_invoice_due_amount,

        harvest_invoice_discount_amount,
        harvest_invoice_discount,

        harvest_invoice_tax_amount,
        harvest_invoice_tax,

        harvest_invoice_period_start,
        harvest_invoice_period_end,

        harvest_invoice_paid_date,
        harvest_invoice_issue_date,
        harvest_invoice_due_date,

        harvest_invoice_created_at,
        harvest_invoice_sent_at,
        harvest_invoice_paid_at,
        harvest_invoice_updated_at

    from int_harvest__invoices

)

select * from final
    );
  
[0m09:38:42.113367 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:1a250a19-a2db-4d6d-8c26-726b15a8fdea:europe-west2&page=queryresults
[0m09:38:42.215488 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:eaa226cb-5fa2-4e09-a20f-161ea5043cb2:europe-west2&page=queryresults
[0m09:38:42.218904 [debug] [Thread-2  ]: On model.jira.int_jira__issue_calendar_spine: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.int_jira__issue_calendar_spine"} */


        select 

    datetime_diff(
        cast(

        datetime_add(
            cast( current_timestamp as datetime),
        interval 1 week
        )

 as datetime),
        cast(cast('2018-08-01' as date) as datetime),
        day
    )

  
[0m09:38:42.249956 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:d0da8ac7-39a9-4119-8cfe-5b314c8f505c:europe-west2&page=queryresults
[0m09:38:42.306449 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:ec67198c-8200-42c1-84aa-40cd5ca43956:europe-west2&page=queryresults
[0m09:38:42.370677 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:42.371609 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12762c3d0>]}
[0m09:38:42.371952 [info ] [Thread-5  ]: 69 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira__fields  [[32mCREATE VIEW (0 processed)[0m in 1.04s]
[0m09:38:42.372290 [debug] [Thread-5  ]: Finished running node model.wire_jira.int_jira__fields
[0m09:38:42.372432 [debug] [Thread-5  ]: Began running node model.wire_harvest.wh_delivery__harvest_projects_fact
[0m09:38:42.372684 [info ] [Thread-5  ]: 77 of 110 START sql table model lewis_analytics_dev.wh_delivery__harvest_projects_fact  [RUN]
[0m09:38:42.373279 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.wire_harvest.wh_delivery__harvest_projects_fact"
[0m09:38:42.373408 [debug] [Thread-5  ]: Began compiling node model.wire_harvest.wh_delivery__harvest_projects_fact
[0m09:38:42.373520 [debug] [Thread-5  ]: Compiling model.wire_harvest.wh_delivery__harvest_projects_fact
[0m09:38:42.381695 [debug] [Thread-5  ]: Writing injected SQL for node "model.wire_harvest.wh_delivery__harvest_projects_fact"
[0m09:38:42.382185 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:42.382322 [debug] [Thread-5  ]: Began executing node model.wire_harvest.wh_delivery__harvest_projects_fact
[0m09:38:42.385034 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:42.532478 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:42.533068 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1336165e0>]}
[0m09:38:42.533387 [info ] [Thread-7  ]: 71 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira_intermediate__issues  [[32mCREATE VIEW (0 processed)[0m in 1.13s]
[0m09:38:42.533739 [debug] [Thread-7  ]: Finished running node model.wire_jira.int_jira_intermediate__issues
[0m09:38:42.533884 [debug] [Thread-7  ]: Began running node model.wire_harvest.wh_delivery__harvest_tasks_dim
[0m09:38:42.534117 [info ] [Thread-7  ]: 78 of 110 START sql table model lewis_analytics_dev.wh_delivery__harvest_tasks_dim  [RUN]
[0m09:38:42.534642 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.wire_harvest.wh_delivery__harvest_tasks_dim"
[0m09:38:42.534748 [debug] [Thread-7  ]: Began compiling node model.wire_harvest.wh_delivery__harvest_tasks_dim
[0m09:38:42.534848 [debug] [Thread-7  ]: Compiling model.wire_harvest.wh_delivery__harvest_tasks_dim
[0m09:38:42.539595 [debug] [Thread-7  ]: Writing injected SQL for node "model.wire_harvest.wh_delivery__harvest_tasks_dim"
[0m09:38:42.540094 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:42.540217 [debug] [Thread-7  ]: Began executing node model.wire_harvest.wh_delivery__harvest_tasks_dim
[0m09:38:42.542479 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:42.587161 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:42.587605 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ff5af0>]}
[0m09:38:42.587891 [info ] [Thread-3  ]: 70 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira__boards  [[32mCREATE VIEW (0 processed)[0m in 1.20s]
[0m09:38:42.588172 [debug] [Thread-3  ]: Finished running node model.wire_jira.int_jira__boards
[0m09:38:42.588291 [debug] [Thread-3  ]: Began running node model.wire_harvest.wh_delivery__harvest_invoice_line_items_fact
[0m09:38:42.588480 [info ] [Thread-3  ]: 79 of 110 START sql table model lewis_analytics_dev.wh_delivery__harvest_invoice_line_items_fact  [RUN]
[0m09:38:42.588940 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.wire_harvest.wh_delivery__harvest_invoice_line_items_fact"
[0m09:38:42.589013 [debug] [Thread-3  ]: Began compiling node model.wire_harvest.wh_delivery__harvest_invoice_line_items_fact
[0m09:38:42.589084 [debug] [Thread-3  ]: Compiling model.wire_harvest.wh_delivery__harvest_invoice_line_items_fact
[0m09:38:42.593972 [debug] [Thread-3  ]: Writing injected SQL for node "model.wire_harvest.wh_delivery__harvest_invoice_line_items_fact"
[0m09:38:42.594256 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:42.594334 [debug] [Thread-3  ]: Began executing node model.wire_harvest.wh_delivery__harvest_invoice_line_items_fact
[0m09:38:42.596626 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:42.667827 [debug] [Thread-5  ]: Writing runtime sql for node "model.wire_harvest.wh_delivery__harvest_projects_fact"
[0m09:38:42.669953 [debug] [Thread-5  ]: On model.wire_harvest.wh_delivery__harvest_projects_fact: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.wh_delivery__harvest_projects_fact"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_projects_fact`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_harvest__projects as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__projects`

),

final as (

    select 

        
    
to_hex(md5(cast(coalesce(cast(harvest_project_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_project_pk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_client_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_client_fk,

        harvest_project_name,
        harvest_project_code,
        harvest_project_notes,

        harvest_project_bill_by,
        harvest_project_budget_by,

        harvest_project_hourly_rate,
        harvest_project_cost_budget,
        harvest_project_fee,
        harvest_project_budget,
        harvest_project_over_budget_notification_percentage,

        harvest_project_show_budget_to_all,
        harvest_project_cost_budget_include_expenses,
        harvest_project_budget_is_monthly,
        harvest_project_notify_when_over_budget,
        
        harvest_project_is_billable,
        harvest_project_is_fixed_fee,
        harvest_project_is_active,

        harvest_project_over_budget_notification_date,
        harvest_project_created_at,
        harvest_project_ends_on,
        harvest_project_updated_at,
        harvest_project_starts_on

    from int_harvest__projects

)

select * from final
    );
  
[0m09:38:42.770105 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:d7db156a-52b4-4d1e-9eb3-576afb8716d8:europe-west2&page=queryresults
[0m09:38:42.778029 [debug] [Thread-2  ]: Writing injected SQL for node "model.jira.int_jira__issue_calendar_spine"
[0m09:38:42.778462 [debug] [Thread-2  ]: finished collecting timing info
[0m09:38:42.778586 [debug] [Thread-2  ]: Began executing node model.jira.int_jira__issue_calendar_spine
[0m09:38:42.804444 [debug] [Thread-7  ]: Writing runtime sql for node "model.wire_harvest.wh_delivery__harvest_tasks_dim"
[0m09:38:42.805259 [debug] [Thread-7  ]: On model.wire_harvest.wh_delivery__harvest_tasks_dim: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.wh_delivery__harvest_tasks_dim"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_tasks_dim`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_harvest__tasks as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__tasks`

),

final as (

    select 

        
    
to_hex(md5(cast(coalesce(cast(harvest_task_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_task_pk,

        harvest_task_name,

        harvest_task_default_hourly_rate,

        harvest_task_is_billable_by_default,
        harvest_task_is_default,
        harvest_task_is_active,

        harvest_task_created_at_ts,
        harvest_task_updated_at_ts

    from int_harvest__tasks

)

select * from final
    );
  
[0m09:38:42.857596 [debug] [Thread-3  ]: Writing runtime sql for node "model.wire_harvest.wh_delivery__harvest_invoice_line_items_fact"
[0m09:38:42.858453 [debug] [Thread-3  ]: On model.wire_harvest.wh_delivery__harvest_invoice_line_items_fact: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.wh_delivery__harvest_invoice_line_items_fact"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_invoice_line_items_fact`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_harvest__invoice_line_items as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__invoice_line_items`

),

final as (

    select 

        
    
to_hex(md5(cast(coalesce(cast(harvest_invoice_line_item_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_invoice_line_item_pk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_project_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_project_fk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_invoice_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_invoice_fk,

        harvest_invoice_line_item_kind,
        harvest_invoice_line_item_description,

        harvest_invoice_line_item_amount,
        harvest_invoice_line_item_unit_price,
        harvest_invoice_line_item_quantity,

        harvest_invoice_line_item_services_amount_billed,
        harvest_invoice_line_item_license_referral_fee_amount_billed,
        harvest_invoice_line_item_expenses_amount_billed,
        harvest_invoice_line_item_support_amount_billed,

        harvest_invoice_line_item_is_taxed

    from int_harvest__invoice_line_items

)

select * from final
    );
  
[0m09:38:42.920568 [debug] [Thread-2  ]: Writing runtime sql for node "model.jira.int_jira__issue_calendar_spine"
[0m09:38:42.921215 [debug] [Thread-2  ]: On model.jira.int_jira__issue_calendar_spine: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.int_jira__issue_calendar_spine"} */

        
            
            
        
    

    

    merge into `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__issue_calendar_spine` as DBT_INTERNAL_DEST
        using (
          

with spine as (

    
    
    
    
    


    select * 
    from (
        





with rawdata as (

    

    

    with p as (
        select 0 as generated_number union all select 1
    ), unioned as (

    select

    
    p0.generated_number * power(2, 0)
     + 
    
    p1.generated_number * power(2, 1)
     + 
    
    p2.generated_number * power(2, 2)
     + 
    
    p3.generated_number * power(2, 3)
     + 
    
    p4.generated_number * power(2, 4)
     + 
    
    p5.generated_number * power(2, 5)
     + 
    
    p6.generated_number * power(2, 6)
     + 
    
    p7.generated_number * power(2, 7)
     + 
    
    p8.generated_number * power(2, 8)
     + 
    
    p9.generated_number * power(2, 9)
     + 
    
    p10.generated_number * power(2, 10)
    
    
    + 1
    as generated_number

    from

    
    p as p0
     cross join 
    
    p as p1
     cross join 
    
    p as p2
     cross join 
    
    p as p3
     cross join 
    
    p as p4
     cross join 
    
    p as p5
     cross join 
    
    p as p6
     cross join 
    
    p as p7
     cross join 
    
    p as p8
     cross join 
    
    p as p9
     cross join 
    
    p as p10
    
    

    )

    select *
    from unioned
    where generated_number <= 1682
    order by generated_number



),

all_periods as (

    select (
        

        datetime_add(
            cast( cast('2018-08-01' as date) as datetime),
        interval row_number() over (order by 1) - 1 day
        )


    ) as date_day
    from rawdata

),

filtered as (

    select *
    from all_periods
    where date_day <= 

        datetime_add(
            cast( current_timestamp as datetime),
        interval 1 week
        )



)

select * from filtered

 
    ) as date_spine

    
    -- compare to the earliest possible open_until date so that if a resolved issue is updated after a long period of inactivity, we don't need a full refresh
    -- essentially we need to be able to backfill
    where cast( date_day as date) >= (select min(earliest_open_until_date) from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__issue_calendar_spine` )
    
),

issue_dates as (

    select
        issue_id,
        cast( timestamp_trunc(
        cast(created_at as timestamp),
        day
    ) as date) as created_on,

        -- resolved_at will become null if an issue is marked as un-resolved. if this sorta thing happens often, you may want to run full-refreshes of the field_history models often
        -- if it's not resolved include everything up to today. if it is, look at the last time it was updated 
        cast(timestamp_trunc(
        cast(case when resolved_at is null then current_timestamp else updated_at end as timestamp),
        day
    ) as date) as open_until

    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue`

),

issue_spine as (

    select 
        cast(spine.date_day as date) as date_day,
        issue_dates.issue_id,
        -- will take the table-wide min of this in the incremental block at the top of this model
        min(issue_dates.open_until) as earliest_open_until_date

    from spine 
    join issue_dates on
        issue_dates.created_on <= spine.date_day
        and 

        datetime_add(
            cast( issue_dates.open_until as datetime),
        interval 1 month
        )

 >= spine.date_day
        -- if we cut off issues, we're going to have to do a full refresh to catch issues that have been un-resolved

    group by 1,2
),

surrogate_key as (

    select 
        date_day,
        issue_id,
        
    
to_hex(md5(cast(coalesce(cast(date_day as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(issue_id as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as issue_day_id,
        earliest_open_until_date

    from issue_spine

    where date_day <= cast( timestamp_trunc(
        cast(current_timestamp as timestamp),
        day
    ) as date)
)

select * from surrogate_key
        ) as DBT_INTERNAL_SOURCE
        on 
                DBT_INTERNAL_SOURCE.issue_day_id = DBT_INTERNAL_DEST.issue_day_id
            

    
    when matched then update set
        `date_day` = DBT_INTERNAL_SOURCE.`date_day`,`issue_id` = DBT_INTERNAL_SOURCE.`issue_id`,`issue_day_id` = DBT_INTERNAL_SOURCE.`issue_day_id`,`earliest_open_until_date` = DBT_INTERNAL_SOURCE.`earliest_open_until_date`
    

    when not matched then insert
        (`date_day`, `issue_id`, `issue_day_id`, `earliest_open_until_date`)
    values
        (`date_day`, `issue_id`, `issue_day_id`, `earliest_open_until_date`)


    
[0m09:38:43.620619 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:b6db17f4-0d31-4cf8-a1c2-7dab0e119e28:europe-west2&page=queryresults
[0m09:38:43.626662 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:2215af98-7ff2-4a90-acdd-dfbd596c0db8:europe-west2&page=queryresults
[0m09:38:43.829323 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:86af4f82-08e5-40c6-bd0e-3cdb66d23f95:europe-west2&page=queryresults
[0m09:38:43.902141 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:43.903957 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13298a4c0>]}
[0m09:38:43.904761 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:43.905376 [info ] [Thread-6  ]: 73 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__harvest_expenses_fact  [[32mCREATE TABLE (151.0 rows, 37.0 KB processed)[0m in 2.38s]
[0m09:38:43.906177 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x132972e50>]}
[0m09:38:43.907001 [debug] [Thread-6  ]: Finished running node model.wire_harvest.wh_delivery__harvest_expenses_fact
[0m09:38:43.907440 [info ] [Thread-1  ]: 74 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__harvest_clients_dim  [[32mCREATE TABLE (54.0 rows, 5.6 KB processed)[0m in 2.37s]
[0m09:38:43.907688 [debug] [Thread-6  ]: Began running node model.jira.int_jira__agg_multiselect_history
[0m09:38:43.908416 [debug] [Thread-1  ]: Finished running node model.wire_harvest.wh_delivery__harvest_clients_dim
[0m09:38:43.908610 [info ] [Thread-6  ]: 80 of 110 START sql incremental model lewis_analytics_dev_int_jira.int_jira__agg_multiselect_history  [RUN]
[0m09:38:43.908780 [debug] [Thread-1  ]: Began running node model.jira.int_jira__issue_sprint
[0m09:38:43.909290 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira.int_jira__agg_multiselect_history"
[0m09:38:43.909731 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_sprint"
[0m09:38:43.909900 [debug] [Thread-6  ]: Began compiling node model.jira.int_jira__agg_multiselect_history
[0m09:38:43.910025 [debug] [Thread-1  ]: Began compiling node model.jira.int_jira__issue_sprint
[0m09:38:43.910152 [debug] [Thread-6  ]: Compiling model.jira.int_jira__agg_multiselect_history
[0m09:38:43.910264 [debug] [Thread-1  ]: Compiling model.jira.int_jira__issue_sprint
[0m09:38:43.953160 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira.int_jira__agg_multiselect_history"
[0m09:38:43.960486 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira.int_jira__issue_sprint"
[0m09:38:43.960780 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:510803bf-77bd-4580-b69c-35396dacc9b4:europe-west2&page=queryresults
[0m09:38:43.963307 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:43.963506 [debug] [Thread-6  ]: Began executing node model.jira.int_jira__agg_multiselect_history
[0m09:38:43.968122 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:43.968508 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:43.968996 [debug] [Thread-1  ]: Finished running node model.jira.int_jira__issue_sprint
[0m09:38:43.969355 [debug] [Thread-1  ]: Began running node model.jira.int_jira__issue_assign_resolution
[0m09:38:43.970529 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_assign_resolution"
[0m09:38:43.970722 [debug] [Thread-1  ]: Began compiling node model.jira.int_jira__issue_assign_resolution
[0m09:38:43.970967 [debug] [Thread-1  ]: Compiling model.jira.int_jira__issue_assign_resolution
[0m09:38:43.979918 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira.int_jira__issue_assign_resolution"
[0m09:38:43.980324 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:43.980723 [debug] [Thread-1  ]: Finished running node model.jira.int_jira__issue_assign_resolution
[0m09:38:43.980837 [debug] [Thread-1  ]: Began running node model.jira.int_jira__issue_epic
[0m09:38:43.981171 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_epic"
[0m09:38:43.981269 [debug] [Thread-1  ]: Began compiling node model.jira.int_jira__issue_epic
[0m09:38:43.981352 [debug] [Thread-1  ]: Compiling model.jira.int_jira__issue_epic
[0m09:38:43.989180 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira.int_jira__issue_epic"
[0m09:38:43.989503 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:43.989864 [debug] [Thread-1  ]: Finished running node model.jira.int_jira__issue_epic
[0m09:38:43.989965 [debug] [Thread-1  ]: Began running node model.jira.int_jira__issue_versions
[0m09:38:43.990268 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_versions"
[0m09:38:43.990348 [debug] [Thread-1  ]: Began compiling node model.jira.int_jira__issue_versions
[0m09:38:43.990464 [debug] [Thread-1  ]: Compiling model.jira.int_jira__issue_versions
[0m09:38:44.003242 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira.int_jira__issue_versions"
[0m09:38:44.003696 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:44.004163 [debug] [Thread-1  ]: Finished running node model.jira.int_jira__issue_versions
[0m09:38:44.004276 [debug] [Thread-1  ]: Began running node model.wire_harvest.wh_delivery__harvest_time_sheets_fact
[0m09:38:44.004511 [info ] [Thread-1  ]: 81 of 110 START sql table model lewis_analytics_dev.wh_delivery__harvest_time_sheets_fact  [RUN]
[0m09:38:44.004895 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.wire_harvest.wh_delivery__harvest_time_sheets_fact"
[0m09:38:44.004976 [debug] [Thread-1  ]: Began compiling node model.wire_harvest.wh_delivery__harvest_time_sheets_fact
[0m09:38:44.005053 [debug] [Thread-1  ]: Compiling model.wire_harvest.wh_delivery__harvest_time_sheets_fact
[0m09:38:44.011526 [debug] [Thread-1  ]: Writing injected SQL for node "model.wire_harvest.wh_delivery__harvest_time_sheets_fact"
[0m09:38:44.011928 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:44.012026 [debug] [Thread-1  ]: Began executing node model.wire_harvest.wh_delivery__harvest_time_sheets_fact
[0m09:38:44.013849 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:44.174085 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:44.174783 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13371b610>]}
[0m09:38:44.175032 [info ] [Thread-8  ]: 75 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__harvest_employees_dim  [[32mCREATE TABLE (32.0 rows, 26.1 KB processed)[0m in 2.39s]
[0m09:38:44.175395 [debug] [Thread-8  ]: Finished running node model.wire_harvest.wh_delivery__harvest_employees_dim
[0m09:38:44.175536 [debug] [Thread-8  ]: Began running node model.wire_jira.wh_delivery__jira_epics_dim
[0m09:38:44.175737 [info ] [Thread-8  ]: 82 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_epics_dim  [RUN]
[0m09:38:44.176168 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_epics_dim"
[0m09:38:44.176265 [debug] [Thread-8  ]: Began compiling node model.wire_jira.wh_delivery__jira_epics_dim
[0m09:38:44.176358 [debug] [Thread-8  ]: Compiling model.wire_jira.wh_delivery__jira_epics_dim
[0m09:38:44.181539 [debug] [Thread-8  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_epics_dim"
[0m09:38:44.182019 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:44.182127 [debug] [Thread-8  ]: Began executing node model.wire_jira.wh_delivery__jira_epics_dim
[0m09:38:44.184231 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:44.224935 [debug] [Thread-6  ]: Writing runtime sql for node "model.jira.int_jira__agg_multiselect_history"
[0m09:38:44.225297 [debug] [Thread-6  ]: On model.jira.int_jira__agg_multiselect_history: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.int_jira__agg_multiselect_history"} */

        
            
            
        
    

    

    merge into `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__agg_multiselect_history` as DBT_INTERNAL_DEST
        using (
          

-- issue_multiselect_history splits out an array-type field into multiple rows with unique individual values
-- to combine with issue_field_history we need to aggregate the multiselect field values.

with  __dbt__cte__int_jira__issue_multiselect_history as (
with issue_multiselect_history as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_multiselect_history`
    
), 

fields as (
      
    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field`

), 

joined as (
  
  select
    issue_multiselect_history.*,
    fields.field_name

  from issue_multiselect_history
  join fields using (field_id)

)

select *
from joined
),issue_multiselect_history as (

    select *
    from __dbt__cte__int_jira__issue_multiselect_history

    
    -- always refresh the most recent day of data
    where cast(updated_at as date) >= 

        datetime_add(
            cast( (select max(date_day) from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__agg_multiselect_history`) as datetime),
        interval -1 day
        )


    

),

-- each field value has its own row, but each batch of values for that field has the same timestamp
batch_updates as (

    select 
        *,
        
    
to_hex(md5(cast(coalesce(cast(field_id as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(issue_id as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(updated_at as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as batch_id

    from issue_multiselect_history 
),

consolidate_batches as (

    select 
        field_id,
        field_name,
        issue_id,
        updated_at,
        batch_id,
        cast( timestamp_trunc(
        cast(updated_at as timestamp),
        day
    ) as date) as date_day,

        -- if the field refers to an object captured in a table elsewhere (ie sprint, users, field_option for custom fields),
        -- the value is actually a foreign key to that table. 
        
    string_agg(batch_updates.field_value, ', ')

 as field_values 

    from batch_updates

    group by 1,2,3,4,5,6
)

select *
from consolidate_batches
        ) as DBT_INTERNAL_SOURCE
        on 
                DBT_INTERNAL_SOURCE.batch_id = DBT_INTERNAL_DEST.batch_id
            

    
    when matched then update set
        `field_id` = DBT_INTERNAL_SOURCE.`field_id`,`field_name` = DBT_INTERNAL_SOURCE.`field_name`,`issue_id` = DBT_INTERNAL_SOURCE.`issue_id`,`updated_at` = DBT_INTERNAL_SOURCE.`updated_at`,`batch_id` = DBT_INTERNAL_SOURCE.`batch_id`,`date_day` = DBT_INTERNAL_SOURCE.`date_day`,`field_values` = DBT_INTERNAL_SOURCE.`field_values`
    

    when not matched then insert
        (`field_id`, `field_name`, `issue_id`, `updated_at`, `batch_id`, `date_day`, `field_values`)
    values
        (`field_id`, `field_name`, `issue_id`, `updated_at`, `batch_id`, `date_day`, `field_values`)


    
[0m09:38:44.234350 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:44.234720 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1274b9a30>]}
[0m09:38:44.234906 [info ] [Thread-4  ]: 76 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__harvest_invoices_fact  [[32mCREATE TABLE (501.0 rows, 574.8 KB processed)[0m in 2.39s]
[0m09:38:44.235160 [debug] [Thread-4  ]: Finished running node model.wire_harvest.wh_delivery__harvest_invoices_fact
[0m09:38:44.235253 [debug] [Thread-4  ]: Began running node model.wire_jira.wh_delivery__jira_fields_dim
[0m09:38:44.235409 [info ] [Thread-4  ]: 83 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_fields_dim  [RUN]
[0m09:38:44.235691 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_fields_dim"
[0m09:38:44.235758 [debug] [Thread-4  ]: Began compiling node model.wire_jira.wh_delivery__jira_fields_dim
[0m09:38:44.235823 [debug] [Thread-4  ]: Compiling model.wire_jira.wh_delivery__jira_fields_dim
[0m09:38:44.238906 [debug] [Thread-4  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_fields_dim"
[0m09:38:44.239173 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:44.239250 [debug] [Thread-4  ]: Began executing node model.wire_jira.wh_delivery__jira_fields_dim
[0m09:38:44.240743 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:44.261747 [debug] [Thread-1  ]: Writing runtime sql for node "model.wire_harvest.wh_delivery__harvest_time_sheets_fact"
[0m09:38:44.262509 [debug] [Thread-1  ]: On model.wire_harvest.wh_delivery__harvest_time_sheets_fact: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.wh_delivery__harvest_time_sheets_fact"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_time_sheets_fact`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_harvest__time_sheets as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_harvest__time_sheets`

),

final as (

    select distinct

        
    
to_hex(md5(cast(coalesce(cast(harvest_timesheet_sk as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_timesheet_pk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_external_reference_jira_issue_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_external_reference_jira_fk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_task_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_task_fk,

        
    
to_hex(md5(cast(coalesce(cast(harvest_project_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as harvest_project_fk,

        harvest_external_reference_jira_issue_key,
        harvest_timesheet_natural_key,

        harvest_employee_natural_key,
        harvest_task_assignment_natural_key,
        harvest_employee_assignment_natural_key,
        harvest_invoice_natural_key,
        harvest_client_natural_key,

        harvest_timesheet_notes,
        harvest_timesheet_locked_reason,

        harvest_timesheet_billable_rate,
        harvest_timesheet_cost_rate,
        harvest_timesheet_hours,
        harvest_timesheet_hours_budgeted,

        harvest_external_reference_permalink,
        harvest_external_reference_platform,

        harvest_timesheet_is_billable,
        harvest_timesheet_is_closed,
        harvest_timesheet_is_running,
        harvest_timesheet_is_billed,
        harvest_timesheet_is_locked,

        harvest_timesheet_created_at_ts,
        harvest_timesheet_timer_started_at_ts,
        harvest_timesheet_started_at,
        harvest_timesheet_updated_at_ts,
        harvest_timesheet_spent_at_ts

    from int_harvest__time_sheets

)

select * from final
    );
  
[0m09:38:44.485063 [debug] [Thread-4  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_fields_dim"
[0m09:38:44.485844 [debug] [Thread-4  ]: On model.wire_jira.wh_delivery__jira_fields_dim: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_fields_dim"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_fields_dim`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_jira__fields as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__fields`

),

final as (

    select 

        
    
to_hex(md5(cast(coalesce(cast(jira_field_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_field_pk,
        
        jira_field_name,
        jira_field_is_array,
        jira_field_is_custom

    from int_jira__fields

)

select * from final
    );
  
[0m09:38:44.595277 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:0ac2e796-022b-4d8e-a730-cddc05501693:europe-west2&page=queryresults
[0m09:38:44.707678 [debug] [Thread-8  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_epics_dim"
[0m09:38:44.708501 [debug] [Thread-8  ]: On model.wire_jira.wh_delivery__jira_epics_dim: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_epics_dim"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_epics_dim`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_jira__epics as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__epics`

),

final as (

    select 

        
    
to_hex(md5(cast(coalesce(cast(jira_epic_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_epic_pk,

        jira_epic_name,
        jira_epic_summary,
        jira_epic_is_done,
        jira_epic_key

    from int_jira__epics

)

select * from final
    );
  
[0m09:38:44.730171 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:4d1162aa-a84a-488e-b40e-1f82bbaab8be:europe-west2&page=queryresults
[0m09:38:44.831348 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:dfb8582f-fe13-4d63-8dd3-dcf846304d93:europe-west2&page=queryresults
[0m09:38:44.916086 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:44.917544 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ddff70>]}
[0m09:38:44.918082 [info ] [Thread-7  ]: 78 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__harvest_tasks_dim  [[32mCREATE TABLE (92.0 rows, 6.0 KB processed)[0m in 2.38s]
[0m09:38:44.918803 [debug] [Thread-7  ]: Finished running node model.wire_harvest.wh_delivery__harvest_tasks_dim
[0m09:38:44.919132 [debug] [Thread-7  ]: Began running node model.wire_jira.int_jira_intermediate__issues_pivot
[0m09:38:44.919655 [info ] [Thread-7  ]: 84 of 110 START sql view model lewis_analytics_dev_integration.int_jira_intermediate__issues_pivot  [RUN]
[0m09:38:44.921127 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.wire_jira.int_jira_intermediate__issues_pivot"
[0m09:38:44.921419 [debug] [Thread-7  ]: Began compiling node model.wire_jira.int_jira_intermediate__issues_pivot
[0m09:38:44.922274 [debug] [Thread-7  ]: Compiling model.wire_jira.int_jira_intermediate__issues_pivot
[0m09:38:44.929935 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:45.025157 [debug] [Thread-7  ]: On model.wire_jira.int_jira_intermediate__issues_pivot: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira_intermediate__issues_pivot"} */
select
                field_name as value

            from `ra-development`.`lewis_analytics_dev_integration`.`int_jira_intermediate__issues`

            

            group by field_name
            order by count(*) desc

            

        
[0m09:38:45.053611 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:45.054110 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1329a5340>]}
[0m09:38:45.054341 [info ] [Thread-3  ]: 79 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__harvest_invoice_line_items_fact  [[32mCREATE TABLE (752.0 rows, 195.5 KB processed)[0m in 2.47s]
[0m09:38:45.054625 [debug] [Thread-3  ]: Finished running node model.wire_harvest.wh_delivery__harvest_invoice_line_items_fact
[0m09:38:45.054735 [debug] [Thread-3  ]: Began running node model.wire_jira.int_jira__sprints
[0m09:38:45.054971 [info ] [Thread-3  ]: 85 of 110 START sql view model lewis_analytics_dev_integration.int_jira__sprints  [RUN]
[0m09:38:45.055428 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.wire_jira.int_jira__sprints"
[0m09:38:45.055536 [debug] [Thread-3  ]: Began compiling node model.wire_jira.int_jira__sprints
[0m09:38:45.055624 [debug] [Thread-3  ]: Compiling model.wire_jira.int_jira__sprints
[0m09:38:45.058393 [debug] [Thread-3  ]: Writing injected SQL for node "model.wire_jira.int_jira__sprints"
[0m09:38:45.058734 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:45.058823 [debug] [Thread-3  ]: Began executing node model.wire_jira.int_jira__sprints
[0m09:38:45.061309 [debug] [Thread-3  ]: Writing runtime sql for node "model.wire_jira.int_jira__sprints"
[0m09:38:45.061624 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:45.123290 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:45.123732 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13328e040>]}
[0m09:38:45.123984 [info ] [Thread-5  ]: 77 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__harvest_projects_fact  [[32mCREATE TABLE (443.0 rows, 224.0 KB processed)[0m in 2.75s]
[0m09:38:45.124337 [debug] [Thread-5  ]: Finished running node model.wire_harvest.wh_delivery__harvest_projects_fact
[0m09:38:45.124445 [debug] [Thread-5  ]: Began running node model.jira.int_jira__issue_type_parents
[0m09:38:45.124619 [info ] [Thread-5  ]: 86 of 110 START sql table model lewis_analytics_dev_int_jira.int_jira__issue_type_parents  [RUN]
[0m09:38:45.124988 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_type_parents"
[0m09:38:45.125067 [debug] [Thread-5  ]: Began compiling node model.jira.int_jira__issue_type_parents
[0m09:38:45.125141 [debug] [Thread-5  ]: Compiling model.jira.int_jira__issue_type_parents
[0m09:38:45.135881 [debug] [Thread-5  ]: Writing injected SQL for node "model.jira.int_jira__issue_type_parents"
[0m09:38:45.136102 [debug] [Thread-3  ]: On model.wire_jira.int_jira__sprints: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira__sprints"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira__sprints`
  OPTIONS(
      description=""""""
    )
  as with stg_jira__sprints as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__sprints`

),

int_jira__boards as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__boards`

),

joined as (

    select

        stg_jira__sprints.jira_sprint_natural_key,
        int_jira__boards.jira_board_natural_key,
        int_jira__boards.jira_project_natural_key,

        stg_jira__sprints.jira_sprint_name,
        stg_jira__sprints.jira_sprint_goal,
        stg_jira__sprints.jira_sprint_state,

        stg_jira__sprints.jira_start_at_date,
        stg_jira__sprints.jira_complete_at_date,
        stg_jira__sprints.jira_end_at_date
    
    from stg_jira__sprints

    left join int_jira__boards
    on int_jira__boards.jira_board_natural_key = stg_jira__sprints.jira_sprint_board_natural_key

)

select * from joined;


[0m09:38:45.136688 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:45.136777 [debug] [Thread-5  ]: Began executing node model.jira.int_jira__issue_type_parents
[0m09:38:45.139113 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:45.396947 [debug] [Thread-5  ]: Writing runtime sql for node "model.jira.int_jira__issue_type_parents"
[0m09:38:45.397560 [debug] [Thread-5  ]: On model.jira.int_jira__issue_type_parents: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.int_jira__issue_type_parents"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__issue_type_parents`
    
    
    OPTIONS(
      description="""Table relating issues with data regarding their parent issues (which may be epics). Contains all columns present in `stg_jira__issue`.\n"""
    )
    as (
      
-- needs to be a view to use the dbt_utils.star macro in int_jira__issue_users

with  __dbt__cte__int_jira__issue_field_history as (
with field_history as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_field_history`
    
), 

fields as (
      
    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field`

), 

joined as (
  
  select
    field_history.*,
    fields.field_name

  from field_history
  join fields using (field_id)

)

select *
from joined
),  __dbt__cte__int_jira__issue_epic as (
-- issue-epic relationships are either captured via the issue's parent_issue_id (next-gen projects)
-- or through the 'Epic Link' field (classic projects)
with epic_field_history as (

    select *
    from __dbt__cte__int_jira__issue_field_history
    where lower(field_name) like 'epic%link'
    
),

order_epic_links as (

    select
        issue_id,
        cast(field_value as INT64 ) as epic_issue_id,

        row_number() over (
                partition by issue_id order by updated_at desc
                ) as row_num

    from epic_field_history
),

last_epic_link as (

    select 
      issue_id, 
      epic_issue_id 
    
    from order_epic_links
    where row_num = 1
)

select *
from last_epic_link
),issue as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue`
    
),

issue_type as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_type`
), 
-- issue-epic relationships are either captured via the issue's parent_issue_id (next-gen projects)
-- or through the 'Epic Link' field (classic projects)

issues_w_epics as (

  select * 
  from __dbt__cte__int_jira__issue_epic

), 

issue_enriched_with_epics as (

  select
  
    issue.*,
    coalesce(parent_issue_id, epic_issue_id) as revised_parent_issue_id
  
  from issue
  
  left join issues_w_epics on issues_w_epics.issue_id = issue.issue_id

), 

issue_w_types as (

    select 

        issue_enriched_with_epics.*,
        issue_type.issue_type_name as issue_type
        
    from issue_enriched_with_epics 
    
    left join issue_type on issue_type.issue_type_id = issue_enriched_with_epics.issue_type_id
),

add_parent_info as (

    select
        issue_w_types.*,
        parent.issue_type as parent_issue_type,
        parent.issue_name as parent_issue_name,
        parent.issue_key as parent_issue_key,
        lower(coalesce(parent.issue_type, '')) = 'epic' as is_parent_epic

    from
    issue_w_types

    -- do a left join so we can grab all issue types from this table in `issue_join`
    left join issue_w_types as parent on issue_w_types.revised_parent_issue_id = parent.issue_id

)

select * 
from add_parent_info
    );
  
[0m09:38:45.865712 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:a5f1490b-572e-4f88-99ee-aef9e631888b:europe-west2&page=queryresults
[0m09:38:46.148007 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:46.149276 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133661d60>]}
[0m09:38:46.150072 [info ] [Thread-3  ]: 85 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira__sprints  [[32mCREATE VIEW (0 processed)[0m in 1.09s]
[0m09:38:46.151142 [debug] [Thread-3  ]: Finished running node model.wire_jira.int_jira__sprints
[0m09:38:46.151390 [debug] [Thread-3  ]: Began running node model.wire_harvest.wh_delivery__harvest_invoices_xa
[0m09:38:46.151890 [info ] [Thread-3  ]: 87 of 110 START sql table model lewis_analytics_dev.wh_delivery__harvest_invoices_xa  [RUN]
[0m09:38:46.152752 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.wire_harvest.wh_delivery__harvest_invoices_xa"
[0m09:38:46.153024 [debug] [Thread-3  ]: Began compiling node model.wire_harvest.wh_delivery__harvest_invoices_xa
[0m09:38:46.153172 [debug] [Thread-3  ]: Compiling model.wire_harvest.wh_delivery__harvest_invoices_xa
[0m09:38:46.157900 [debug] [Thread-3  ]: Writing injected SQL for node "model.wire_harvest.wh_delivery__harvest_invoices_xa"
[0m09:38:46.158394 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:46.158524 [debug] [Thread-3  ]: Began executing node model.wire_harvest.wh_delivery__harvest_invoices_xa
[0m09:38:46.161129 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:46.176008 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:6a77cdc2-7f5c-42db-b835-a843cd028fd9:europe-west2&page=queryresults
[0m09:38:46.176808 [debug] [Thread-7  ]: Writing injected SQL for node "model.wire_jira.int_jira_intermediate__issues_pivot"
[0m09:38:46.177237 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:46.177365 [debug] [Thread-7  ]: Began executing node model.wire_jira.int_jira_intermediate__issues_pivot
[0m09:38:46.180700 [debug] [Thread-7  ]: Writing runtime sql for node "model.wire_jira.int_jira_intermediate__issues_pivot"
[0m09:38:46.181045 [debug] [Thread-7  ]: On model.wire_jira.int_jira_intermediate__issues_pivot: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira_intermediate__issues_pivot"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira_intermediate__issues_pivot`
  OPTIONS(
      description=""""""
    )
  as 


with int_jira_intermediate__issues as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira_intermediate__issues`

),

pivot_issue_history as (


    select 
    
      jira_issue_natural_key,
      jira_field_natural_key,

      

      status as jira_issue_field_history_status,

      

      assignee as jira_issue_field_history_assignee,

      

      resolution as jira_issue_field_history_resolution,

      

      story_point_estimate as jira_issue_field_history_story_point_estimate,

      

      description as jira_issue_field_history_description,

      

      summary as jira_issue_field_history_summary,

      

      parent as jira_issue_field_history_parent,

      

      start_date as jira_issue_field_history_start_date,

      

      due_date as jira_issue_field_history_due_date,

      

      end_date as jira_issue_field_history_end_date,

      

      source as jira_issue_field_history_source,

      

      issue_type as jira_issue_field_history_issue_type,

      

      epic_link as jira_issue_field_history_epic_link,

      

      project as jira_issue_field_history_project,

      

      remaining_estimate as jira_issue_field_history_remaining_estimate,

      

      reporter as jira_issue_field_history_reporter,

      

      original_estimate as jira_issue_field_history_original_estimate,

      

      priority as jira_issue_field_history_priority,

      

      time_spent as jira_issue_field_history_time_spent,

      

      baseline_end_date as jira_issue_field_history_baseline_end_date,

      

      baseline_start_date as jira_issue_field_history_baseline_start_date,

      

      satisfaction_date as jira_issue_field_history_satisfaction_date,

      

      satisfaction as jira_issue_field_history_satisfaction,

      

      hubspot_ticket_count__hub_id__4402794_ as jira_issue_field_history_hubspot_ticket_count__hub_id__4402794_,

      

      issue_color as jira_issue_field_history_issue_color,

      

      request_type as jira_issue_field_history_request_type,

      

      creator as jira_issue_field_history_creator,

      

      _remaining_estimate as jira_issue_field_history__remaining_estimate,

      

      operational_categorization as jira_issue_field_history_operational_categorization,

      

      affected_hardware as jira_issue_field_history_affected_hardware,

      

      severity as jira_issue_field_history_severity,

      

      status_category_changed as jira_issue_field_history_status_category_changed,

      

      change_completion_date as jira_issue_field_history_change_completion_date,

      

      product_categorization as jira_issue_field_history_product_categorization,

      

      number_of_linked_intercom_conversations as jira_issue_field_history_number_of_linked_intercom_conversations,

      

      change_reason as jira_issue_field_history_change_reason,

      

      change_start_date as jira_issue_field_history_change_start_date,

      

      planned_start_date as jira_issue_field_history_planned_start_date,

      

      planned_end_date as jira_issue_field_history_planned_end_date,

      

      security_level as jira_issue_field_history_security_level,

      

      created as jira_issue_field_history_created,

      

      change_type as jira_issue_field_history_change_type,

      

      change_risk as jira_issue_field_history_change_risk,

      

      backout_plan as jira_issue_field_history_backout_plan,

      

      test_plan as jira_issue_field_history_test_plan,

      

      resolved as jira_issue_field_history_resolved,

      

      work_ratio as jira_issue_field_history_work_ratio,

      

      parent_link as jira_issue_field_history_parent_link,

      

      investigation_reason as jira_issue_field_history_investigation_reason,

      

      root_cause as jira_issue_field_history_root_cause,

      

      workaround as jira_issue_field_history_workaround,

      

      updated as jira_issue_field_history_updated,

      

      target_start as jira_issue_field_history_target_start,

      

      accelo as jira_issue_field_history_accelo,

      

      _time_spent as jira_issue_field_history__time_spent,

      

      last_viewed as jira_issue_field_history_last_viewed,

      

      program_increment as jira_issue_field_history_program_increment,

      

      task_progress as jira_issue_field_history_task_progress,

      

      target_end as jira_issue_field_history_target_end,

      

      _original_estimate as jira_issue_field_history__original_estimate,

      

      impact as jira_issue_field_history_impact,

      

      urgency as jira_issue_field_history_urgency,

      

      pending_reason as jira_issue_field_history_pending_reason,

      

      implementation_plan as jira_issue_field_history_implementation_plan,

      

      environment as jira_issue_field_history_environment,

      

      planned_end as jira_issue_field_history_planned_end,

      

      planned_start as jira_issue_field_history_planned_start,

      

      linked_intercom_conversation_ids as jira_issue_field_history_linked_intercom_conversation_ids,

      

      time_to_first_response as jira_issue_field_history_time_to_first_response,

      

      time_to_resolution as jira_issue_field_history_time_to_resolution,

      

      work_category as jira_issue_field_history_work_category,

      

      risk_consequence as jira_issue_field_history_risk_consequence,

      

      risk_probability as jira_issue_field_history_risk_probability,

      

      time_to_close_after_resolution as jira_issue_field_history_time_to_close_after_resolution,

      

      time_to_review_normal_change as jira_issue_field_history_time_to_review_normal_change,

      

      team as jira_issue_field_history_team,

      

      rank as jira_issue_field_history_rank,

      

      development as jira_issue_field_history_development,

      

      total_forms as jira_issue_field_history_total_forms,

      

      submitted_forms as jira_issue_field_history_submitted_forms,

      

      locked_forms as jira_issue_field_history_locked_forms,

      

      open_forms as jira_issue_field_history_open_forms,

      

      compass as jira_issue_field_history_compass,

      

      category as jira_issue_field_history_category,

      

      external_issue_id as jira_issue_field_history_external_issue_id,

      

      deliverable_id as jira_issue_field_history_deliverable_id,

      

      deliverable_type as jira_issue_field_history_deliverable_type,

      

      development_stage as jira_issue_field_history_development_stage,

      

      story_points as jira_issue_field_history_story_points,

      

      key as jira_issue_field_history_key,

      

      product as jira_issue_field_history_product,

      

      acceptance_criteria as jira_issue_field_history_acceptance_criteria,

      

      epic_name as jira_issue_field_history_epic_name,

      

      domain as jira_issue_field_history_domain,

      

      position_in_hierarchy_ as jira_issue_field_history_position_in_hierarchy_,

      

      epic_status as jira_issue_field_history_epic_status,

      

      epic_color as jira_issue_field_history_epic_color,

      

      bug_category as jira_issue_field_history_bug_category,

      

      jira_issue_field_history_timestamp,
      jira_issue_field_history_is_active
    
    from

      (select * from int_jira_intermediate__issues)
        pivot(string_agg(jira_issue_field_history_value) for field_name in ( 

      

      'status'

      ,

      

      'assignee'

      ,

      

      'resolution'

      ,

      

      'story_point_estimate'

      ,

      

      'description'

      ,

      

      'summary'

      ,

      

      'parent'

      ,

      

      'start_date'

      ,

      

      'due_date'

      ,

      

      'end_date'

      ,

      

      'source'

      ,

      

      'issue_type'

      ,

      

      'epic_link'

      ,

      

      'project'

      ,

      

      'remaining_estimate'

      ,

      

      'reporter'

      ,

      

      'original_estimate'

      ,

      

      'priority'

      ,

      

      'time_spent'

      ,

      

      'baseline_end_date'

      ,

      

      'baseline_start_date'

      ,

      

      'satisfaction_date'

      ,

      

      'satisfaction'

      ,

      

      'hubspot_ticket_count__hub_id__4402794_'

      ,

      

      'issue_color'

      ,

      

      'request_type'

      ,

      

      'creator'

      ,

      

      '_remaining_estimate'

      ,

      

      'operational_categorization'

      ,

      

      'affected_hardware'

      ,

      

      'severity'

      ,

      

      'status_category_changed'

      ,

      

      'change_completion_date'

      ,

      

      'product_categorization'

      ,

      

      'number_of_linked_intercom_conversations'

      ,

      

      'change_reason'

      ,

      

      'change_start_date'

      ,

      

      'planned_start_date'

      ,

      

      'planned_end_date'

      ,

      

      'security_level'

      ,

      

      'created'

      ,

      

      'change_type'

      ,

      

      'change_risk'

      ,

      

      'backout_plan'

      ,

      

      'test_plan'

      ,

      

      'resolved'

      ,

      

      'work_ratio'

      ,

      

      'parent_link'

      ,

      

      'investigation_reason'

      ,

      

      'root_cause'

      ,

      

      'workaround'

      ,

      

      'updated'

      ,

      

      'target_start'

      ,

      

      'accelo'

      ,

      

      '_time_spent'

      ,

      

      'last_viewed'

      ,

      

      'program_increment'

      ,

      

      'task_progress'

      ,

      

      'target_end'

      ,

      

      '_original_estimate'

      ,

      

      'impact'

      ,

      

      'urgency'

      ,

      

      'pending_reason'

      ,

      

      'implementation_plan'

      ,

      

      'environment'

      ,

      

      'planned_end'

      ,

      

      'planned_start'

      ,

      

      'linked_intercom_conversation_ids'

      ,

      

      'time_to_first_response'

      ,

      

      'time_to_resolution'

      ,

      

      'work_category'

      ,

      

      'risk_consequence'

      ,

      

      'risk_probability'

      ,

      

      'time_to_close_after_resolution'

      ,

      

      'time_to_review_normal_change'

      ,

      

      'team'

      ,

      

      'rank'

      ,

      

      'development'

      ,

      

      'total_forms'

      ,

      

      'submitted_forms'

      ,

      

      'locked_forms'

      ,

      

      'open_forms'

      ,

      

      'compass'

      ,

      

      'category'

      ,

      

      'external_issue_id'

      ,

      

      'deliverable_id'

      ,

      

      'deliverable_type'

      ,

      

      'development_stage'

      ,

      

      'story_points'

      ,

      

      'key'

      ,

      

      'product'

      ,

      

      'acceptance_criteria'

      ,

      

      'epic_name'

      ,

      

      'domain'

      ,

      

      'position_in_hierarchy_'

      ,

      

      'epic_status'

      ,

      

      'epic_color'

      ,

      

      'bug_category'

      

      

      ))

)

select * from pivot_issue_history;


[0m09:38:46.299444 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:1ab10077-a048-48e5-877d-99fac19fad5f:europe-west2&page=queryresults
[0m09:38:46.489943 [debug] [Thread-3  ]: Writing runtime sql for node "model.wire_harvest.wh_delivery__harvest_invoices_xa"
[0m09:38:46.490823 [debug] [Thread-3  ]: On model.wire_harvest.wh_delivery__harvest_invoices_xa: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_harvest.wh_delivery__harvest_invoices_xa"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_invoices_xa`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with wh_delivery__harvest_invoices_fact as (

    select * from `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_invoices_fact`

),

wh_delivery__harvest_expenses_fact as (

    select * from `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_expenses_fact`

),

wh_delivery__harvest_invoice_line_items_fact as (

    select * from `ra-development`.`lewis_analytics_dev`.`wh_delivery__harvest_invoice_line_items_fact`

),

joined as (

    select distinct
    
        wh_delivery__harvest_invoices_fact.harvest_invoice_pk,
        wh_delivery__harvest_invoices_fact.harvest_client_fk,
        
        wh_delivery__harvest_invoices_fact.harvest_invoice_tax_amount,
        
        wh_delivery__harvest_invoices_fact.harvest_invoice_created_at,
        
        sum(wh_delivery__harvest_invoice_line_items_fact.harvest_invoice_line_item_services_amount_billed) +
        sum(wh_delivery__harvest_invoice_line_items_fact.harvest_invoice_line_item_license_referral_fee_amount_billed) as harvest_invoice_revenue_amount_billed,
    
    from wh_delivery__harvest_invoices_fact

    left join wh_delivery__harvest_invoice_line_items_fact
    on wh_delivery__harvest_invoice_line_items_fact.harvest_invoice_fk = wh_delivery__harvest_invoices_fact.harvest_invoice_pk

    group by 1,2,3,4

), 

invoice_aggregates as (

    select

        harvest_invoice_pk,
        
        harvest_invoice_revenue_amount_billed,
        row_number() over (partition by harvest_client_fk order by harvest_invoice_created_at) as harvest_client_invoice_sequence_nunber

    from joined

)

select * from invoice_aggregates
    );
  
[0m09:38:46.502658 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:ac504633-42a8-4367-b214-5043aeb815e0:europe-west2&page=queryresults
[0m09:38:46.618337 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:46.620636 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1336148e0>]}
[0m09:38:46.621629 [info ] [Thread-4  ]: 83 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_fields_dim  [[32mCREATE TABLE (138.0 rows, 4.6 KB processed)[0m in 2.38s]
[0m09:38:46.622908 [debug] [Thread-4  ]: Finished running node model.wire_jira.wh_delivery__jira_fields_dim
[0m09:38:46.623382 [debug] [Thread-4  ]: Began running node model.wire_jira.wh_delivery__jira_sprints_dim
[0m09:38:46.623840 [info ] [Thread-4  ]: 88 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_sprints_dim  [RUN]
[0m09:38:46.624468 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_sprints_dim"
[0m09:38:46.624612 [debug] [Thread-4  ]: Began compiling node model.wire_jira.wh_delivery__jira_sprints_dim
[0m09:38:46.624736 [debug] [Thread-4  ]: Compiling model.wire_jira.wh_delivery__jira_sprints_dim
[0m09:38:46.633202 [debug] [Thread-4  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_sprints_dim"
[0m09:38:46.633751 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:46.633933 [debug] [Thread-4  ]: Began executing node model.wire_jira.wh_delivery__jira_sprints_dim
[0m09:38:46.637154 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:38:46.796951 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:46.797456 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127675460>]}
[0m09:38:46.797701 [info ] [Thread-8  ]: 82 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_epics_dim  [[32mCREATE TABLE (26.0 rows, 2.6 KB processed)[0m in 2.62s]
[0m09:38:46.798062 [debug] [Thread-8  ]: Finished running node model.wire_jira.wh_delivery__jira_epics_dim
[0m09:38:46.820694 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:141804ef-ad59-4096-bbd6-097106ac61a3:europe-west2&page=queryresults
[0m09:38:46.822355 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:46.822836 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ffc430>]}
[0m09:38:46.823092 [info ] [Thread-7  ]: 84 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira_intermediate__issues_pivot  [[32mCREATE VIEW (0 processed)[0m in 1.90s]
[0m09:38:46.823362 [debug] [Thread-7  ]: Finished running node model.wire_jira.int_jira_intermediate__issues_pivot
[0m09:38:46.823626 [debug] [Thread-8  ]: Began running node model.wire_jira.int_jira__issues_field_history
[0m09:38:46.823809 [info ] [Thread-8  ]: 89 of 110 START sql view model lewis_analytics_dev_integration.int_jira__issues_field_history  [RUN]
[0m09:38:46.824246 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.wire_jira.int_jira__issues_field_history"
[0m09:38:46.824347 [debug] [Thread-8  ]: Began compiling node model.wire_jira.int_jira__issues_field_history
[0m09:38:46.824441 [debug] [Thread-8  ]: Compiling model.wire_jira.int_jira__issues_field_history
[0m09:38:46.827806 [debug] [Thread-8  ]: Writing injected SQL for node "model.wire_jira.int_jira__issues_field_history"
[0m09:38:46.828283 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:46.828411 [debug] [Thread-8  ]: Began executing node model.wire_jira.int_jira__issues_field_history
[0m09:38:46.831425 [debug] [Thread-8  ]: Writing runtime sql for node "model.wire_jira.int_jira__issues_field_history"
[0m09:38:46.831788 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:38:46.905356 [debug] [Thread-8  ]: On model.wire_jira.int_jira__issues_field_history: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira__issues_field_history"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira__issues_field_history`
  OPTIONS(
      description=""""""
    )
  as with int_jira_intermediate__issues_pivot as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira_intermediate__issues_pivot`

),

stg_jira__status as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__statuses`

),

base as (

    select

        jira_field_natural_key,
        jira_issue_natural_key,

        row_number() over(partition by jira_issue_natural_key order by jira_issue_field_history_timestamp) as issue_field_history_index,

        jira_issue_field_history_is_active,
        
        cast(jira_issue_field_history_story_point_estimate as numeric) as jira_issue_field_history_story_point_estimate,
        cast(jira_issue_field_history_status as numeric) as jira_status_natural_key,

        jira_issue_field_history_timestamp

    from int_jira_intermediate__issues_pivot

),

joined as (

    select 

        base.*,
        stg_jira__status.jira_status_description as jira_issue_field_history_status_description,
        stg_jira__status.jira_status_name as jira_issue_field_history_status_name

    from base

    left join stg_jira__status
    on base.jira_status_natural_key = stg_jira__status.jira_status_natural_key

)

select * from joined;


[0m09:38:46.914035 [debug] [Thread-4  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_sprints_dim"
[0m09:38:46.914384 [debug] [Thread-4  ]: On model.wire_jira.wh_delivery__jira_sprints_dim: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_sprints_dim"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_sprints_dim`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_jira__sprints as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__sprints`

),

final as (

    select

        
    
to_hex(md5(cast(coalesce(cast(jira_sprint_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_sprint_pk,

        
    
to_hex(md5(cast(coalesce(cast(jira_project_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_project_fk,

        jira_sprint_name,
        jira_sprint_goal,

        jira_sprint_state,

        jira_start_at_date,
        jira_complete_at_date,
        jira_end_at_date

    from int_jira__sprints

)

select * from final
    );
  
[0m09:38:47.342686 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:0abdafe7-2cd6-4586-8c6d-ca1302bd0bbd:europe-west2&page=queryresults
[0m09:38:47.554604 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:16c14311-5ae2-409c-8492-e235f057d8eb:europe-west2&page=queryresults
[0m09:38:47.628839 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:47.630245 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1276971c0>]}
[0m09:38:47.630846 [info ] [Thread-6  ]: 80 of 110 OK created sql incremental model lewis_analytics_dev_int_jira.int_jira__agg_multiselect_history  [[32mMERGE (44.0 rows, 9.3 MB processed)[0m in 3.72s]
[0m09:38:47.631584 [debug] [Thread-6  ]: Finished running node model.jira.int_jira__agg_multiselect_history
[0m09:38:47.632233 [debug] [Thread-7  ]: Began running node model.jira.int_jira__combine_field_histories
[0m09:38:47.632697 [info ] [Thread-7  ]: 90 of 110 START sql incremental model lewis_analytics_dev_int_jira.int_jira__combine_field_histories  [RUN]
[0m09:38:47.633734 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.jira.int_jira__combine_field_histories"
[0m09:38:47.634001 [debug] [Thread-7  ]: Began compiling node model.jira.int_jira__combine_field_histories
[0m09:38:47.634335 [debug] [Thread-7  ]: Compiling model.jira.int_jira__combine_field_histories
[0m09:38:47.778451 [debug] [Thread-7  ]: Writing injected SQL for node "model.jira.int_jira__combine_field_histories"
[0m09:38:47.779700 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:82bf684a-3cc0-45e4-b109-39b164f77b22:europe-west2&page=queryresults
[0m09:38:47.781640 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:47.781773 [debug] [Thread-7  ]: Began executing node model.jira.int_jira__combine_field_histories
[0m09:38:47.784137 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:47.812305 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:a34d2296-8f8e-4e66-8e13-f83d3883a6dd:europe-west2&page=queryresults
[0m09:38:47.921801 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:47.922277 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133c95250>]}
[0m09:38:48.042292 [debug] [Thread-7  ]: Writing runtime sql for node "model.jira.int_jira__combine_field_histories"
[0m09:38:48.042953 [debug] [Thread-7  ]: On model.jira.int_jira__combine_field_histories: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.int_jira__combine_field_histories"} */

        
            
            
        
    

    

    merge into `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__combine_field_histories` as DBT_INTERNAL_DEST
        using (
          

with  __dbt__cte__int_jira__issue_field_history as (
with field_history as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_field_history`
    
), 

fields as (
      
    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field`

), 

joined as (
  
  select
    field_history.*,
    fields.field_name

  from field_history
  join fields using (field_id)

)

select *
from joined
),issue_field_history as (

    select * from __dbt__cte__int_jira__issue_field_history

    
    where cast( updated_at as date) >= (select max(valid_starting_on) from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__combine_field_histories` )
    
),

issue_multiselect_batch_history as (

    select * from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__agg_multiselect_history`

    
    where cast( updated_at as date) >= (select max(valid_starting_on) from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__combine_field_histories` )
    
),

combine_field_history as (
-- combining all the field histories together
    select 
        field_id,
        issue_id,
        updated_at,
        field_value,
        field_name

    from issue_field_history

    union all

    select 
        field_id,
        issue_id,
        updated_at,
        field_values as field_value, -- this is an aggregated list but we'll just call it field_value
        field_name

    from issue_multiselect_batch_history
),

get_valid_dates as (


    select 
        field_id,
        issue_id,
        field_value,
        field_name,
        updated_at as valid_starting_at,

        -- this value is valid until the next value is updated
        lead(updated_at, 1) over(partition by issue_id, field_id order by updated_at asc) as valid_ending_at, 

        cast( timestamp_trunc(
        cast(updated_at as timestamp),
        day
    ) as date) as valid_starting_on

    from combine_field_history

),

surrogate_key as (

    select 
    *,
    
    
to_hex(md5(cast(coalesce(cast(field_id as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(issue_id as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(valid_starting_at as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as combined_history_id

    from get_valid_dates

)

select * from surrogate_key
        ) as DBT_INTERNAL_SOURCE
        on 
                DBT_INTERNAL_SOURCE.combined_history_id = DBT_INTERNAL_DEST.combined_history_id
            

    
    when matched then update set
        `field_id` = DBT_INTERNAL_SOURCE.`field_id`,`issue_id` = DBT_INTERNAL_SOURCE.`issue_id`,`field_value` = DBT_INTERNAL_SOURCE.`field_value`,`field_name` = DBT_INTERNAL_SOURCE.`field_name`,`valid_starting_at` = DBT_INTERNAL_SOURCE.`valid_starting_at`,`valid_ending_at` = DBT_INTERNAL_SOURCE.`valid_ending_at`,`valid_starting_on` = DBT_INTERNAL_SOURCE.`valid_starting_on`,`combined_history_id` = DBT_INTERNAL_SOURCE.`combined_history_id`
    

    when not matched then insert
        (`field_id`, `issue_id`, `field_value`, `field_name`, `valid_starting_at`, `valid_ending_at`, `valid_starting_on`, `combined_history_id`)
    values
        (`field_id`, `issue_id`, `field_value`, `field_name`, `valid_starting_at`, `valid_ending_at`, `valid_starting_on`, `combined_history_id`)


    
[0m09:38:48.083858 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:48.084483 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133ef7100>]}
[0m09:38:48.093126 [debug] [Thread-8  ]: finished collecting timing info
[0m09:38:48.093719 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x134157a30>]}
[0m09:38:48.356774 [info ] [Thread-1  ]: 81 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__harvest_time_sheets_fact  [[32mCREATE TABLE (10.7k rows, 2.9 MB processed)[0m in 3.92s]
[0m09:38:48.357382 [info ] [Thread-5  ]: 86 of 110 OK created sql table model lewis_analytics_dev_int_jira.int_jira__issue_type_parents  [[32mCREATE TABLE (4.8k rows, 19.3 MB processed)[0m in 2.96s]
[0m09:38:48.357905 [info ] [Thread-8  ]: 89 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira__issues_field_history  [[32mCREATE VIEW (0 processed)[0m in 1.27s]
[0m09:38:48.359109 [debug] [Thread-1  ]: Finished running node model.wire_harvest.wh_delivery__harvest_time_sheets_fact
[0m09:38:48.359902 [debug] [Thread-5  ]: Finished running node model.jira.int_jira__issue_type_parents
[0m09:38:48.360543 [debug] [Thread-8  ]: Finished running node model.wire_jira.int_jira__issues_field_history
[0m09:38:48.361430 [debug] [Thread-6  ]: Began running node model.jira.int_jira__issue_users
[0m09:38:48.362488 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_users"
[0m09:38:48.362767 [debug] [Thread-5  ]: Began running node model.wire_jira.wh_delivery__jira_issues_field_history_fact
[0m09:38:48.362970 [debug] [Thread-6  ]: Began compiling node model.jira.int_jira__issue_users
[0m09:38:48.363378 [info ] [Thread-5  ]: 91 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_issues_field_history_fact  [RUN]
[0m09:38:48.363576 [debug] [Thread-6  ]: Compiling model.jira.int_jira__issue_users
[0m09:38:48.364244 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_issues_field_history_fact"
[0m09:38:48.376186 [debug] [Thread-5  ]: Began compiling node model.wire_jira.wh_delivery__jira_issues_field_history_fact
[0m09:38:48.376744 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:48.376931 [debug] [Thread-5  ]: Compiling model.wire_jira.wh_delivery__jira_issues_field_history_fact
[0m09:38:48.387400 [debug] [Thread-5  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_issues_field_history_fact"
[0m09:38:48.388004 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:48.388155 [debug] [Thread-5  ]: Began executing node model.wire_jira.wh_delivery__jira_issues_field_history_fact
[0m09:38:48.390832 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:38:48.612174 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:b0ac14bb-9bd9-4ab8-b27c-405ff3a31994:europe-west2&page=queryresults
[0m09:38:48.664274 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira.int_jira__issue_users"
[0m09:38:48.664895 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:48.665627 [debug] [Thread-6  ]: Finished running node model.jira.int_jira__issue_users
[0m09:38:48.666007 [debug] [Thread-1  ]: Began running node model.jira.int_jira__issue_join
[0m09:38:48.666280 [info ] [Thread-1  ]: 92 of 110 START sql table model lewis_analytics_dev_int_jira.int_jira__issue_join  [RUN]
[0m09:38:48.666902 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira.int_jira__issue_join"
[0m09:38:48.667053 [debug] [Thread-1  ]: Began compiling node model.jira.int_jira__issue_join
[0m09:38:48.667187 [debug] [Thread-1  ]: Compiling model.jira.int_jira__issue_join
[0m09:38:48.707839 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira.int_jira__issue_join"
[0m09:38:48.709293 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:48.709447 [debug] [Thread-1  ]: Began executing node model.jira.int_jira__issue_join
[0m09:38:48.711549 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:38:48.899950 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:48.900610 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1336ca910>]}
[0m09:38:48.900996 [info ] [Thread-3  ]: 87 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__harvest_invoices_xa  [[32mCREATE TABLE (501.0 rows, 78.0 KB processed)[0m in 2.75s]
[0m09:38:48.901440 [debug] [Thread-3  ]: Finished running node model.wire_harvest.wh_delivery__harvest_invoices_xa
[0m09:38:48.979854 [debug] [Thread-1  ]: Writing runtime sql for node "model.jira.int_jira__issue_join"
[0m09:38:48.980546 [debug] [Thread-1  ]: On model.jira.int_jira__issue_join: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.int_jira__issue_join"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__issue_join`
    
    
    OPTIONS(
      description="""The core issue table, enhanced with current-status attributes from foreign-key-related tables, and metrics regarding resolutions and assignments.\n"""
    )
    as (
      

with  __dbt__cte__int_jira__issue_users as (
-- just grabs user attributes for issue assignees and reporters 

with issue as (

    -- including issue_id in here because snowflake for some reason ignores issue_id,
    -- so we'll just always pull it out and explicitly select it
    

    select
        issue_id,
        coalesce(revised_parent_issue_id, parent_issue_id) as parent_issue_id,

        `original_estimate_seconds`,
  `remaining_estimate_seconds`,
  `time_spent_seconds`,
  `assignee_user_id`,
  `created_at`,
  `resolved_at`,
  `creator_user_id`,
  `issue_description`,
  `due_date`,
  `environment`,
  `issue_type_id`,
  `issue_key`,
  `priority_id`,
  `project_id`,
  `reporter_user_id`,
  `resolution_id`,
  `status_id`,
  `status_changed_at`,
  `issue_name`,
  `updated_at`,
  `work_ratio`,
  `_fivetran_synced`,
  `issue_type`,
  `parent_issue_type`,
  `parent_issue_name`,
  `parent_issue_key`,
  `is_parent_epic`


    
    from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__issue_type_parents`

),

-- user is a reserved keyword in AWS
jira_user as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__user`
),

issue_user_join as (

    select
        issue.*,
        assignee.user_display_name as assignee_name,
        assignee.time_zone as assignee_timezone,
        assignee.email as assignee_email,
        reporter.email as reporter_email,
        reporter.user_display_name as reporter_name,
        reporter.time_zone as reporter_timezone
        
        
    from issue
    left join jira_user as assignee on issue.assignee_user_id = assignee.user_id 
    left join jira_user as reporter on issue.reporter_user_id = reporter.user_id

)

select * 
from issue_user_join
),  __dbt__cte__int_jira__issue_multiselect_history as (
with issue_multiselect_history as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_multiselect_history`
    
), 

fields as (
      
    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field`

), 

joined as (
  
  select
    issue_multiselect_history.*,
    fields.field_name

  from issue_multiselect_history
  join fields using (field_id)

)

select *
from joined
),  __dbt__cte__int_jira__issue_sprint as (


with sprint as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__sprint`

),

field_history as (

     -- sprints don't appear to be capable of multiselect in the UI...
    select *
    from __dbt__cte__int_jira__issue_multiselect_history

),

sprint_field_history as (

    select 
        field_history.*,
        sprint.*,
        row_number() over (
                    partition by field_history.issue_id 
                    order by field_history.updated_at desc, sprint.started_at desc         
                    ) as row_num
    from field_history
    join sprint on field_history.field_value = cast(sprint.sprint_id as STRING)
    where lower(field_history.field_name) = 'sprint'
),


last_sprint as (

    select *
    from sprint_field_history
    
    where row_num = 1

), 

sprint_rollovers as (

    select 
        issue_id,
        count(distinct case when field_value is not null then field_value end) as count_sprint_changes
    
    from sprint_field_history
    group by 1

),

issue_sprint as (

    select 
        last_sprint.issue_id,
        last_sprint.field_value as current_sprint_id,
        last_sprint.sprint_name as current_sprint_name,
        last_sprint.board_id,
        last_sprint.started_at as sprint_started_at,
        last_sprint.ended_at as sprint_ended_at,
        last_sprint.completed_at as sprint_completed_at,
        coalesce(sprint_rollovers.count_sprint_changes, 0) as count_sprint_changes

    from 
    last_sprint 
    left join sprint_rollovers on sprint_rollovers.issue_id = last_sprint.issue_id
    
)

select * from issue_sprint
),  __dbt__cte__int_jira__issue_comments as (


with comment as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__comment`

    order by issue_id, created_at asc

),

-- user is a reserved keyword in AWS 
jira_user as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__user`
),

agg_comments as (

    select 
    comment.issue_id,
    
    string_agg(comment.created_at || '  -  ' || jira_user.user_display_name || ':  ' || comment.body, '\n')

 as conversation,
    count(comment.comment_id) as count_comments

    from
    comment 
    join jira_user on comment.author_user_id = jira_user.user_id

    group by 1
)

select * from agg_comments
),  __dbt__cte__int_jira__issue_field_history as (
with field_history as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__issue_field_history`
    
), 

fields as (
      
    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field`

), 

joined as (
  
  select
    field_history.*,
    fields.field_name

  from field_history
  join fields using (field_id)

)

select *
from joined
),  __dbt__cte__int_jira__issue_assign_resolution as (
with issue_field_history as (
    
    select *
    from __dbt__cte__int_jira__issue_field_history

), 

filtered as (
    -- we're only looking at assignments and resolutions, which are single-field values
    select *
    from issue_field_history

    where (lower(field_id) = 'assignee'
    or lower(field_id) = 'resolutiondate')

    and field_value is not null -- remove initial null rows
),

issue_dates as (

    select

        issue_id,
        min(case when field_id = 'assignee' then updated_at end) as first_assigned_at,
        max(case when field_id = 'assignee' then updated_at end) as last_assigned_at,
        min(case when field_id = 'resolutiondate' then updated_at end) as first_resolved_at -- in case it's been re-opened

    from filtered
    group by 1
)

select *
from issue_dates
),  __dbt__cte__int_jira__issue_versions as (


with version as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__version`
),

version_history as (

    select *
    from __dbt__cte__int_jira__issue_multiselect_history

    where field_id = 'versions'
        or field_id = 'fixVersions'
),

order_versions as (

    select
        *,
        -- using rank so batches stick together
        rank() over (
            partition by field_id, issue_id
            order by updated_at desc
            ) as row_num

    from version_history
),

latest_versions as (

    select 
        field_id,
        issue_id,	
        updated_at,
        cast(field_value as INT64) as version_id
    from order_versions
    where row_num = 1
),

version_info as (

    select 
        latest_versions.field_id,
        latest_versions.issue_id,
        
    string_agg(version.version_name, ', ')

 as versions

    from latest_versions
    join version on latest_versions.version_id = version.version_id

    group by 1,2
),

split_versions as (

    select 
        issue_id,
        case when field_id = 'versions' then versions else null end as affects_versions,
        case when field_id = 'fixVersions' then versions else null end as fixes_versions
    from version_info
),

final as (

    select 
        issue_id,
        max(affects_versions) as affects_versions,
        max(fixes_versions) as fixes_versions
    from split_versions
    group by 1
)

select *
from final
),issue as (

    select *
    from __dbt__cte__int_jira__issue_users

),

project as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__project`
),

status as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__status`
),

status_category as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__status_category`
),

resolution as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__resolution`
),


priority as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__priority`
),



issue_sprint as (

    select *
    from __dbt__cte__int_jira__issue_sprint
),



issue_comments as (

    select * 
    from __dbt__cte__int_jira__issue_comments
),


issue_assignments_and_resolutions as (
  
  select *
  from __dbt__cte__int_jira__issue_assign_resolution

),


issue_versions as (

    select *
    from __dbt__cte__int_jira__issue_versions
),


join_issue as (

    select
        issue.* 

        ,project.project_name as project_name

        ,status.status_name as current_status
        ,status_category.status_category_name as current_status_category   
        ,resolution.resolution_name as resolution_type
        
        ,priority.priority_name as current_priority
	

        
        ,issue_sprint.current_sprint_id
        ,issue_sprint.current_sprint_name
        ,coalesce(issue_sprint.count_sprint_changes, 0) as count_sprint_changes
        ,issue_sprint.sprint_started_at
        ,issue_sprint.sprint_ended_at
        ,issue_sprint.sprint_completed_at
        ,coalesce(issue_sprint.sprint_started_at <= current_timestamp
          and coalesce(issue_sprint.sprint_completed_at, current_timestamp) >= current_timestamp  
          , false) as is_active_sprint -- If sprint doesn't have a start date, default to false. If it does have a start date, but no completed date, this means that the sprint is active. The ended_at timestamp is irrelevant here.
        

        ,issue_assignments_and_resolutions.first_assigned_at
        ,issue_assignments_and_resolutions.last_assigned_at
        ,issue_assignments_and_resolutions.first_resolved_at

        
        ,issue_versions.fixes_versions
        ,issue_versions.affects_versions
        

        
        ,issue_comments.conversation
        ,coalesce(issue_comments.count_comments, 0) as count_comments
        
    
    from issue
    left join project on project.project_id = issue.project_id
    left join status on status.status_id = issue.status_id
    left join status_category on status.status_category_id = status_category.status_category_id
    left join resolution on resolution.resolution_id = issue.resolution_id
	
    left join priority on priority.priority_id = issue.priority_id
	
    left join issue_assignments_and_resolutions on issue_assignments_and_resolutions.issue_id = issue.issue_id

    
    left join issue_versions on issue_versions.issue_id = issue.issue_id
    
    
    
    left join issue_sprint on issue_sprint.issue_id = issue.issue_id
    

    
    left join issue_comments on issue_comments.issue_id = issue.issue_id
    
)

select * 
from join_issue
    );
  
[0m09:38:49.051206 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:21a81288-79b7-4fed-8e45-1d9e6610a7ac:europe-west2&page=queryresults
[0m09:38:49.093036 [debug] [Thread-5  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_issues_field_history_fact"
[0m09:38:49.093815 [debug] [Thread-5  ]: On model.wire_jira.wh_delivery__jira_issues_field_history_fact: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_issues_field_history_fact"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_issues_field_history_fact`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_jira__issues_field_history as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__issues_field_history`

),

final as (

    select

        
    
to_hex(md5(cast(coalesce(cast(jira_field_natural_key as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(jira_issue_natural_key as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(jira_issue_field_history_timestamp as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_issues_field_history_pk,  
        
        
    
to_hex(md5(cast(coalesce(cast(jira_field_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_field_fk,
        
        
    
to_hex(md5(cast(coalesce(cast(jira_issue_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_issue_fk,       

        jira_issue_field_history_is_active,
        jira_issue_field_history_story_point_estimate,
        jira_issue_field_history_status_description,
        jira_issue_field_history_status_name,
        jira_issue_field_history_timestamp

    from int_jira__issues_field_history

)

select * from final
    );
  
[0m09:38:49.349406 [debug] [Thread-4  ]: finished collecting timing info
[0m09:38:49.350491 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126f45ca0>]}
[0m09:38:49.351398 [info ] [Thread-4  ]: 88 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_sprints_dim  [[32mCREATE TABLE (254.0 rows, 36.3 KB processed)[0m in 2.73s]
[0m09:38:49.352374 [debug] [Thread-4  ]: Finished running node model.wire_jira.wh_delivery__jira_sprints_dim
[0m09:38:51.623260 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:2fd8af79-05a3-4e11-8c88-492c7824b65f:europe-west2&page=queryresults
[0m09:38:51.925707 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:51.927113 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127a2d3d0>]}
[0m09:38:51.927723 [info ] [Thread-7  ]: 90 of 110 OK created sql incremental model lewis_analytics_dev_int_jira.int_jira__combine_field_histories  [[32mMERGE (111.0 rows, 70.2 MB processed)[0m in 4.29s]
[0m09:38:51.928514 [debug] [Thread-7  ]: Finished running node model.jira.int_jira__combine_field_histories
[0m09:38:51.929145 [debug] [Thread-6  ]: Began running node model.jira.int_jira__daily_field_history
[0m09:38:51.929491 [info ] [Thread-6  ]: 93 of 110 START sql incremental model lewis_analytics_dev_int_jira.int_jira__daily_field_history  [RUN]
[0m09:38:51.930509 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira.int_jira__daily_field_history"
[0m09:38:51.930717 [debug] [Thread-6  ]: Began compiling node model.jira.int_jira__daily_field_history
[0m09:38:51.930943 [debug] [Thread-6  ]: Compiling model.jira.int_jira__daily_field_history
[0m09:38:51.940925 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira.int_jira__daily_field_history"
[0m09:38:51.941485 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:51.941633 [debug] [Thread-6  ]: Began executing node model.jira.int_jira__daily_field_history
[0m09:38:51.945192 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:38:51.959684 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:efc19013-b783-41a9-945e-c9b261ea867e:europe-west2&page=queryresults
[0m09:38:52.240406 [debug] [Thread-6  ]: Writing runtime sql for node "model.jira.int_jira__daily_field_history"
[0m09:38:52.240974 [debug] [Thread-6  ]: On model.jira.int_jira__daily_field_history: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.int_jira__daily_field_history"} */

        
            
            
        
    

    

    merge into `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__daily_field_history` as DBT_INTERNAL_DEST
        using (
          

with combined_field_histories as (

    select * 
    from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__combine_field_histories`

    
    where valid_starting_on >= (select max(valid_starting_on) from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__daily_field_history` )
    
),


limit_to_relevant_fields as (

-- let's remove unncessary rows moving forward and grab field names 
    select 
        combined_field_histories.*

    from combined_field_histories

    where lower(field_id) = 'status' 
            or lower(field_name) in ('sprint')
    
),

order_daily_values as (

    select 
        *,

        -- want to grab last value for an issue's field for each day
        row_number() over (
            partition by valid_starting_on, issue_id, field_id
            order by valid_starting_at desc
            ) as row_num

    from limit_to_relevant_fields
),

-- only looking at the latest value for each day
get_latest_daily_value as (

    select * 
    from order_daily_values

    where row_num = 1
), 

final as (

    select
        field_id,
        issue_id,
        field_name,

        -- doing this to figure out what values are actually null and what needs to be backfilled in jira__daily_issue_field_history
        case when field_value is null then 'is_null' else field_value end as field_value,
        valid_starting_at,
        valid_ending_at, 
        valid_starting_on,

        
    
to_hex(md5(cast(coalesce(cast(field_id as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(issue_id as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(valid_starting_on as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as issue_field_day_id
        
    from get_latest_daily_value
)

select * from final
        ) as DBT_INTERNAL_SOURCE
        on 
                DBT_INTERNAL_SOURCE.issue_field_day_id = DBT_INTERNAL_DEST.issue_field_day_id
            

    
    when matched then update set
        `field_id` = DBT_INTERNAL_SOURCE.`field_id`,`issue_id` = DBT_INTERNAL_SOURCE.`issue_id`,`field_name` = DBT_INTERNAL_SOURCE.`field_name`,`field_value` = DBT_INTERNAL_SOURCE.`field_value`,`valid_starting_at` = DBT_INTERNAL_SOURCE.`valid_starting_at`,`valid_ending_at` = DBT_INTERNAL_SOURCE.`valid_ending_at`,`valid_starting_on` = DBT_INTERNAL_SOURCE.`valid_starting_on`,`issue_field_day_id` = DBT_INTERNAL_SOURCE.`issue_field_day_id`
    

    when not matched then insert
        (`field_id`, `issue_id`, `field_name`, `field_value`, `valid_starting_at`, `valid_ending_at`, `valid_starting_on`, `issue_field_day_id`)
    values
        (`field_id`, `issue_id`, `field_name`, `field_value`, `valid_starting_at`, `valid_ending_at`, `valid_starting_on`, `issue_field_day_id`)


    
[0m09:38:52.251294 [debug] [Thread-1  ]: finished collecting timing info
[0m09:38:52.251903 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133ce5bb0>]}
[0m09:38:52.252200 [info ] [Thread-1  ]: 92 of 110 OK created sql table model lewis_analytics_dev_int_jira.int_jira__issue_join  [[32mCREATE TABLE (4.8k rows, 25.4 MB processed)[0m in 3.59s]
[0m09:38:52.252725 [debug] [Thread-1  ]: Finished running node model.jira.int_jira__issue_join
[0m09:38:54.685951 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:3d36e68c-7dd4-4d01-9ef4-b80bd0a9271f:europe-west2&page=queryresults
[0m09:38:54.966714 [debug] [Thread-5  ]: finished collecting timing info
[0m09:38:54.967685 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127a0d490>]}
[0m09:38:54.968178 [info ] [Thread-5  ]: 91 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_issues_field_history_fact  [[32mCREATE TABLE (457.4k rows, 17.9 MB processed)[0m in 6.60s]
[0m09:38:54.968882 [debug] [Thread-5  ]: Finished running node model.wire_jira.wh_delivery__jira_issues_field_history_fact
[0m09:38:55.205990 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:9038320e-9daf-4213-a4c0-f9a03758759c:europe-west2&page=queryresults
[0m09:38:55.498634 [debug] [Thread-6  ]: finished collecting timing info
[0m09:38:55.500387 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127ec8e80>]}
[0m09:38:55.501219 [info ] [Thread-6  ]: 93 of 110 OK created sql incremental model lewis_analytics_dev_int_jira.int_jira__daily_field_history  [[32mMERGE (11.0 rows, 33.8 MB processed)[0m in 3.57s]
[0m09:38:55.502469 [debug] [Thread-6  ]: Finished running node model.jira.int_jira__daily_field_history
[0m09:38:55.503228 [debug] [Thread-3  ]: Began running node model.jira.int_jira__pivot_daily_field_history
[0m09:38:55.503659 [info ] [Thread-3  ]: 94 of 110 START sql incremental model lewis_analytics_dev_int_jira.int_jira__pivot_daily_field_history  [RUN]
[0m09:38:55.504263 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.jira.int_jira__pivot_daily_field_history"
[0m09:38:55.504370 [debug] [Thread-3  ]: Began compiling node model.jira.int_jira__pivot_daily_field_history
[0m09:38:55.504467 [debug] [Thread-3  ]: Compiling model.jira.int_jira__pivot_daily_field_history
[0m09:38:55.512211 [debug] [Thread-3  ]: Writing injected SQL for node "model.jira.int_jira__pivot_daily_field_history"
[0m09:38:55.512666 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:55.512814 [debug] [Thread-3  ]: Began executing node model.jira.int_jira__pivot_daily_field_history
[0m09:38:55.516639 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:38:55.795891 [debug] [Thread-3  ]: Writing runtime sql for node "model.jira.int_jira__pivot_daily_field_history"
[0m09:38:55.796520 [debug] [Thread-3  ]: On model.jira.int_jira__pivot_daily_field_history: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.int_jira__pivot_daily_field_history"} */

        
            
            
        
    

    

    merge into `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__pivot_daily_field_history` as DBT_INTERNAL_DEST
        using (
          

-- latest value per issue field (already limited included fields to sprint, status, and var(issue_field_history_columns))
with daily_field_history as (

    select * 
    from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__daily_field_history`

    
    where valid_starting_on >= (select max(valid_starting_on) from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__pivot_daily_field_history` )
    
),

pivot_out as (

    -- pivot out default columns (status and sprint) and others specified in the var(issue_field_history_columns)
    -- only days on which a field value was actively changed will have a non-null value. the nulls will need to 
    -- be backfilled in the final jira__daily_issue_field_history model
    select 
        valid_starting_on, 
        issue_id,
        max(case when lower(field_id) = 'status' then field_value end) as status,
        max(case when lower(field_name) = 'sprint' then field_value end) as sprint

        from daily_field_history

    group by 1,2
),

surrogate_key as (

    select 
        *,
        
    
to_hex(md5(cast(coalesce(cast(valid_starting_on as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(issue_id as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as issue_day_id

    from pivot_out
)

select * from surrogate_key
        ) as DBT_INTERNAL_SOURCE
        on 
                DBT_INTERNAL_SOURCE.issue_day_id = DBT_INTERNAL_DEST.issue_day_id
            

    
    when matched then update set
        `valid_starting_on` = DBT_INTERNAL_SOURCE.`valid_starting_on`,`issue_id` = DBT_INTERNAL_SOURCE.`issue_id`,`status` = DBT_INTERNAL_SOURCE.`status`,`sprint` = DBT_INTERNAL_SOURCE.`sprint`,`issue_day_id` = DBT_INTERNAL_SOURCE.`issue_day_id`
    

    when not matched then insert
        (`valid_starting_on`, `issue_id`, `status`, `sprint`, `issue_day_id`)
    values
        (`valid_starting_on`, `issue_id`, `status`, `sprint`, `issue_day_id`)


    
[0m09:38:58.675035 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:fe21f87c-ac8d-4b6b-84c2-5c9cd53fe5e4:europe-west2&page=queryresults
[0m09:38:58.973673 [debug] [Thread-3  ]: finished collecting timing info
[0m09:38:58.974749 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127ec2670>]}
[0m09:38:58.975445 [info ] [Thread-3  ]: 94 of 110 OK created sql incremental model lewis_analytics_dev_int_jira.int_jira__pivot_daily_field_history  [[32mMERGE (10.0 rows, 1.8 MB processed)[0m in 3.47s]
[0m09:38:58.976415 [debug] [Thread-3  ]: Finished running node model.jira.int_jira__pivot_daily_field_history
[0m09:38:58.977104 [debug] [Thread-7  ]: Began running node model.jira.int_jira__field_history_scd
[0m09:38:58.977449 [info ] [Thread-7  ]: 95 of 110 START sql table model lewis_analytics_dev_int_jira.int_jira__field_history_scd  [RUN]
[0m09:38:58.978472 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.jira.int_jira__field_history_scd"
[0m09:38:58.978734 [debug] [Thread-7  ]: Began compiling node model.jira.int_jira__field_history_scd
[0m09:38:58.978930 [debug] [Thread-7  ]: Compiling model.jira.int_jira__field_history_scd
[0m09:38:58.987113 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:38:59.264424 [debug] [Thread-7  ]: Writing injected SQL for node "model.jira.int_jira__field_history_scd"
[0m09:38:59.265111 [debug] [Thread-7  ]: finished collecting timing info
[0m09:38:59.265321 [debug] [Thread-7  ]: Began executing node model.jira.int_jira__field_history_scd
[0m09:38:59.363787 [debug] [Thread-7  ]: Writing runtime sql for node "model.jira.int_jira__field_history_scd"
[0m09:38:59.364789 [debug] [Thread-7  ]: On model.jira.int_jira__field_history_scd: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.int_jira__field_history_scd"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__field_history_scd`
    
    
    OPTIONS(
      description="""Slowly-changing-dimension model that fills values from differnt fields in the pivoted daily history model.  Note: this is the singular field history-related model that is not incremental (materialized as table)\n"""
    )
    as (
      with change_data as (

    select *
    from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__pivot_daily_field_history`

), set_values as (

    select 
        valid_starting_on, 
        issue_id,
        issue_day_id

         
        , status
        -- create a batch/partition once a new value is provided
        , sum( case when status is null then 0 else 1 end) over ( partition by issue_id 
            order by valid_starting_on rows unbounded preceding) as status_field_partition

         
        , sprint
        -- create a batch/partition once a new value is provided
        , sum( case when sprint is null then 0 else 1 end) over ( partition by issue_id 
            order by valid_starting_on rows unbounded preceding) as sprint_field_partition

        
    
    from change_data

), fill_values as (

-- each row of the pivoted table includes field values if that field was updated on that day
-- we need to backfill to persist values that have been previously updated and are still valid 
    select 
        valid_starting_on, 
        issue_id,
        issue_day_id
        
         

        -- grab the value that started this batch/partition
        , first_value( status ) over (
            partition by issue_id, status_field_partition 
            order by valid_starting_on asc rows between unbounded preceding and current row) as status

         

        -- grab the value that started this batch/partition
        , first_value( sprint ) over (
            partition by issue_id, sprint_field_partition 
            order by valid_starting_on asc rows between unbounded preceding and current row) as sprint

        

    from set_values

)

select *
from fill_values
    );
  
[0m09:39:02.285559 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:9b603cc2-2c48-41b8-8298-e538f8880ae4:europe-west2&page=queryresults
[0m09:39:02.560734 [debug] [Thread-7  ]: finished collecting timing info
[0m09:39:02.562891 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127ec2a60>]}
[0m09:39:02.563720 [info ] [Thread-7  ]: 95 of 110 OK created sql table model lewis_analytics_dev_int_jira.int_jira__field_history_scd  [[32mCREATE TABLE (16.0k rows, 943.7 KB processed)[0m in 3.58s]
[0m09:39:02.564914 [debug] [Thread-7  ]: Finished running node model.jira.int_jira__field_history_scd
[0m09:39:29.683204 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:43cc0399-4f39-42c9-8534-8aa0ebebad9b:europe-west2&page=queryresults
[0m09:39:30.043663 [debug] [Thread-2  ]: finished collecting timing info
[0m09:39:30.045274 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1329dc8b0>]}
[0m09:39:30.046064 [info ] [Thread-2  ]: 72 of 110 OK created sql incremental model lewis_analytics_dev_int_jira.int_jira__issue_calendar_spine  [[32mMERGE (953.7k rows, 54.6 MB processed)[0m in 48.61s]
[0m09:39:30.047199 [debug] [Thread-2  ]: Finished running node model.jira.int_jira__issue_calendar_spine
[0m09:39:30.049373 [debug] [Thread-1  ]: Began running node model.jira.jira__daily_issue_field_history
[0m09:39:30.049840 [info ] [Thread-1  ]: 96 of 110 START sql incremental model lewis_analytics_dev_jira.jira__daily_issue_field_history  [RUN]
[0m09:39:30.050771 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.jira.jira__daily_issue_field_history"
[0m09:39:30.050980 [debug] [Thread-1  ]: Began compiling node model.jira.jira__daily_issue_field_history
[0m09:39:30.051210 [debug] [Thread-1  ]: Compiling model.jira.jira__daily_issue_field_history
[0m09:39:30.073993 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:39:30.364459 [debug] [Thread-1  ]: Writing injected SQL for node "model.jira.jira__daily_issue_field_history"
[0m09:39:30.365872 [debug] [Thread-1  ]: finished collecting timing info
[0m09:39:30.366075 [debug] [Thread-1  ]: Began executing node model.jira.jira__daily_issue_field_history
[0m09:39:30.480443 [debug] [Thread-1  ]: Writing runtime sql for node "model.jira.jira__daily_issue_field_history"
[0m09:39:30.481491 [debug] [Thread-1  ]: On model.jira.jira__daily_issue_field_history: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.jira__daily_issue_field_history"} */

        
            
            
        
    

    

    merge into `ra-development`.`lewis_analytics_dev_jira`.`jira__daily_issue_field_history` as DBT_INTERNAL_DEST
        using (
          

-- grab column names that were pivoted out-- in intermediate/field_history/
with pivoted_daily_history as (

    select * 
    from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__field_history_scd`

    
    
    where valid_starting_on >= (select max(date_day) from `ra-development`.`lewis_analytics_dev_jira`.`jira__daily_issue_field_history` )

-- If no issue fields have been updated since the last incremental run, the pivoted_daily_history CTE will return no record/rows.
-- When this is the case, we need to grab the most recent day's records from the previously built table so that we can persist 
-- those values into the future.

), most_recent_data as ( 
 
    select 
        *
    from `ra-development`.`lewis_analytics_dev_jira`.`jira__daily_issue_field_history`
    where date_day = (select max(date_day) from `ra-development`.`lewis_analytics_dev_jira`.`jira__daily_issue_field_history` )



), field_option as (
    
    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__field_option`
),

statuses as (
    
    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__status`
),

-- in intermediate/field_history/
calendar as (

    select *
    from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__issue_calendar_spine`

    
    where date_day >= (select max(date_day) from `ra-development`.`lewis_analytics_dev_jira`.`jira__daily_issue_field_history` )
    
),

joined as (

    select
        calendar.date_day,
        calendar.issue_id

        
         
        , coalesce(pivoted_daily_history.status, most_recent_data.status) as status
         
        , coalesce(pivoted_daily_history.sprint, most_recent_data.sprint) as sprint
        
    
    
    
    from calendar
    left join pivoted_daily_history 
        on calendar.issue_id = pivoted_daily_history.issue_id
        and calendar.date_day = pivoted_daily_history.valid_starting_on
    
    
    left join most_recent_data
        on calendar.issue_id = most_recent_data.issue_id
        and calendar.date_day = most_recent_data.date_day
    
),

set_values as (

    select
        date_day,
        issue_id,
        statuses.status_name as status,
        sum( case when statuses.status_name is null then 0 else 1 end) over ( partition by issue_id
            order by date_day rows unbounded preceding) as status_field_partition

        
        , coalesce(field_option_sprint.field_option_name, sprint) as sprint
        -- create a batch/partition once a new value is provided
        , sum( case when sprint is null then 0 else 1 end) over ( partition by issue_id
            order by date_day rows unbounded preceding) as sprint_field_partition

        

    from joined

    left join statuses
        on cast(statuses.status_id as STRING) = joined.status

    
    left join field_option as field_option_sprint
        on cast(field_option_sprint.field_id as STRING) = sprint
    
),

fill_values as (

    select  
        date_day,
        issue_id,
        first_value( status ) over (
            partition by issue_id, status_field_partition 
            order by date_day asc rows between unbounded preceding and current row) as status

        
        -- grab the value that started this batch/partition
        , first_value( sprint ) over (
            partition by issue_id, sprint_field_partition 
            order by date_day asc rows between unbounded preceding and current row) as sprint
        

    from set_values
),

fix_null_values as (

    select  
        date_day,
        issue_id,
        case when status = 'is_null' then null else status end as status
         

        -- we de-nulled the true null values earlier in order to differentiate them from nulls that just needed to be backfilled
        , case when sprint = 'is_null' then null else sprint end as sprint
        

    from fill_values

),

surrogate_key as (

    select
        *,
        
    
to_hex(md5(cast(coalesce(cast(date_day as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(issue_id as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as issue_day_id

    from fix_null_values
)

select *
from surrogate_key
        ) as DBT_INTERNAL_SOURCE
        on 
                DBT_INTERNAL_SOURCE.issue_day_id = DBT_INTERNAL_DEST.issue_day_id
            

    
    when matched then update set
        `date_day` = DBT_INTERNAL_SOURCE.`date_day`,`issue_id` = DBT_INTERNAL_SOURCE.`issue_id`,`status` = DBT_INTERNAL_SOURCE.`status`,`sprint` = DBT_INTERNAL_SOURCE.`sprint`,`issue_day_id` = DBT_INTERNAL_SOURCE.`issue_day_id`
    

    when not matched then insert
        (`date_day`, `issue_id`, `status`, `sprint`, `issue_day_id`)
    values
        (`date_day`, `issue_id`, `status`, `sprint`, `issue_day_id`)


    
[0m09:39:35.645056 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:787453e4-abb7-4999-826c-5561432a2d48:europe-west2&page=queryresults
[0m09:39:35.957731 [debug] [Thread-1  ]: finished collecting timing info
[0m09:39:35.959698 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1273f6280>]}
[0m09:39:35.960635 [info ] [Thread-1  ]: 96 of 110 OK created sql incremental model lewis_analytics_dev_jira.jira__daily_issue_field_history  [[32mMERGE (3.1k rows, 74.2 MB processed)[0m in 5.91s]
[0m09:39:35.961486 [debug] [Thread-1  ]: Finished running node model.jira.jira__daily_issue_field_history
[0m09:39:35.962626 [debug] [Thread-6  ]: Began running node model.jira.jira__issue_enhanced
[0m09:39:35.962915 [debug] [Thread-4  ]: Began running node model.wire_jira.int_jira__daily_issue_field_history
[0m09:39:35.963232 [info ] [Thread-6  ]: 97 of 110 START sql table model lewis_analytics_dev_jira.jira__issue_enhanced .. [RUN]
[0m09:39:35.963563 [info ] [Thread-4  ]: 98 of 110 START sql view model lewis_analytics_dev_integration.int_jira__daily_issue_field_history  [RUN]
[0m09:39:35.964534 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira.jira__issue_enhanced"
[0m09:39:35.965096 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.wire_jira.int_jira__daily_issue_field_history"
[0m09:39:35.965290 [debug] [Thread-6  ]: Began compiling node model.jira.jira__issue_enhanced
[0m09:39:35.965417 [debug] [Thread-4  ]: Began compiling node model.wire_jira.int_jira__daily_issue_field_history
[0m09:39:35.965548 [debug] [Thread-6  ]: Compiling model.jira.jira__issue_enhanced
[0m09:39:35.965661 [debug] [Thread-4  ]: Compiling model.wire_jira.int_jira__daily_issue_field_history
[0m09:39:35.976612 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:39:35.980260 [debug] [Thread-4  ]: Writing injected SQL for node "model.wire_jira.int_jira__daily_issue_field_history"
[0m09:39:35.981839 [debug] [Thread-4  ]: finished collecting timing info
[0m09:39:35.982050 [debug] [Thread-4  ]: Began executing node model.wire_jira.int_jira__daily_issue_field_history
[0m09:39:35.985881 [debug] [Thread-4  ]: Writing runtime sql for node "model.wire_jira.int_jira__daily_issue_field_history"
[0m09:39:35.986370 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:39:36.074968 [debug] [Thread-4  ]: On model.wire_jira.int_jira__daily_issue_field_history: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira__daily_issue_field_history"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira__daily_issue_field_history`
  OPTIONS(
      description=""""""
    )
  as with jira__daily_issue_field_history as (

    select * from `ra-development`.`lewis_analytics_dev_jira`.`jira__daily_issue_field_history`

),

final as (

    select 

        issue_id as jira_issue_natural_key,
        issue_day_id as jira_daily_issue_field_history_natural_key,
        
        status as jira_daily_issue_field_history_status,
        sprint as jira_daily_issue_field_history_sprint,
        
        date_day as jira_daily_issue_field_history_date_day,
        
    from jira__daily_issue_field_history

)

select * from final;


[0m09:39:36.368316 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira.jira__issue_enhanced"
[0m09:39:36.369166 [debug] [Thread-6  ]: finished collecting timing info
[0m09:39:36.369673 [debug] [Thread-6  ]: Began executing node model.jira.jira__issue_enhanced
[0m09:39:36.453781 [debug] [Thread-6  ]: Writing runtime sql for node "model.jira.jira__issue_enhanced"
[0m09:39:36.454291 [debug] [Thread-6  ]: On model.jira.jira__issue_enhanced: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.jira__issue_enhanced"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira`.`jira__issue_enhanced`
    
    
    OPTIONS(
      description="""The core issue table, enhanced with current-status attributes from foreign-key-related tables, and metrics regarding resolutions and assignments.\n"""
    )
    as (
      with issue as (

    select *
    from `ra-development`.`lewis_analytics_dev_int_jira`.`int_jira__issue_join`
),daily_issue_field_history as (
    
    select
        *,
        row_number() over (partition by issue_id order by date_day desc) = 1 as latest_record
    from `ra-development`.`lewis_analytics_dev_jira`.`jira__daily_issue_field_history`

),

latest_issue_field_history as (
    
    select
        *
    from daily_issue_field_history
    where latest_record
),

final as (

    select 
    
        issue.*,

        

    datetime_diff(
        cast(coalesce(resolved_at, current_timestamp) as datetime),
        cast(created_at as datetime),
        second
    )

   open_duration_seconds,

        -- this will be null if no one has been assigned
        

    datetime_diff(
        cast(coalesce(resolved_at, current_timestamp) as datetime),
        cast(first_assigned_at as datetime),
        second
    )

   any_assignment_duration_seconds,

        -- if an issue is not currently assigned this will not be null
        

    datetime_diff(
        cast(coalesce(resolved_at, current_timestamp) as datetime),
        cast(last_assigned_at as datetime),
        second
    )

   last_assignment_duration_seconds 

        , status, sprint

    from issue
    
    left join latest_issue_field_history 
        on issue.issue_id = latest_issue_field_history.issue_id
        
)

select *
from final
    );
  
[0m09:39:36.741858 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:129b67ee-d8f1-48e2-9e3b-bedbcc11373b:europe-west2&page=queryresults
[0m09:39:37.018853 [debug] [Thread-4  ]: finished collecting timing info
[0m09:39:37.019944 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1271404f0>]}
[0m09:39:37.020617 [info ] [Thread-4  ]: 98 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira__daily_issue_field_history  [[32mCREATE VIEW (0 processed)[0m in 1.06s]
[0m09:39:37.021279 [debug] [Thread-4  ]: Finished running node model.wire_jira.int_jira__daily_issue_field_history
[0m09:39:37.021998 [debug] [Thread-8  ]: Began running node model.wire_jira.wh_delivery__jira_daily_issue_field_history_fact
[0m09:39:37.022504 [info ] [Thread-8  ]: 99 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_daily_issue_field_history_fact  [RUN]
[0m09:39:37.023909 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_daily_issue_field_history_fact"
[0m09:39:37.024201 [debug] [Thread-8  ]: Began compiling node model.wire_jira.wh_delivery__jira_daily_issue_field_history_fact
[0m09:39:37.024330 [debug] [Thread-8  ]: Compiling model.wire_jira.wh_delivery__jira_daily_issue_field_history_fact
[0m09:39:37.031277 [debug] [Thread-8  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_daily_issue_field_history_fact"
[0m09:39:37.032653 [debug] [Thread-8  ]: finished collecting timing info
[0m09:39:37.032797 [debug] [Thread-8  ]: Began executing node model.wire_jira.wh_delivery__jira_daily_issue_field_history_fact
[0m09:39:37.035405 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:39:37.304940 [debug] [Thread-8  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_daily_issue_field_history_fact"
[0m09:39:37.306399 [debug] [Thread-8  ]: On model.wire_jira.wh_delivery__jira_daily_issue_field_history_fact: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_daily_issue_field_history_fact"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_daily_issue_field_history_fact`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_jira__daily_issue_field_history as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__daily_issue_field_history`

),

final as (

    select

        
    
to_hex(md5(cast(coalesce(cast(jira_daily_issue_field_history_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_daily_issue_field_history_pk,  
        
        
    
to_hex(md5(cast(coalesce(cast(jira_issue_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_issue_fk,       

        jira_daily_issue_field_history_status,
        jira_daily_issue_field_history_sprint,
        jira_daily_issue_field_history_date_day

    from int_jira__daily_issue_field_history

)

select * from final
    );
  
[0m09:39:39.701485 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:64091465-39f4-4ed8-b604-ee47437a1555:europe-west2&page=queryresults
[0m09:39:39.982300 [debug] [Thread-6  ]: finished collecting timing info
[0m09:39:39.983810 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127140eb0>]}
[0m09:39:39.984463 [info ] [Thread-6  ]: 97 of 110 OK created sql table model lewis_analytics_dev_jira.jira__issue_enhanced  [[32mCREATE TABLE (4.8k rows, 32.7 MB processed)[0m in 4.02s]
[0m09:39:39.985617 [debug] [Thread-6  ]: Finished running node model.jira.jira__issue_enhanced
[0m09:39:39.986638 [debug] [Thread-2  ]: Began running node model.jira.int_jira__project_metrics
[0m09:39:39.986976 [debug] [Thread-5  ]: Began running node model.jira.int_jira__user_metrics
[0m09:39:39.987650 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.jira.int_jira__project_metrics"
[0m09:39:39.987843 [debug] [Thread-1  ]: Began running node model.wire_jira.int_jira__issues
[0m09:39:39.988364 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.jira.int_jira__user_metrics"
[0m09:39:39.988512 [debug] [Thread-2  ]: Began compiling node model.jira.int_jira__project_metrics
[0m09:39:39.988727 [info ] [Thread-1  ]: 100 of 110 START sql view model lewis_analytics_dev_integration.int_jira__issues  [RUN]
[0m09:39:39.988863 [debug] [Thread-5  ]: Began compiling node model.jira.int_jira__user_metrics
[0m09:39:39.988989 [debug] [Thread-2  ]: Compiling model.jira.int_jira__project_metrics
[0m09:39:39.989480 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.wire_jira.int_jira__issues"
[0m09:39:39.989589 [debug] [Thread-5  ]: Compiling model.jira.int_jira__user_metrics
[0m09:39:40.002337 [debug] [Thread-1  ]: Began compiling node model.wire_jira.int_jira__issues
[0m09:39:40.005369 [debug] [Thread-2  ]: Writing injected SQL for node "model.jira.int_jira__project_metrics"
[0m09:39:40.014443 [debug] [Thread-5  ]: Writing injected SQL for node "model.jira.int_jira__user_metrics"
[0m09:39:40.014573 [debug] [Thread-1  ]: Compiling model.wire_jira.int_jira__issues
[0m09:39:40.020871 [debug] [Thread-1  ]: Writing injected SQL for node "model.wire_jira.int_jira__issues"
[0m09:39:40.021328 [debug] [Thread-5  ]: finished collecting timing info
[0m09:39:40.022002 [debug] [Thread-5  ]: Finished running node model.jira.int_jira__user_metrics
[0m09:39:40.022175 [debug] [Thread-2  ]: finished collecting timing info
[0m09:39:40.022559 [debug] [Thread-4  ]: Began running node model.jira.jira__user_enhanced
[0m09:39:40.023123 [debug] [Thread-2  ]: Finished running node model.jira.int_jira__project_metrics
[0m09:39:40.023234 [debug] [Thread-1  ]: finished collecting timing info
[0m09:39:40.023458 [info ] [Thread-4  ]: 101 of 110 START sql table model lewis_analytics_dev_jira.jira__user_enhanced .. [RUN]
[0m09:39:40.023705 [debug] [Thread-1  ]: Began executing node model.wire_jira.int_jira__issues
[0m09:39:40.023875 [debug] [Thread-6  ]: Began running node model.jira.jira__project_enhanced
[0m09:39:40.024513 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.jira.jira__user_enhanced"
[0m09:39:40.029106 [debug] [Thread-1  ]: Writing runtime sql for node "model.wire_jira.int_jira__issues"
[0m09:39:40.029446 [info ] [Thread-6  ]: 102 of 110 START sql table model lewis_analytics_dev_jira.jira__project_enhanced  [RUN]
[0m09:39:40.029619 [debug] [Thread-4  ]: Began compiling node model.jira.jira__user_enhanced
[0m09:39:40.030234 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.jira.jira__project_enhanced"
[0m09:39:40.030350 [debug] [Thread-4  ]: Compiling model.jira.jira__user_enhanced
[0m09:39:40.030528 [debug] [Thread-6  ]: Began compiling node model.jira.jira__project_enhanced
[0m09:39:40.036811 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:39:40.048514 [debug] [Thread-4  ]: Writing injected SQL for node "model.jira.jira__user_enhanced"
[0m09:39:40.048664 [debug] [Thread-6  ]: Compiling model.jira.jira__project_enhanced
[0m09:39:40.070043 [debug] [Thread-6  ]: Writing injected SQL for node "model.jira.jira__project_enhanced"
[0m09:39:40.070400 [debug] [Thread-4  ]: finished collecting timing info
[0m09:39:40.070549 [debug] [Thread-4  ]: Began executing node model.jira.jira__user_enhanced
[0m09:39:40.072504 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:39:40.072700 [debug] [Thread-6  ]: finished collecting timing info
[0m09:39:40.072825 [debug] [Thread-6  ]: Began executing node model.jira.jira__project_enhanced
[0m09:39:40.074512 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:39:40.133082 [debug] [Thread-1  ]: On model.wire_jira.int_jira__issues: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira__issues"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira__issues`
  OPTIONS(
      description=""""""
    )
  as with stg_jira__issues as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__issues`

),

stg_jira__status as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__statuses`

),

int_jira__issues_field_history as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__issues_field_history`

),

fivetran_jira__issue_enhanced as (

    select * from `ra-development`.`lewis_analytics_dev_jira`.`jira__issue_enhanced`

),

int_jira__boards as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__boards`

),

int_jira__sprints as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__sprints`

),

stg_jira__issue_board as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__issue_board`

),

most_recent_jira__issues_field as (

    select distinct

        jira_issue_natural_key,
        jira_issue_field_history_story_point_estimate
    
    from int_jira__issues_field_history

    where jira_issue_field_history_is_active = true

),

joined as (

    select 
    
        stg_jira__issues.jira_issue_natural_key,
        stg_jira__issues.jira_issue_parent_natural_key,

        stg_jira__issue_board.jira_board_natural_key,
        int_jira__sprints.jira_sprint_natural_key,

        fivetran_jira__issue_enhanced.creator_user_id as jira_creator_natural_key,
        fivetran_jira__issue_enhanced.reporter_user_id as jira_reporter_natural_key,
        fivetran_jira__issue_enhanced.resolution_id as jira_resolution_natural_key,
        fivetran_jira__issue_enhanced.current_sprint_id as jira_current_sprint_natural_key,

        stg_jira__issues.jira_issue_summary,
        stg_jira__issues.jira_issue_description,
        stg_jira__issues.jira_issue_project,
        stg_jira__issues.jira_issue_assignee,
        stg_jira__issues.jira_issue_reporter,
        stg_jira__issues.jira_issue_priority,
        stg_jira__issues.jira_issue_creator,
        stg_jira__issues.jira_issue_issue_type,
        stg_jira__issues.jira_issue_key,

        fivetran_jira__issue_enhanced.issue_type as jira_issue_type,
        fivetran_jira__issue_enhanced.parent_issue_type as jira_issue_parent_issue_type,
        fivetran_jira__issue_enhanced.parent_issue_name as jira_issue_parent_issue_name,
        fivetran_jira__issue_enhanced.is_parent_epic as jira_issue_is_parent_epic,
        fivetran_jira__issue_enhanced.resolution_type as jira_issue_resolution_type,
        fivetran_jira__issue_enhanced.work_ratio as jira_issue_work_ratio,
        fivetran_jira__issue_enhanced.status as jira_issue_status,
        fivetran_jira__issue_enhanced.conversation as jira_issue_conversation,
        fivetran_jira__issue_enhanced.current_status as jira_issue_current_status,
        fivetran_jira__issue_enhanced.current_status_category as jira_issue_current_status_category,
        fivetran_jira__issue_enhanced.current_priority as jira_issue_current_priority,
        fivetran_jira__issue_enhanced.sprint as jira_issue_sprint,
        fivetran_jira__issue_enhanced.current_sprint_name as jira_issue_current_sprint_name,
        fivetran_jira__issue_enhanced.is_active_sprint as jira_issue_is_active_sprint,
        fivetran_jira__issue_enhanced.fixes_versions as jira_issue_fixes_versions,
        fivetran_jira__issue_enhanced.sprint_started_at as jira_issue_sprint_started_at,
        fivetran_jira__issue_enhanced.sprint_ended_at as jira_issue_sprint_ended_at,
        fivetran_jira__issue_enhanced.sprint_completed_at as jira_issue_sprint_completed_at,
        fivetran_jira__issue_enhanced.first_assigned_at as jira_issue_first_assigned_at,
        fivetran_jira__issue_enhanced.last_assigned_at as jira_issue_last_assigned_at,
        fivetran_jira__issue_enhanced.first_resolved_at as jira_issue_first_resolved_at,
        fivetran_jira__issue_enhanced.count_sprint_changes as jira_issue_count_sprint_changes,
        fivetran_jira__issue_enhanced.time_spent_seconds as jira_issue_time_spent_seconds,
        fivetran_jira__issue_enhanced.count_comments as jira_issue_count_comments,
        fivetran_jira__issue_enhanced.open_duration_seconds as jira_issue_open_duration_seconds,
        fivetran_jira__issue_enhanced.any_assignment_duration_seconds as jira_issue_any_assignment_duration_seconds,
        fivetran_jira__issue_enhanced.last_assignment_duration_seconds as jira_issue_last_assignment_duration_seconds,

        stg_jira__status.jira_status_description as jira_issue_status_description,
        stg_jira__status.jira_status_name as jira_issue_status_name,
        fivetran_jira__issue_enhanced.status_changed_at as jira_issue_status_changed_at,

        first_value (most_recent_jira__issues_field.jira_issue_field_history_story_point_estimate ignore nulls) 
            over(partition by stg_jira__issues.jira_issue_natural_key order by stg_jira__issues.jira_issue_updated_at_ts 
            rows between unbounded preceding and unbounded following
        ) as jira_issue_story_point_estimate,

        stg_jira__issues.jira_issue_original_estimate,
        stg_jira__issues.jira_issue_remaining_estimate,

        stg_jira__issues.jira_issue_status_category_changed_at_ts,
        stg_jira__issues.jira_issue_resolved_at_ts,
        stg_jira__issues.jira_issue_last_viewed_at_ts,
        stg_jira__issues.jira_issue_due_date_at_ts,
        stg_jira__issues.jira_issue_created_at_ts,
        stg_jira__issues.jira_issue_updated_at_ts
    
    from stg_jira__issues

    left join stg_jira__status 
    on stg_jira__issues.jira_status_natural_key = stg_jira__status.jira_status_natural_key

    left join most_recent_jira__issues_field 
    on stg_jira__issues.jira_issue_natural_key = most_recent_jira__issues_field.jira_issue_natural_key

    left join fivetran_jira__issue_enhanced 
    on stg_jira__issues.jira_issue_natural_key = fivetran_jira__issue_enhanced.issue_id

    left join stg_jira__issue_board
    on stg_jira__issue_board.jira_issue_natural_key = stg_jira__issues.jira_issue_natural_key

    left join int_jira__boards
    on int_jira__boards.jira_board_natural_key = stg_jira__issue_board.jira_board_natural_key

    left join int_jira__sprints
    on int_jira__boards.jira_board_natural_key = int_jira__sprints.jira_board_natural_key

)

select * from joined;


[0m09:39:40.325627 [debug] [Thread-4  ]: Writing runtime sql for node "model.jira.jira__user_enhanced"
[0m09:39:40.326801 [debug] [Thread-6  ]: Writing runtime sql for node "model.jira.jira__project_enhanced"
[0m09:39:40.327302 [debug] [Thread-4  ]: On model.jira.jira__user_enhanced: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.jira__user_enhanced"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira`.`jira__user_enhanced`
    
    
    OPTIONS(
      description="""Table of users enriched with their projects, and the volume and velocity of their issues.\n"""
    )
    as (
      with  __dbt__cte__int_jira__user_metrics as (
with issue as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira`.`jira__issue_enhanced` 
    where assignee_user_id is not null
),

calculate_medians as (

    select 
        assignee_user_id as user_id,
        round( cast( 

    percentile_cont( 
        case when resolved_at is not null then last_assignment_duration_seconds end, 
        0.5) 
        over (partition by assignee_user_id    
        )

 as numeric), 0) as median_close_time_seconds,
        round( cast( 

    percentile_cont( 
        case when resolved_at is null then last_assignment_duration_seconds end, 
        0.5) 
        over (partition by assignee_user_id    
        )

 as numeric), 0) as median_age_currently_open_seconds

    from issue

    
),

-- grouping because the medians were calculated using window functions (except postgres)
median_metrics as (

    select 
        user_id, 
        median_close_time_seconds, 
        median_age_currently_open_seconds

    from calculate_medians
    group by 1,2,3
),


user_issues as (

    select
        assignee_user_id as user_id,
        sum(case when resolved_at is not null then 1 else 0 end) as count_closed_issues,
        sum(case when resolved_at is null then 1 else 0 end) as count_open_issues,

        sum(case when resolved_at is not null then last_assignment_duration_seconds end) as sum_close_time_seconds,
        sum(case when resolved_at is null then last_assignment_duration_seconds end) as sum_current_open_seconds

    from issue

    group by 1

),

calculate_avg_metrics as (

    select 
        user_id,
        count_closed_issues,
        count_open_issues,

        case when count_closed_issues = 0 then 0 else
        round( cast(sum_close_time_seconds * 1.0 / count_closed_issues as numeric ), 0) end as avg_close_time_seconds,

        case when count_open_issues = 0 then 0 else
        round( cast(sum_current_open_seconds * 1.0 / count_open_issues as numeric ), 0) end as avg_age_currently_open_seconds

    from user_issues
),

join_metrics as (

    select
        calculate_avg_metrics.*,
        round( cast(calculate_avg_metrics.avg_close_time_seconds / 86400.0 as numeric ), 0) as avg_close_time_days,
        round( cast(calculate_avg_metrics.avg_age_currently_open_seconds / 86400.0 as numeric ), 0) as avg_age_currently_open_days,

        median_metrics.median_close_time_seconds,
        median_metrics.median_age_currently_open_seconds,

        round( cast(median_metrics.median_close_time_seconds / 86400.0 as numeric ), 0) as median_close_time_days,
        round( cast(median_metrics.median_age_currently_open_seconds / 86400.0 as numeric ), 0) as median_age_currently_open_days
        
    from calculate_avg_metrics
    left join median_metrics using(user_id)
)

select * from join_metrics
),jira_user as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__user`
),

user_metrics as (

    select *
    from __dbt__cte__int_jira__user_metrics
),

issue as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira`.`jira__issue_enhanced` 
),

user_project as (

    select 
        assignee_user_id,
        project_name

    from issue
    group by 1,2

),

agg_user_projects as (

    select 
        assignee_user_id,
        
    string_agg(project_name, ', ')

 as projects

    from user_project
    group by 1
),

user_join as (

    select
        jira_user.*,
        agg_user_projects.projects, -- projects they've worked on issues for
        coalesce(user_metrics.count_closed_issues, 0) as count_closed_issues,
        coalesce(user_metrics.count_open_issues, 0) as count_open_issues,

        -- days
        user_metrics.avg_close_time_days,
        user_metrics.avg_age_currently_open_days,
        
        user_metrics.median_close_time_days,
        user_metrics.median_age_currently_open_days,

        -- seconds
        user_metrics.avg_close_time_seconds,
        user_metrics.avg_age_currently_open_seconds,
        
        user_metrics.median_close_time_seconds,
        user_metrics.median_age_currently_open_seconds

    from jira_user 
    left join user_metrics on jira_user.user_id = user_metrics.user_id
    left join agg_user_projects on jira_user.user_id = agg_user_projects.assignee_user_id
)

select * from user_join
    );
  
[0m09:39:40.327582 [debug] [Thread-6  ]: On model.jira.jira__project_enhanced: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.jira.jira__project_enhanced"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev_jira`.`jira__project_enhanced`
    
    
    OPTIONS(
      description="""Table of projects enriched with data about its lead, epics, components, and volume and velocity of worktime.\n"""
    )
    as (
      with  __dbt__cte__int_jira__project_metrics as (
with issue as (

    select * 
    from `ra-development`.`lewis_analytics_dev_jira`.`jira__issue_enhanced`
    where project_id is not null
),

calculate_medians as (

    select 
        project_id,
        round( cast( 

    percentile_cont( 
        case when resolved_at is not null then open_duration_seconds end, 
        0.5) 
        over (partition by project_id    
        )

 as numeric ), 0) as median_close_time_seconds,
        round( cast(

    percentile_cont( 
        case when resolved_at is null then open_duration_seconds end, 
        0.5) 
        over (partition by project_id    
        )

 as numeric ), 0) as median_age_currently_open_seconds,

        round( cast(

    percentile_cont( 
        case when resolved_at is not null then any_assignment_duration_seconds end, 
        0.5) 
        over (partition by project_id    
        )

 as numeric ), 0) as median_assigned_close_time_seconds,
        round( cast(

    percentile_cont( 
        case when resolved_at is null then any_assignment_duration_seconds end, 
        0.5) 
        over (partition by project_id    
        )

 as numeric ), 0) as median_age_currently_open_assigned_seconds

    from issue

    
),

-- grouping because the medians were calculated using window functions (except in postgres)
median_metrics as (

    select 
        project_id, 
        median_close_time_seconds, 
        median_age_currently_open_seconds,
        median_assigned_close_time_seconds,
        median_age_currently_open_assigned_seconds

    from calculate_medians
    group by 1,2,3,4,5
),


-- get appropriate counts + sums to calculate averages
project_issues as (
    select
        project_id,
        sum(case when resolved_at is not null then 1 else 0 end) as count_closed_issues,
        sum(case when resolved_at is null then 1 else 0 end) as count_open_issues,

        -- using the below to calculate averages

        -- assigned issues
        sum(case when resolved_at is null and assignee_user_id is not null then 1 else 0 end) as count_open_assigned_issues,
        sum(case when resolved_at is not null and assignee_user_id is not null then 1 else 0 end) as count_closed_assigned_issues,

        -- close time 
        sum(case when resolved_at is not null then open_duration_seconds else 0 end) as sum_close_time_seconds,
        sum(case when resolved_at is not null then any_assignment_duration_seconds else 0 end) as sum_assigned_close_time_seconds,

        -- age of currently open tasks
        sum(case when resolved_at is null then open_duration_seconds else 0 end) as sum_currently_open_duration_seconds,
        sum(case when resolved_at is null then any_assignment_duration_seconds else 0 end) as sum_currently_open_assigned_duration_seconds

    from issue

    group by 1
),

calculate_avg_metrics as (

    select
        project_id,
        count_closed_issues,
        count_open_issues,
        count_open_assigned_issues,

        case when count_closed_issues = 0 then 0 else
        round( cast(sum_close_time_seconds * 1.0 / count_closed_issues  as numeric ), 0) end as avg_close_time_seconds,

        case when count_closed_assigned_issues = 0 then 0 else
        round( cast(sum_assigned_close_time_seconds * 1.0 / count_closed_assigned_issues  as numeric ), 0) end as avg_assigned_close_time_seconds,

        case when count_open_issues = 0 then 0 else
        round( cast(sum_currently_open_duration_seconds * 1.0 / count_open_issues as numeric ), 0) end as avg_age_currently_open_seconds,

        case when count_open_assigned_issues = 0 then 0 else
        round( cast(sum_currently_open_assigned_duration_seconds * 1.0 / count_open_assigned_issues as numeric ), 0) end as avg_age_currently_open_assigned_seconds

    from project_issues
),

-- join medians and averages + convert to days
join_metrics as (

    select
        calculate_avg_metrics.*,

        -- there are 86400 seconds in a day
        round( cast(calculate_avg_metrics.avg_close_time_seconds / 86400.0 as numeric ), 0) as avg_close_time_days,
        round( cast(calculate_avg_metrics.avg_assigned_close_time_seconds / 86400.0 as numeric ), 0) as avg_assigned_close_time_days,
        round( cast(calculate_avg_metrics.avg_age_currently_open_seconds / 86400.0 as numeric ), 0) as avg_age_currently_open_days,
        round( cast(calculate_avg_metrics.avg_age_currently_open_assigned_seconds / 86400.0 as numeric ), 0) as avg_age_currently_open_assigned_days,

        median_metrics.median_close_time_seconds, 
        median_metrics.median_age_currently_open_seconds,
        median_metrics.median_assigned_close_time_seconds,
        median_metrics.median_age_currently_open_assigned_seconds,

        round( cast(median_metrics.median_close_time_seconds / 86400.0 as numeric ), 0) as median_close_time_days,
        round( cast(median_metrics.median_age_currently_open_seconds / 86400.0 as numeric ), 0) as median_age_currently_open_days,
        round( cast(median_metrics.median_assigned_close_time_seconds / 86400.0 as numeric ), 0) as median_assigned_close_time_days,
        round( cast(median_metrics.median_age_currently_open_assigned_seconds / 86400.0 as numeric ), 0) as median_age_currently_open_assigned_days
        
    from calculate_avg_metrics
    left join median_metrics using(project_id)
)

select * from join_metrics
),project as (

    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__project`
),

project_metrics as (

    select * 
    from __dbt__cte__int_jira__project_metrics
),

-- user is reserved in AWS
jira_user as (
-- to grab the project lead
    select *
    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__user`
),

agg_epics as (

    select 
        project_id,
        
    string_agg(issue_name, ', ')

 as epics

    from `ra-development`.`lewis_analytics_dev_jira`.`jira__issue_enhanced`
    where lower(issue_type) = 'epic'
    -- should we limit to active epics?
    group by 1

),



agg_components as (
    -- i'm just aggregating the components here, but perhaps pivoting out components (and epics) 
    -- into columns where the values are the number of issues completed and/or open would be more valuable
    select 
        project_id,
        
    string_agg(component_name, ', ')

 as components

    from `ra-development`.`lewis_analytics_dev_jira_source`.`stg_jira__component`

    group by 1
),



project_join as (

    select
        project.*,
        jira_user.user_display_name as project_lead_user_name,
        jira_user.email as project_lead_email,
        agg_epics.epics,
        
        
        agg_components.components,
        

        coalesce(project_metrics.count_closed_issues, 0) as count_closed_issues,
        coalesce(project_metrics.count_open_issues, 0) as count_open_issues,
        coalesce(project_metrics.count_open_assigned_issues, 0) as count_open_assigned_issues,

        -- days
        project_metrics.avg_close_time_days,
        project_metrics.avg_assigned_close_time_days,

        project_metrics.avg_age_currently_open_days,
        project_metrics.avg_age_currently_open_assigned_days,

        project_metrics.median_close_time_days, 
        project_metrics.median_age_currently_open_days,
        project_metrics.median_assigned_close_time_days,
        project_metrics.median_age_currently_open_assigned_days,

        -- seconds
        project_metrics.avg_close_time_seconds,
        project_metrics.avg_assigned_close_time_seconds,

        project_metrics.avg_age_currently_open_seconds,
        project_metrics.avg_age_currently_open_assigned_seconds,

        project_metrics.median_close_time_seconds, 
        project_metrics.median_age_currently_open_seconds,
        project_metrics.median_assigned_close_time_seconds,
        project_metrics.median_age_currently_open_assigned_seconds

    from project
    left join project_metrics on project.project_id = project_metrics.project_id
    left join jira_user on project.project_lead_user_id = jira_user.user_id
    left join agg_epics on project.project_id = agg_epics.project_id 
    
    
    left join agg_components on project.project_id = agg_components.project_id 
    

)

select * from project_join
    );
  
[0m09:39:40.985836 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:0940794b-7260-4e2b-b403-06722a3c5670:europe-west2&page=queryresults
[0m09:39:41.274434 [debug] [Thread-1  ]: finished collecting timing info
[0m09:39:41.275659 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12708a430>]}
[0m09:39:41.276562 [info ] [Thread-1  ]: 100 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira__issues  [[32mCREATE VIEW (0 processed)[0m in 1.29s]
[0m09:39:41.277752 [debug] [Thread-1  ]: Finished running node model.wire_jira.int_jira__issues
[0m09:39:41.278540 [debug] [Thread-5  ]: Began running node model.wire_jira.wh_delivery__jira_issues_board_bridge
[0m09:39:41.278851 [debug] [Thread-7  ]: Began running node model.wire_jira.wh_delivery__jira_issues_fact
[0m09:39:41.279110 [debug] [Thread-2  ]: Began running node model.wire_jira.wh_delivery__jira_issues_sprint_bridge
[0m09:39:41.279525 [info ] [Thread-5  ]: 103 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_issues_board_bridge  [RUN]
[0m09:39:41.279866 [info ] [Thread-7  ]: 104 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_issues_fact  [RUN]
[0m09:39:41.280070 [info ] [Thread-2  ]: 105 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_issues_sprint_bridge  [RUN]
[0m09:39:41.280689 [debug] [Thread-5  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_issues_board_bridge"
[0m09:39:41.281186 [debug] [Thread-7  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_issues_fact"
[0m09:39:41.281653 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_issues_sprint_bridge"
[0m09:39:41.281792 [debug] [Thread-5  ]: Began compiling node model.wire_jira.wh_delivery__jira_issues_board_bridge
[0m09:39:41.281909 [debug] [Thread-7  ]: Began compiling node model.wire_jira.wh_delivery__jira_issues_fact
[0m09:39:41.282020 [debug] [Thread-2  ]: Began compiling node model.wire_jira.wh_delivery__jira_issues_sprint_bridge
[0m09:39:41.282141 [debug] [Thread-5  ]: Compiling model.wire_jira.wh_delivery__jira_issues_board_bridge
[0m09:39:41.282249 [debug] [Thread-7  ]: Compiling model.wire_jira.wh_delivery__jira_issues_fact
[0m09:39:41.282392 [debug] [Thread-2  ]: Compiling model.wire_jira.wh_delivery__jira_issues_sprint_bridge
[0m09:39:41.292439 [debug] [Thread-5  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_issues_board_bridge"
[0m09:39:41.324159 [debug] [Thread-7  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_issues_fact"
[0m09:39:41.315644 [debug] [Thread-2  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_issues_sprint_bridge"
[0m09:39:41.324928 [debug] [Thread-5  ]: finished collecting timing info
[0m09:39:41.325419 [debug] [Thread-5  ]: Began executing node model.wire_jira.wh_delivery__jira_issues_board_bridge
[0m09:39:41.329788 [debug] [Thread-5  ]: Opening a new connection, currently in state closed
[0m09:39:41.330175 [debug] [Thread-7  ]: finished collecting timing info
[0m09:39:41.330336 [debug] [Thread-7  ]: Began executing node model.wire_jira.wh_delivery__jira_issues_fact
[0m09:39:41.333027 [debug] [Thread-7  ]: Opening a new connection, currently in state closed
[0m09:39:41.333192 [debug] [Thread-2  ]: finished collecting timing info
[0m09:39:41.333385 [debug] [Thread-2  ]: Began executing node model.wire_jira.wh_delivery__jira_issues_sprint_bridge
[0m09:39:41.335473 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m09:39:41.589324 [debug] [Thread-2  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_issues_sprint_bridge"
[0m09:39:41.589951 [debug] [Thread-2  ]: On model.wire_jira.wh_delivery__jira_issues_sprint_bridge: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_issues_sprint_bridge"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_issues_sprint_bridge`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_jira__issues as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__issues`

),

final as (

    select distinct

        
    
to_hex(md5(cast(coalesce(cast(jira_issue_natural_key as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(jira_sprint_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_issue_sprint_bridge_pk,
        
        
    
to_hex(md5(cast(coalesce(cast(jira_issue_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_issue_fk,

        
    
to_hex(md5(cast(coalesce(cast(jira_sprint_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_sprint_fk

    from int_jira__issues

) 

select * from final
    );
  
[0m09:39:41.594237 [debug] [Thread-5  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_issues_board_bridge"
[0m09:39:41.595164 [debug] [Thread-5  ]: On model.wire_jira.wh_delivery__jira_issues_board_bridge: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_issues_board_bridge"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_issues_board_bridge`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_jira__issues as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__issues`

),

final as (

    select distinct

        
    
to_hex(md5(cast(coalesce(cast(jira_issue_natural_key as STRING), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(jira_board_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_issue_board_bridge_pk,
        
        
    
to_hex(md5(cast(coalesce(cast(jira_issue_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_issue_fk,

        
    
to_hex(md5(cast(coalesce(cast(jira_board_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_board_fk

    from int_jira__issues

) 

select * from final
    );
  
[0m09:39:41.608507 [debug] [Thread-7  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_issues_fact"
[0m09:39:41.609155 [debug] [Thread-7  ]: On model.wire_jira.wh_delivery__jira_issues_fact: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_issues_fact"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_issues_fact`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_jira__issues as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__issues`

),

final as (

    select distinct

        
    
to_hex(md5(cast(coalesce(cast(jira_issue_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_issue_pk,

        
    
to_hex(md5(cast(coalesce(cast(jira_issue_parent_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_issue_parent_fk,

        
    
to_hex(md5(cast(coalesce(cast(jira_issue_assignee as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_user_fk,

        
    
to_hex(md5(cast(coalesce(cast(jira_creator_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_creator_fk,

        
    
to_hex(md5(cast(coalesce(cast(jira_reporter_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_reporter_fk,

        
    
to_hex(md5(cast(coalesce(cast(jira_resolution_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_resolution_fk,        

        
    
to_hex(md5(cast(coalesce(cast(jira_current_sprint_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_current_sprint_fk, 

        
    
to_hex(md5(cast(coalesce(cast(jira_issue_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_external_reference_jira_fk, 

        jira_issue_natural_key,
        jira_issue_summary,
        jira_issue_description,
        jira_issue_project,
        jira_issue_assignee,
        jira_issue_reporter,
        jira_issue_priority,
        jira_issue_creator,
        jira_issue_issue_type,
        jira_issue_key,

        jira_issue_status_description,
        jira_issue_status_name,

        case 
            when jira_issue_status_name = 'to do'
                then  '1'
            when jira_issue_status_name = 'design in progress'
                then  '2'
            when jira_issue_status_name = 'in progress'
                then  '2'
            when jira_issue_status_name = 'warehouse in progress'
                then  '3'
            when jira_issue_status_name = 'in progress dbt'
                then  '3'                
            when jira_issue_status_name = 'warehouse qa'
                then  '4'
            when jira_issue_status_name = 'looker in progess'
                then  '5'
            when jira_issue_status_name = 'looker in progress'
                then  '5'
            when jira_issue_status_name = 'looker qa'
                then  '6'
            when jira_issue_status_name = 'internal qa'
                then  '6'
            when jira_issue_status_name = 'blocked'
                then  '7'
            when jira_issue_status_name = 'done'
                then  '8'

            else null

        end as jira_issue_status_stage,

        case 
            when jira_issue_status_name = 'done'
                then true
            else false
        end as jira_issue_is_done,

        jira_issue_type,
        jira_issue_parent_issue_type,
        jira_issue_parent_issue_name,
        jira_issue_is_parent_epic,
        jira_issue_resolution_type,
        jira_issue_work_ratio,
        jira_issue_status,
        jira_issue_conversation,
        jira_issue_current_status,
        jira_issue_current_status_category,
        jira_issue_current_priority,
        jira_issue_sprint,
        jira_issue_current_sprint_name,
        jira_issue_is_active_sprint,
        jira_issue_fixes_versions,

        jira_issue_count_sprint_changes,
        jira_issue_time_spent_seconds,
        jira_issue_count_comments,
        jira_issue_open_duration_seconds,
        jira_issue_any_assignment_duration_seconds,
        jira_issue_last_assignment_duration_seconds,

        jira_issue_story_point_estimate,
        jira_issue_original_estimate,
        jira_issue_remaining_estimate,

        jira_issue_sprint_started_at,
        jira_issue_sprint_ended_at,
        jira_issue_sprint_completed_at,
        jira_issue_first_assigned_at,
        jira_issue_last_assigned_at,
        jira_issue_first_resolved_at,

        jira_issue_status_category_changed_at_ts,
        jira_issue_resolved_at_ts,
        jira_issue_last_viewed_at_ts,
        jira_issue_due_date_at_ts,
        jira_issue_created_at_ts,
        jira_issue_updated_at_ts

    from int_jira__issues

)

select * from final
    );
  
[0m09:39:42.471674 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:181121c7-16f8-4498-8397-aee24e251286:europe-west2&page=queryresults
[0m09:39:42.703992 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:f014a746-00ad-458c-b1e0-1336c2f48ea8:europe-west2&page=queryresults
[0m09:39:42.744103 [debug] [Thread-8  ]: finished collecting timing info
[0m09:39:42.745665 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126e82af0>]}
[0m09:39:42.746379 [info ] [Thread-8  ]: 99 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_daily_issue_field_history_fact  [[32mCREATE TABLE (984.3k rows, 58.8 MB processed)[0m in 5.72s]
[0m09:39:42.747290 [debug] [Thread-8  ]: Finished running node model.wire_jira.wh_delivery__jira_daily_issue_field_history_fact
[0m09:39:42.991515 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:81666812-3d07-48ed-9d62-020015ab9e47:europe-west2&page=queryresults
[0m09:39:42.997694 [debug] [Thread-4  ]: finished collecting timing info
[0m09:39:42.998641 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127244ee0>]}
[0m09:39:42.999803 [info ] [Thread-4  ]: 101 of 110 OK created sql table model lewis_analytics_dev_jira.jira__user_enhanced  [[32mCREATE TABLE (109.0 rows, 210.9 KB processed)[0m in 2.97s]
[0m09:39:43.000256 [debug] [Thread-4  ]: Finished running node model.jira.jira__user_enhanced
[0m09:39:43.000736 [debug] [Thread-1  ]: Began running node model.wire_jira.int_jira__users
[0m09:39:43.001106 [info ] [Thread-1  ]: 106 of 110 START sql view model lewis_analytics_dev_integration.int_jira__users  [RUN]
[0m09:39:43.001605 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.wire_jira.int_jira__users"
[0m09:39:43.001720 [debug] [Thread-1  ]: Began compiling node model.wire_jira.int_jira__users
[0m09:39:43.001977 [debug] [Thread-1  ]: Compiling model.wire_jira.int_jira__users
[0m09:39:43.006881 [debug] [Thread-1  ]: Writing injected SQL for node "model.wire_jira.int_jira__users"
[0m09:39:43.007361 [debug] [Thread-1  ]: finished collecting timing info
[0m09:39:43.007495 [debug] [Thread-1  ]: Began executing node model.wire_jira.int_jira__users
[0m09:39:43.010755 [debug] [Thread-1  ]: Writing runtime sql for node "model.wire_jira.int_jira__users"
[0m09:39:43.011193 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:39:43.102027 [debug] [Thread-1  ]: On model.wire_jira.int_jira__users: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira__users"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira__users`
  OPTIONS(
      description=""""""
    )
  as with stg_jira__users as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__users`

),

jira__user_enhanced as (

    select * from `ra-development`.`lewis_analytics_dev_jira`.`jira__user_enhanced`

),

joined as (

    select

        stg_jira__users.jira_user_natural_key,

        stg_jira__users.jira_user_name,
        stg_jira__users.jira_user_email,
        stg_jira__users.jira_user_locale,
        stg_jira__users.jira_user_time_zone,

        jira__user_enhanced.projects as jira_user_projects,
        jira__user_enhanced.count_closed_issues as jira_user_count_closed_issues,
        jira__user_enhanced.count_open_issues as jira_user_count_open_issues,
        jira__user_enhanced.avg_close_time_days as jira_user_avg_close_time_days,
        jira__user_enhanced.avg_age_currently_open_days as jira_user_avg_age_currently_open_days,
        jira__user_enhanced.median_close_time_days as jira_user_median_close_time_days,
        jira__user_enhanced.median_age_currently_open_days as jira_user_median_age_currently_open_days,
        jira__user_enhanced.avg_close_time_seconds as jira_user_avg_close_time_seconds,
        jira__user_enhanced.avg_age_currently_open_seconds as jira_user_avg_age_currently_open_seconds,
        jira__user_enhanced.median_close_time_seconds as jira_user_median_close_time_seconds,
        jira__user_enhanced.median_age_currently_open_seconds as jira_user_median_age_currently_open_seconds

    from stg_jira__users

    left join jira__user_enhanced
    on stg_jira__users.jira_user_natural_key = jira__user_enhanced.user_id

)

select * from joined;


[0m09:39:43.281082 [debug] [Thread-6  ]: finished collecting timing info
[0m09:39:43.281833 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127516b50>]}
[0m09:39:43.282322 [info ] [Thread-6  ]: 102 of 110 OK created sql table model lewis_analytics_dev_jira.jira__project_enhanced  [[32mCREATE TABLE (83.0 rows, 482.8 KB processed)[0m in 3.25s]
[0m09:39:43.282956 [debug] [Thread-6  ]: Finished running node model.jira.jira__project_enhanced
[0m09:39:43.283442 [debug] [Thread-8  ]: Began running node model.wire_jira.int_jira__projects
[0m09:39:43.283688 [info ] [Thread-8  ]: 107 of 110 START sql view model lewis_analytics_dev_integration.int_jira__projects  [RUN]
[0m09:39:43.284427 [debug] [Thread-8  ]: Acquiring new bigquery connection "model.wire_jira.int_jira__projects"
[0m09:39:43.284620 [debug] [Thread-8  ]: Began compiling node model.wire_jira.int_jira__projects
[0m09:39:43.284779 [debug] [Thread-8  ]: Compiling model.wire_jira.int_jira__projects
[0m09:39:43.289867 [debug] [Thread-8  ]: Writing injected SQL for node "model.wire_jira.int_jira__projects"
[0m09:39:43.290467 [debug] [Thread-8  ]: finished collecting timing info
[0m09:39:43.290630 [debug] [Thread-8  ]: Began executing node model.wire_jira.int_jira__projects
[0m09:39:43.295116 [debug] [Thread-8  ]: Writing runtime sql for node "model.wire_jira.int_jira__projects"
[0m09:39:43.295723 [debug] [Thread-8  ]: Opening a new connection, currently in state closed
[0m09:39:43.386822 [debug] [Thread-8  ]: On model.wire_jira.int_jira__projects: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.int_jira__projects"} */


  create or replace view `ra-development`.`lewis_analytics_dev_integration`.`int_jira__projects`
  OPTIONS(
      description=""""""
    )
  as with stg_jira__projects as (

    select * from `ra-development`.`lewis_analytics_dev_staging`.`stg_jira__projects`

),

fivetran_jira__project_enhanced as (

    select * from `ra-development`.`lewis_analytics_dev_jira`.`jira__project_enhanced`

),

joined as (

    select

        stg_jira__projects.jira_project_natural_key,
        stg_jira__projects.jira_project_lead_natural_key,

        stg_jira__projects.jira_project_name,
        stg_jira__projects.jira_project_description,
        stg_jira__projects.jira_project_key,
        stg_jira__projects.jira_project_project_type_key,
        
        fivetran_jira__project_enhanced.epics as jira_project_epics,
        fivetran_jira__project_enhanced.components as jira_project_components,
        fivetran_jira__project_enhanced.count_closed_issues as jira_project_count_closed_issues,
        fivetran_jira__project_enhanced.count_open_issues as jira_project_count_open_issues,
        fivetran_jira__project_enhanced.count_open_assigned_issues as jira_project_count_open_assigned_issues,
        fivetran_jira__project_enhanced.avg_close_time_days as jira_project_avg_close_time_days,
        fivetran_jira__project_enhanced.avg_assigned_close_time_days as jira_project_avg_assigned_close_time_days,
        fivetran_jira__project_enhanced.avg_age_currently_open_days as jira_project_avg_age_currently_open_days,
        fivetran_jira__project_enhanced.avg_age_currently_open_assigned_days as jira_project_avg_age_currently_open_assigned_days,
        fivetran_jira__project_enhanced.median_close_time_days as jira_project_median_close_time_days,
        fivetran_jira__project_enhanced.median_age_currently_open_days as jira_project_median_age_currently_open_days,
        fivetran_jira__project_enhanced.median_assigned_close_time_days as jira_project_median_assigned_close_time_days,
        fivetran_jira__project_enhanced.median_age_currently_open_assigned_days as jira_project_median_age_currently_open_assigned_days,
        fivetran_jira__project_enhanced.avg_close_time_seconds as jira_project_avg_close_time_seconds,
        fivetran_jira__project_enhanced.avg_assigned_close_time_seconds as jira_project_avg_assigned_close_time_seconds,
        fivetran_jira__project_enhanced.avg_age_currently_open_seconds as jira_project_avg_age_currently_open_seconds,
        fivetran_jira__project_enhanced.avg_age_currently_open_assigned_seconds as jira_project_avg_age_currently_open_assigned_seconds,
        fivetran_jira__project_enhanced.median_close_time_seconds as jira_project_median_close_time_seconds,
        fivetran_jira__project_enhanced.median_age_currently_open_seconds as jira_project_median_age_currently_open_seconds,
        fivetran_jira__project_enhanced.median_assigned_close_time_seconds as jira_project_median_assigned_close_time_seconds,
        fivetran_jira__project_enhanced.median_age_currently_open_assigned_seconds as jira_project_median_age_currently_open_assigned_seconds
    
    from stg_jira__projects

    left join fivetran_jira__project_enhanced
    on fivetran_jira__project_enhanced.project_id = stg_jira__projects.jira_project_natural_key
  
)

select * from joined;


[0m09:39:43.842282 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:1318f030-2c5b-4cca-b2da-5799cc07e1f2:europe-west2&page=queryresults
[0m09:39:44.101309 [debug] [Thread-8  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:38164058-499e-48a5-a4f1-1a3e89d611c3:europe-west2&page=queryresults
[0m09:39:44.116418 [debug] [Thread-1  ]: finished collecting timing info
[0m09:39:44.117421 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133249970>]}
[0m09:39:44.117734 [info ] [Thread-1  ]: 106 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira__users  [[32mCREATE VIEW (0 processed)[0m in 1.12s]
[0m09:39:44.118092 [debug] [Thread-1  ]: Finished running node model.wire_jira.int_jira__users
[0m09:39:44.118407 [debug] [Thread-3  ]: Began running node model.wire_jira.wh_delivery__jira_users_dim
[0m09:39:44.118630 [info ] [Thread-3  ]: 108 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_users_dim  [RUN]
[0m09:39:44.119185 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_users_dim"
[0m09:39:44.119339 [debug] [Thread-3  ]: Began compiling node model.wire_jira.wh_delivery__jira_users_dim
[0m09:39:44.119458 [debug] [Thread-3  ]: Compiling model.wire_jira.wh_delivery__jira_users_dim
[0m09:39:44.124670 [debug] [Thread-3  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_users_dim"
[0m09:39:44.125150 [debug] [Thread-3  ]: finished collecting timing info
[0m09:39:44.125280 [debug] [Thread-3  ]: Began executing node model.wire_jira.wh_delivery__jira_users_dim
[0m09:39:44.129353 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m09:39:44.401305 [debug] [Thread-3  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_users_dim"
[0m09:39:44.402162 [debug] [Thread-3  ]: On model.wire_jira.wh_delivery__jira_users_dim: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_users_dim"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_users_dim`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_jira__users as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__users`

),

final as (

    select

        
    
to_hex(md5(cast(coalesce(cast(jira_user_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_user_pk,

        jira_user_name,
        jira_user_email,
        jira_user_locale,
        jira_user_time_zone,

        jira_user_projects,
        jira_user_count_closed_issues,
        jira_user_count_open_issues,
        jira_user_avg_close_time_days,
        jira_user_avg_age_currently_open_days,
        jira_user_median_close_time_days,
        jira_user_median_age_currently_open_days,
        jira_user_avg_close_time_seconds,
        jira_user_avg_age_currently_open_seconds,
        jira_user_median_close_time_seconds,
        jira_user_median_age_currently_open_seconds
            
    from int_jira__users

)

select * from final
    );
  
[0m09:39:44.415118 [debug] [Thread-8  ]: finished collecting timing info
[0m09:39:44.415795 [debug] [Thread-8  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133be52b0>]}
[0m09:39:44.416140 [info ] [Thread-8  ]: 107 of 110 OK created sql view model lewis_analytics_dev_integration.int_jira__projects  [[32mCREATE VIEW (0 processed)[0m in 1.13s]
[0m09:39:44.416692 [debug] [Thread-8  ]: Finished running node model.wire_jira.int_jira__projects
[0m09:39:44.417057 [debug] [Thread-4  ]: Began running node model.wire_jira.wh_delivery__jira_projects_fact
[0m09:39:44.417352 [info ] [Thread-4  ]: 109 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_projects_fact  [RUN]
[0m09:39:44.417968 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_projects_fact"
[0m09:39:44.418123 [debug] [Thread-4  ]: Began compiling node model.wire_jira.wh_delivery__jira_projects_fact
[0m09:39:44.418263 [debug] [Thread-4  ]: Compiling model.wire_jira.wh_delivery__jira_projects_fact
[0m09:39:44.426692 [debug] [Thread-4  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_projects_fact"
[0m09:39:44.427328 [debug] [Thread-4  ]: finished collecting timing info
[0m09:39:44.427509 [debug] [Thread-4  ]: Began executing node model.wire_jira.wh_delivery__jira_projects_fact
[0m09:39:44.430966 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m09:39:44.707696 [debug] [Thread-4  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_projects_fact"
[0m09:39:44.708332 [debug] [Thread-4  ]: On model.wire_jira.wh_delivery__jira_projects_fact: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_projects_fact"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_projects_fact`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with int_jira__projects as (

    select * from `ra-development`.`lewis_analytics_dev_integration`.`int_jira__projects`

),

final as (

    select distinct
        
        
    
to_hex(md5(cast(coalesce(cast(jira_project_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_project_pk, 
        
        
    
to_hex(md5(cast(coalesce(cast(jira_project_lead_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_user_fk,  
        
        jira_project_name,
        jira_project_description,
        jira_project_key,
        jira_project_project_type_key,

        jira_project_epics,
        jira_project_components,
        jira_project_count_closed_issues,
        jira_project_count_open_issues,
        jira_project_count_open_assigned_issues,
        jira_project_avg_close_time_days,
        jira_project_avg_assigned_close_time_days,
        jira_project_avg_age_currently_open_days,
        jira_project_avg_age_currently_open_assigned_days,
        jira_project_median_close_time_days,
        jira_project_median_age_currently_open_days,
        jira_project_median_assigned_close_time_days,
        jira_project_median_age_currently_open_assigned_days,
        jira_project_avg_close_time_seconds,
        jira_project_avg_assigned_close_time_seconds,
        jira_project_avg_age_currently_open_seconds,
        jira_project_avg_age_currently_open_assigned_seconds,
        jira_project_median_close_time_seconds,
        jira_project_median_age_currently_open_seconds,
        jira_project_median_assigned_close_time_seconds,
        jira_project_median_age_currently_open_assigned_seconds

    from int_jira__projects


)

select * from final
    );
  
[0m09:39:45.686641 [debug] [Thread-5  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:1a586ffa-75f5-4374-9ec3-2b29686a75c4:europe-west2&page=queryresults
[0m09:39:45.983751 [debug] [Thread-5  ]: finished collecting timing info
[0m09:39:45.984984 [debug] [Thread-5  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1270d1310>]}
[0m09:39:45.985647 [info ] [Thread-5  ]: 103 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_issues_board_bridge  [[32mCREATE TABLE (5.2k rows, 18.1 MB processed)[0m in 4.70s]
[0m09:39:45.986696 [debug] [Thread-5  ]: Finished running node model.wire_jira.wh_delivery__jira_issues_board_bridge
[0m09:39:46.201083 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:cd717df7-0481-44fe-b105-f1954c8475e2:europe-west2&page=queryresults
[0m09:39:46.321723 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:f047db8f-5c68-49f4-9e92-490759ad7627:europe-west2&page=queryresults
[0m09:39:46.454394 [debug] [Thread-3  ]: finished collecting timing info
[0m09:39:46.455478 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133772400>]}
[0m09:39:46.456309 [info ] [Thread-3  ]: 108 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_users_dim  [[32mCREATE TABLE (109.0 rows, 23.0 KB processed)[0m in 2.34s]
[0m09:39:46.457118 [debug] [Thread-3  ]: Finished running node model.wire_jira.wh_delivery__jira_users_dim
[0m09:39:46.539523 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:0ad5c24a-51c2-45f8-9c1e-b7acded587cf:europe-west2&page=queryresults
[0m09:39:46.596860 [debug] [Thread-2  ]: finished collecting timing info
[0m09:39:46.598022 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1276097c0>]}
[0m09:39:46.598491 [info ] [Thread-2  ]: 105 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_issues_sprint_bridge  [[32mCREATE TABLE (60.9k rows, 18.1 MB processed)[0m in 5.32s]
[0m09:39:46.599058 [debug] [Thread-2  ]: Finished running node model.wire_jira.wh_delivery__jira_issues_sprint_bridge
[0m09:39:46.657078 [debug] [Thread-7  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:df3473bd-2eef-410a-8888-bb2b61488865:europe-west2&page=queryresults
[0m09:39:46.815769 [debug] [Thread-4  ]: finished collecting timing info
[0m09:39:46.817402 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1275e4c10>]}
[0m09:39:46.818140 [info ] [Thread-4  ]: 109 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_projects_fact  [[32mCREATE TABLE (83.0 rows, 33.6 KB processed)[0m in 2.40s]
[0m09:39:46.819039 [debug] [Thread-4  ]: Finished running node model.wire_jira.wh_delivery__jira_projects_fact
[0m09:39:46.939303 [debug] [Thread-7  ]: finished collecting timing info
[0m09:39:46.940322 [debug] [Thread-7  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12729efd0>]}
[0m09:39:46.940757 [info ] [Thread-7  ]: 104 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_issues_fact  [[32mCREATE TABLE (5.1k rows, 24.0 MB processed)[0m in 5.66s]
[0m09:39:46.941626 [debug] [Thread-7  ]: Finished running node model.wire_jira.wh_delivery__jira_issues_fact
[0m09:39:46.942332 [debug] [Thread-6  ]: Began running node model.wire_jira.wh_delivery__jira_issues_xa
[0m09:39:46.942691 [info ] [Thread-6  ]: 110 of 110 START sql table model lewis_analytics_dev.wh_delivery__jira_issues_xa  [RUN]
[0m09:39:46.943833 [debug] [Thread-6  ]: Acquiring new bigquery connection "model.wire_jira.wh_delivery__jira_issues_xa"
[0m09:39:46.944096 [debug] [Thread-6  ]: Began compiling node model.wire_jira.wh_delivery__jira_issues_xa
[0m09:39:46.944363 [debug] [Thread-6  ]: Compiling model.wire_jira.wh_delivery__jira_issues_xa
[0m09:39:46.952971 [debug] [Thread-6  ]: Writing injected SQL for node "model.wire_jira.wh_delivery__jira_issues_xa"
[0m09:39:46.953537 [debug] [Thread-6  ]: finished collecting timing info
[0m09:39:46.953689 [debug] [Thread-6  ]: Began executing node model.wire_jira.wh_delivery__jira_issues_xa
[0m09:39:46.956886 [debug] [Thread-6  ]: Opening a new connection, currently in state closed
[0m09:39:47.233588 [debug] [Thread-6  ]: Writing runtime sql for node "model.wire_jira.wh_delivery__jira_issues_xa"
[0m09:39:47.234379 [debug] [Thread-6  ]: On model.wire_jira.wh_delivery__jira_issues_xa: /* {"app": "dbt", "dbt_version": "1.3.3", "profile_name": "ra_development", "target_name": "dev", "node_id": "model.wire_jira.wh_delivery__jira_issues_xa"} */

  
    

    create or replace table `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_issues_xa`
    
    
    OPTIONS(
      description=""""""
    )
    as (
      

with wh_delivery__issues_fact as (

    select * from `ra-development`.`lewis_analytics_dev`.`wh_delivery__jira_issues_fact`

),

final as (

    select

        
    
to_hex(md5(cast(coalesce(cast(jira_issue_natural_key as STRING), '_dbt_utils_surrogate_key_null_') as STRING))) as jira_issue_summary_pk,

        case
            when jira_issue_summary like "%stage%"
                and jira_issue_summary like "%warehouse%"
                then "warehouse staging layer"
            when jira_issue_summary like "%integrate%"
                and jira_issue_summary like "%warehouse%"
                then "warehouse integration layer"
            when jira_issue_summary like "%warehouse%"
                and jira_issue_summary like "%warehouse%"
                then "warehouse warehousing layer"

            when jira_issue_summary like "%stage%"
                and jira_issue_summary like "%bi%"
                then "bi staging layer"
            when jira_issue_summary like "%integrate%"
                and jira_issue_summary like "%bi%"
                then "bi integration layer"
            when jira_issue_summary like "%aggregate%"
                and jira_issue_summary like "%bi%"
                then "bi aggregate layer"

            when jira_issue_summary like "%stage%"
                and jira_issue_summary like "%looker%"
                then "bi staging layer"
            when jira_issue_summary like "%integrate%"
                and jira_issue_summary like "%looker%"
                then "bi integration layer"
            when jira_issue_summary like "%aggregate%"
                and jira_issue_summary like "%looker%"
                then "looker aggregate layer"

        end as jira_issue_development_stage,

        cast( timestamp_diff(jira_issue_resolved_at_ts, jira_issue_created_at_ts, day) as numeric) as jira_issue_duration,
        cast( timestamp_diff( current_date(), date(jira_issue_created_at_ts), day) as numeric) as jira_issue_age_in_days,

        case 
            when jira_issue_story_point_estimate = 0.5
                then 0.5
            when jira_issue_story_point_estimate = 1
                then 1
            when jira_issue_story_point_estimate = 2
                then 2            
            when jira_issue_story_point_estimate = 3
                then 3
            when jira_issue_story_point_estimate = 4
                then 5
            when jira_issue_story_point_estimate = 5
                then 5      
            when jira_issue_story_point_estimate = 6
                then 5    
            when jira_issue_story_point_estimate >6 or jira_issue_story_point_estimate <=8
                then 8
            when jira_issue_story_point_estimate >8
                then 16
        end as jira_issue_summary_story_point_estimate,







    from wh_delivery__issues_fact
    
)

select * from final
    );
  
[0m09:39:48.987001 [debug] [Thread-6  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ra-development&j=bq:5a34a416-7f7c-4011-b39c-e8f223a2c3f0:europe-west2&page=queryresults
[0m09:39:49.263550 [debug] [Thread-6  ]: finished collecting timing info
[0m09:39:49.264685 [debug] [Thread-6  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c56e1cb2-a929-475b-a37a-fe1fd5478edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133244250>]}
[0m09:39:49.265232 [info ] [Thread-6  ]: 110 of 110 OK created sql table model lewis_analytics_dev.wh_delivery__jira_issues_xa  [[32mCREATE TABLE (5.1k rows, 416.3 KB processed)[0m in 2.32s]
[0m09:39:49.265914 [debug] [Thread-6  ]: Finished running node model.wire_jira.wh_delivery__jira_issues_xa
[0m09:39:49.269047 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m09:39:49.270902 [info ] [MainThread]: 
[0m09:39:49.271336 [info ] [MainThread]: Finished running 61 view models, 43 table models, 6 incremental models in 0 hours 1 minutes and 22.04 seconds (82.04s).
[0m09:39:49.271790 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:39:49.271990 [debug] [MainThread]: Connection 'model.wire_jira.int_jira__users' was properly closed.
[0m09:39:49.272143 [debug] [MainThread]: Connection 'model.wire_jira.wh_delivery__jira_issues_sprint_bridge' was properly closed.
[0m09:39:49.272350 [debug] [MainThread]: Connection 'model.wire_jira.wh_delivery__jira_users_dim' was properly closed.
[0m09:39:49.272492 [debug] [MainThread]: Connection 'model.wire_jira.wh_delivery__jira_projects_fact' was properly closed.
[0m09:39:49.272616 [debug] [MainThread]: Connection 'model.wire_jira.wh_delivery__jira_issues_board_bridge' was properly closed.
[0m09:39:49.272732 [debug] [MainThread]: Connection 'model.wire_jira.wh_delivery__jira_issues_xa' was properly closed.
[0m09:39:49.272844 [debug] [MainThread]: Connection 'model.wire_jira.wh_delivery__jira_issues_fact' was properly closed.
[0m09:39:49.272954 [debug] [MainThread]: Connection 'model.wire_jira.int_jira__projects' was properly closed.
[0m09:39:49.354390 [info ] [MainThread]: 
[0m09:39:49.354672 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:39:49.354910 [info ] [MainThread]: 
[0m09:39:49.355036 [info ] [MainThread]: Done. PASS=110 WARN=0 ERROR=0 SKIP=0 TOTAL=110
[0m09:39:49.355289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102981bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12720a640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x133e72640>]}
[0m09:39:49.355421 [debug] [MainThread]: Flushing usage events
